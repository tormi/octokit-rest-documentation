{"version":3,"sources":["webpack:///./node_modules/core-js/modules/es6.function.name.js","webpack:///./node_modules/prismjs/prism.js","webpack:///./node_modules/marked/lib/marked.js","webpack:///./node_modules/elasticlunr/elasticlunr.js"],"names":["dP","__webpack_require__","f","FProto","Function","prototype","nameRE","configurable","get","this","match","e","Prism","_self","lang","uniqueId","_","manual","disableWorkerMessageHandler","util","encode","tokens","Token","type","content","alias","Array","isArray","map","replace","o","Object","toString","call","slice","objId","obj","defineProperty","value","clone","deepClone","visited","id","key","hasOwnProperty","forEach","v","i","languages","extend","redef","insertBefore","inside","before","insert","root","grammar","ret","token","newToken","old","DFS","callback","property","propertyType","plugins","highlightAll","async","highlightAllUnder","document","container","env","selector","hooks","run","element","elements","querySelectorAll","highlightElement","language","parent","test","className","parentNode","toLowerCase","nodeName","code","textContent","insertHighlightedCode","highlightedCode","innerHTML","Worker","worker","filename","onmessage","evt","data","postMessage","JSON","stringify","immediateClose","highlight","text","tokenize","matchGrammar","strarr","index","startPos","oneshot","target","patterns","j","length","pattern","lookbehind","greedy","lookbehindLength","global","flags","RegExp","source","pos","str","lastIndex","exec","from","to","k","p","len","delNum","after","args","push","wrapped","splice","apply","rest","all","add","name","callbacks","matchedStr","join","tag","classes","attributes","aliases","keys","addEventListener","message","parse","close","script","currentScript","getElementsByTagName","pop","src","hasAttribute","readyState","window","requestAnimationFrame","setTimeout","WorkerGlobalScope","self","module","exports","markup","comment","prolog","doctype","cdata","punctuation","namespace","attr-value","attr-name","entity","tagName","includedCdataInside","included-cdata","def","xml","html","mathml","svg","string","css","atrule","rule","url","important","function","addInlined","style-attr","clike","class-name","keyword","boolean","number","operator","javascript","regex","function-variable","parameter","constant","template-string","interpolation","interpolation-punctuation","js","querySelector","fileHighlight","Extensions","py","rb","ps1","psm1","sh","bat","h","tex","pre","getAttribute","extension","createElement","appendChild","xhr","XMLHttpRequest","open","onreadystatechange","status","responseText","setAttribute","statusText","send","toolbar","registerButton","a","href","block","newline","fences","noop","hr","heading","nptable","blockquote","list","table","lheading","paragraph","Lexer","options","links","create","marked","defaults","rules","normal","pedantic","gfm","tables","_label","_title","edit","getRegex","bullet","item","_tag","_comment","merge","lex","top","next","loose","cap","bull","b","listStart","listItems","t","space","l","isordered","istask","ischecked","substring","rtrim","depth","header","splitCells","align","split","cells","ordered","start","indexOf","smartLists","charAt","undefined","task","checked","sanitize","sanitizer","title","Error","charCodeAt","inline","escape","autolink","link","reflink","nolink","strong","em","br","del","InlineLexer","renderer","Renderer","breaks","TextRenderer","Parser","escapeTest","escapeReplace","ch","replacements","escapeTestNoEncode","escapeReplaceNoEncode","unescape","n","String","fromCharCode","parseInt","opt","val","cleanUrl","base","prot","decodeURIComponent","originIndependentUrl","baseUrls","resolveUrl","encodeURI","_escapes","_scheme","_email","_attribute","_href","_extended_email","_backpedal","output","prevCapZero","out","mangle","inLink","inRawBlock","trim","outputLink","escapes","codespan","smartypants","image","Math","random","escaped","langPrefix","quote","level","raw","headerIds","headerPrefix","xhtml","body","listitem","checkbox","tablerow","tablecell","baseUrl","inlineText","reverse","tok","peek","parseText","row","cell","&","<",">","\"","'","arguments","tableRow","count","offset","curr","c","invert","suffLen","currChar","substr","pending","done","err","silent","setOptions","getDefaults","parser","lexer","inlineLexer","__WEBPACK_AMD_DEFINE_FACTORY__","__WEBPACK_AMD_DEFINE_RESULT__","step2list","step3list","C","re_mgr0","re_mgr1","re_meq1","re_s_v","re_1a","re2_1a","re_1b","re2_1b","re_1b_2","re2_1b_2","re3_1b_2","re4_1b_2","re_1c","re_2","re_3","re_4","re2_4","re_5","re_5_1","re3_5","elasticlunr","config","idx","Index","pipeline","trimmer","stopWordFilter","stemmer","version","lunr","utils","warn","console","EventEmitter","events","addListener","fn","names","TypeError","hasHandler","removeListener","fnIndex","emit","tokenizer","arr","filter","seperator","concat","defaultSeperator","setSeperator","sep","resetSeperator","getSeperator","Pipeline","_queue","registeredFunctions","registerFunction","label","getRegisteredFunction","warnIfFunctionNotRegistered","load","serialised","fnName","existingFn","newFn","remove","tokenLength","pipelineLength","reset","toJSON","_fields","_ref","documentStore","DocumentStore","eventEmitter","_idfCache","on","bind","off","serialisedData","field","fields","ref","InvertedIndex","addField","fieldName","setRef","refName","saveDocument","save","addDoc","doc","emitEvent","docRef","fieldTokens","addFieldLength","tokenCount","termFrequency","sqrt","addToken","tf","removeDocByRef","isDocStored","hasDoc","getDoc","removeDoc","removeToken","updateDoc","idf","term","cacheKey","df","getDocFreq","log","getFields","search","query","userConfig","configStr","Configuration","queryTokens","queryResults","fieldSearchResults","fieldSearch","fieldBoost","boost","results","score","sort","booleanType","bool","expand","scores","docTokens","expandToken","queryTokenScores","docs","getDocs","filteredDocs","fieldSearchStats","getTermFrequency","fieldLength","getFieldLength","fieldLengthNorm","penality","mergeScores","coordNorm","accumScores","op","intersection","indexJson","use","plugin","unshift","_save","docInfo","store","copy","constructor","attr","updateFieldLength","ational","tional","enci","anci","izer","bli","alli","entli","eli","ousli","ization","ation","ator","alism","iveness","fulness","ousness","aliti","iviti","biliti","logi","icate","ative","alize","iciti","ical","ful","ness","w","stem","suffix","firstch","re","re2","re3","re4","toUpperCase","fp","stopWords","clearStopWords","addStopWords","words","word","resetStopWords","defaultStopWords","","able","about","across","almost","also","am","among","an","and","any","are","as","at","be","because","been","but","by","can","cannot","could","dear","did","do","does","either","else","ever","every","for","got","had","has","have","he","her","hers","him","his","how","however","if","in","into","is","it","its","just","least","let","like","likely","may","me","might","most","must","my","neither","no","nor","not","of","often","only","or","other","our","own","rather","said","say","says","she","should","since","so","some","than","that","the","their","them","then","there","these","they","tis","too","twas","us","wants","was","we","were","what","when","where","which","while","who","whom","why","will","with","would","yet","you","your","tokenInfo","hasToken","node","getNode","memo","buildUserConfig","error","buildDefaultConfig","global_bool","global_expand","field_config","field_expand","addAllFields2UserConfig","SortedSet","set","locationFor","toArray","ctx","elem","end","sectionLength","pivot","floor","pivotElem","intersect","otherSet","intersectSet","a_len","b_len","union","longSet","shortSet","unionSet","shortSetElements"],"mappings":"6EAAA,IAAAA,EAASC,EAAQ,IAAcC,EAC/BC,EAAAC,SAAAC,UACAC,EAAA,wBACA,SAGAH,GAAkBF,EAAQ,KAAgBD,EAAAG,EAH1C,OAG0C,CAC1CI,cAAA,EACAC,IAAA,WACA,IACA,UAAAC,MAAAC,MAAAJ,GAAA,GACK,MAAAK,GACL,+CCPA,IAcAC,EAAA,SAAAC,GAGA,IAAAC,EAAA,8BACAC,EAAA,EAEAC,EAAA,CACAC,OAAAJ,EAAAD,OAAAC,EAAAD,MAAAK,OACAC,4BAAAL,EAAAD,OAAAC,EAAAD,MAAAM,4BACAC,KAAA,CACAC,OAAA,SAAAC,GACA,OAAAA,aAAAC,EACA,IAAAA,EAAAD,EAAAE,KAAAP,EAAAG,KAAAC,OAAAC,EAAAG,SAAAH,EAAAI,OACIC,MAAAC,QAAAN,GACJA,EAAAO,IAAAZ,EAAAG,KAAAC,QAEAC,EAAAQ,QAAA,cAAsCA,QAAA,aAAsBA,QAAA,gBAI5DN,KAAA,SAAAO,GACA,OAAAC,OAAA1B,UAAA2B,SAAAC,KAAAH,GAAAI,MAAA,OAGAC,MAAA,SAAAC,GAIA,OAHAA,EAAA,MACAL,OAAAM,eAAAD,EAAA,QAAwCE,QAAAvB,IAExCqB,EAAA,MAIAG,MAAA,SAAAC,EAAAV,EAAAW,GACA,IAAAF,EAAAG,EAAAnB,EAAAP,EAAAG,KAAAI,KAAAO,GAGA,OAFAW,KAAA,GAEAlB,GACA,aAEA,GADAmB,EAAA1B,EAAAG,KAAAgB,MAAAL,GACAW,EAAAC,GACA,OAAAD,EAAAC,GAKA,QAAAC,KAHAJ,EAAA,GACAE,EAAAC,GAAAH,EAEAT,EACAA,EAAAc,eAAAD,KACAJ,EAAAI,GAAAH,EAAAV,EAAAa,GAAAF,IAIA,OAAAF,EAEA,YAEA,OADAG,EAAA1B,EAAAG,KAAAgB,MAAAL,GACAW,EAAAC,GACAD,EAAAC,IAEAH,EAAA,GACAE,EAAAC,GAAAH,EAEAT,EAAAe,QAAA,SAAAC,EAAAC,GACAR,EAAAQ,GAAAP,EAAAM,EAAAL,KAGAF,GAEA,QACA,OAAAT,KAKAkB,UAAA,CACAC,OAAA,SAAAP,EAAAQ,GACA,IAAApC,EAAAE,EAAAG,KAAAoB,MAAAvB,EAAAgC,UAAAN,IAEA,QAAAC,KAAAO,EACApC,EAAA6B,GAAAO,EAAAP,GAGA,OAAA7B,GAYAqC,aAAA,SAAAC,EAAAC,EAAAC,EAAAC,GAEA,IAAAC,GADAD,KAAAvC,EAAAgC,WACAI,GACAK,EAAA,GAEA,QAAAC,KAAAF,EACA,GAAAA,EAAAZ,eAAAc,GAAA,CAEA,GAAAA,GAAAL,EACA,QAAAM,KAAAL,EACAA,EAAAV,eAAAe,KACAF,EAAAE,GAAAL,EAAAK,IAMAL,EAAAV,eAAAc,KACAD,EAAAC,GAAAF,EAAAE,IAKA,IAAAE,EAAAL,EAAAH,GAUA,OATAG,EAAAH,GAAAK,EAGAzC,EAAAgC,UAAAa,IAAA7C,EAAAgC,UAAA,SAAAL,EAAAL,GACAA,IAAAsB,GAAAjB,GAAAS,IACA3C,KAAAkC,GAAAc,KAIAA,GAIAI,IAAA,SAAAA,EAAA/B,EAAAgC,EAAAvC,EAAAkB,GACAA,KAAA,GAEA,IAAAN,EAAAnB,EAAAG,KAAAgB,MAEA,QAAAY,KAAAjB,EACA,GAAAA,EAAAc,eAAAG,GAAA,CACAe,EAAA7B,KAAAH,EAAAiB,EAAAjB,EAAAiB,GAAAxB,GAAAwB,GAEA,IAAAgB,EAAAjC,EAAAiB,GACAiB,EAAAhD,EAAAG,KAAAI,KAAAwC,GAEA,WAAAC,GAAAvB,EAAAN,EAAA4B,IAIA,UAAAC,GAAAvB,EAAAN,EAAA4B,MACAtB,EAAAN,EAAA4B,KAAA,EACAF,EAAAE,EAAAD,EAAAf,EAAAN,KALAA,EAAAN,EAAA4B,KAAA,EACAF,EAAAE,EAAAD,EAAA,KAAArB,OAUAwB,QAAA,GAEAC,aAAA,SAAAC,EAAAL,GACA9C,EAAAoD,kBAAAC,SAAAF,EAAAL,IAGAM,kBAAA,SAAAE,EAAAH,EAAAL,GACA,IAAAS,EAAA,CACAT,WACAU,SAAA,oGAGAxD,EAAAyD,MAAAC,IAAA,sBAAAH,GAIA,IAFA,IAEAI,EAFAC,EAAAL,EAAAK,UAAAN,EAAAO,iBAAAN,EAAAC,UAEAzB,EAAA,EAAwB4B,EAAAC,EAAA7B,MACxB/B,EAAA8D,iBAAAH,GAAA,IAAAR,EAAAI,EAAAT,WAIAgB,iBAAA,SAAAH,EAAAR,EAAAL,GAIA,IAFA,IAAAiB,EAAAvB,EAAAwB,EAAAL,EAEAK,IAAAlE,EAAAmE,KAAAD,EAAAE,YACAF,IAAAG,WAGAH,IACAD,GAAAC,EAAAE,UAAAxE,MAAAI,IAAA,UAAAsE,cACA5B,EAAAxC,EAAAgC,UAAA+B,IAIAJ,EAAAO,UAAAP,EAAAO,UAAArD,QAAAf,EAAA,IAAAe,QAAA,yBAAAkD,EAEAJ,EAAAQ,aAEAH,EAAAL,EAAAQ,WAEA,OAAAF,KAAAD,EAAAK,YACAL,EAAAE,UAAAF,EAAAE,UAAArD,QAAAf,EAAA,IAAAe,QAAA,yBAAAkD,IAIA,IAEAR,EAAA,CACAI,UACAI,WACAvB,UACA8B,KANAX,EAAAY,aASAC,EAAA,SAAAC,GACAlB,EAAAkB,kBAEAzE,EAAAyD,MAAAC,IAAA,gBAAAH,GAEAA,EAAAI,QAAAe,UAAAnB,EAAAkB,gBAEAzE,EAAAyD,MAAAC,IAAA,kBAAAH,GACAvD,EAAAyD,MAAAC,IAAA,WAAAH,GACAT,KAAA7B,KAAAsC,EAAAI,UAKA,GAFA3D,EAAAyD,MAAAC,IAAA,sBAAAH,GAEAA,EAAAe,KAOA,GAFAtE,EAAAyD,MAAAC,IAAA,mBAAAH,GAEAA,EAAAf,QAKA,GAAAW,GAAAtD,EAAA8E,OAAA,CACA,IAAAC,EAAA,IAAAD,OAAA3E,EAAA6E,UAEAD,EAAAE,UAAA,SAAAC,GACAP,EAAAO,EAAAC,OAGAJ,EAAAK,YAAAC,KAAAC,UAAA,CACApB,SAAAR,EAAAQ,SACAO,KAAAf,EAAAe,KACAc,gBAAA,UAIAZ,EAAAxE,EAAAqF,UAAA9B,EAAAe,KAAAf,EAAAf,QAAAe,EAAAQ,gBAlBAS,EAAAxE,EAAAG,KAAAC,OAAAmD,EAAAe,YAPAtE,EAAAyD,MAAAC,IAAA,WAAAH,IA6BA8B,UAAA,SAAAC,EAAA9C,EAAAuB,GACA,IAAAR,EAAA,CACAe,KAAAgB,EACA9C,UACAuB,YAKA,OAHA/D,EAAAyD,MAAAC,IAAA,kBAAAH,GACAA,EAAAlD,OAAAL,EAAAuF,SAAAhC,EAAAe,KAAAf,EAAAf,SACAxC,EAAAyD,MAAAC,IAAA,iBAAAH,GACAjD,EAAA6E,UAAAnF,EAAAG,KAAAC,OAAAmD,EAAAlD,QAAAkD,EAAAQ,WAGAyB,aAAA,SAAAF,EAAAG,EAAAjD,EAAAkD,EAAAC,EAAAC,EAAAC,GACA,QAAAnD,KAAAF,EACA,GAAAA,EAAAZ,eAAAc,IAAAF,EAAAE,GAAA,CAIA,GAAAA,GAAAmD,EACA,OAGA,IAAAC,EAAAtD,EAAAE,GACAoD,EAAA,UAAA9F,EAAAG,KAAAI,KAAAuF,KAAA,CAAAA,GAEA,QAAAC,EAAA,EAAkBA,EAAAD,EAAAE,SAAqBD,EAAA,CACvC,IAAAE,EAAAH,EAAAC,GACA3D,EAAA6D,EAAA7D,OACA8D,IAAAD,EAAAC,WACAC,IAAAF,EAAAE,OACAC,EAAA,EACA3F,EAAAwF,EAAAxF,MAEA,GAAA0F,IAAAF,UAAAI,OAAA,CAEA,IAAAC,EAAAL,UAAAjF,WAAAtB,MAAA,eACAuG,UAAAM,OAAAN,UAAAO,OAAAF,EAAA,KAGAL,eAGA,QAAAlE,EAAA2D,EAAAe,EAAAd,EAAuC5D,EAAA0D,EAAAO,OAAmBS,GAAAhB,EAAA1D,GAAAiE,SAAAjE,EAAA,CAE1D,IAAA2E,EAAAjB,EAAA1D,GAEA,GAAA0D,EAAAO,OAAAV,EAAAU,OAEA,OAGA,KAAAU,aAAApG,GAAA,CAIA,GAAA6F,GAAApE,GAAA0D,EAAAO,OAAA,GAGA,GAFAC,EAAAU,UAAAF,IACA/G,EAAAuG,EAAAW,KAAAtB,IAEA,MAQA,IALA,IAAAuB,EAAAnH,EAAAgG,OAAAQ,EAAAxG,EAAA,GAAAsG,OAAA,GACAc,EAAApH,EAAAgG,MAAAhG,EAAA,GAAAsG,OACAe,EAAAhF,EACAiF,EAAAP,EAEAQ,EAAAxB,EAAAO,OAAmCe,EAAAE,IAAAD,EAAAF,IAAArB,EAAAsB,GAAAxG,OAAAkF,EAAAsB,EAAA,GAAAZ,UAAmEY,EAGtGF,IAFAG,GAAAvB,EAAAsB,GAAAf,YAGAjE,EACA0E,EAAAO,GAKA,GAAAvB,EAAA1D,aAAAzB,EACA,SAIA4G,EAAAH,EAAAhF,EACA2E,EAAApB,EAAApE,MAAAuF,EAAAO,GACAtH,EAAAgG,OAAAe,MACM,CACNR,EAAAU,UAAA,EAEA,IAAAjH,EAAAuG,EAAAW,KAAAF,GACAQ,EAAA,EAGA,GAAAxH,EAAA,CAQAwG,IACAE,EAAA1G,EAAA,GAAAA,EAAA,GAAAsG,OAAA,GAKAc,GAFAD,EAAAnH,EAAAgG,MAAAU,IACA1G,IAAA,GAAAwB,MAAAkF,IACAJ,OAFA,IAGA3D,EAAAqE,EAAAxF,MAAA,EAAA2F,GACAM,EAAAT,EAAAxF,MAAA4F,GAEAM,EAAA,CAAArF,EAAAmF,GAEA7E,MACAN,EACA0E,GAAApE,EAAA2D,OACAoB,EAAAC,KAAAhF,IAGA,IAAAiF,EAAA,IAAAhH,EAAAoC,EAAAN,EAAApC,EAAAuF,SAAA7F,EAAA0C,GAAA1C,EAAAe,EAAAf,EAAAyG,GAaA,GAXAiB,EAAAC,KAAAC,GAEAH,GACAC,EAAAC,KAAAF,GAGAzG,MAAArB,UAAAkI,OAAAC,MAAA/B,EAAA2B,GAEA,GAAAF,GACAlH,EAAAwF,aAAAF,EAAAG,EAAAjD,EAAAT,EAAA0E,GAAA,EAAA/D,GAEAkD,EACA,WAvCA,GAAAA,EACA,WA4CAL,SAAA,SAAAD,EAAA9C,GACA,IAAAiD,EAAA,CAAAH,GAEAmC,EAAAjF,EAAAiF,KAEA,GAAAA,EAAA,CACA,QAAA/E,KAAA+E,EACAjF,EAAAE,GAAA+E,EAAA/E,UAGAF,EAAAiF,KAKA,OAFAzH,EAAAwF,aAAAF,EAAAG,EAAAjD,EAAA,QAEAiD,GAGAhC,MAAA,CACAiE,IAAA,GAEAC,IAAA,SAAAC,EAAA9E,GACA,IAAAW,EAAAzD,EAAAyD,MAAAiE,IAEAjE,EAAAmE,GAAAnE,EAAAmE,IAAA,GAEAnE,EAAAmE,GAAAP,KAAAvE,IAGAY,IAAA,SAAAkE,EAAArE,GACA,IAAAsE,EAAA7H,EAAAyD,MAAAiE,IAAAE,GAEA,GAAAC,KAAA7B,OAIA,QAAAlD,EAAAf,EAAA,EAA0Be,EAAA+E,EAAA9F,MAC1Be,EAAAS,KAKAjD,SAKA,SAAAA,EAAAC,EAAAC,EAAAC,EAAAqH,EAAA3B,GACA1G,KAAAc,OACAd,KAAAe,UACAf,KAAAgB,QAEAhB,KAAAuG,OAAA,GAAA8B,GAAA,IAAA9B,OACAvG,KAAA0G,WAuCA,GA/CAtG,EAAAD,MAAAI,EAWAM,EAAA6E,UAAA,SAAArE,EAAAiD,EAAAC,GACA,oBAAAlD,EACA,OAAAA,EAGA,GAAAJ,MAAAC,QAAAG,GACA,OAAAA,EAAAF,IAAA,SAAA+C,GACA,OAAArD,EAAA6E,UAAAxB,EAAAI,EAAAjD,KACGiH,KAAA,IAGH,IAAAxE,EAAA,CACAhD,KAAAO,EAAAP,KACAC,QAAAF,EAAA6E,UAAArE,EAAAN,QAAAuD,EAAAC,GACAgE,IAAA,OACAC,QAAA,SAAAnH,EAAAP,MACA2H,WAAA,GACAnE,WACAC,UAGA,GAAAlD,EAAAL,MAAA,CACA,IAAA0H,EAAAzH,MAAAC,QAAAG,EAAAL,OAAAK,EAAAL,MAAA,CAAAK,EAAAL,OACAC,MAAArB,UAAAgI,KAAAG,MAAAjE,EAAA0E,QAAAE,GAGAnI,EAAAyD,MAAAC,IAAA,OAAAH,GAEA,IAAA2E,EAAAnH,OAAAqH,KAAA7E,EAAA2E,YAAAtH,IAAA,SAAAgH,GACA,OAAAA,EAAA,MAAArE,EAAA2E,WAAAN,IAAA,IAAA/G,QAAA,eAAyE,MACvEkH,KAAA,KAEF,UAAAxE,EAAAyE,IAAA,WAAAzE,EAAA0E,QAAAF,KAAA,UAAAG,EAAA,IAAAA,EAAA,QAAA3E,EAAA/C,QAAA,KAAA+C,EAAAyE,IAAA,MAIAnI,EAAAwD,SACA,OAAAxD,EAAAwI,kBAKArI,EAAAE,6BAEAL,EAAAwI,iBAAA,mBAAAtD,GACA,IAAAuD,EAAApD,KAAAqD,MAAAxD,EAAAC,MACAlF,EAAAwI,EAAAvE,SACAO,EAAAgE,EAAAhE,KACAc,EAAAkD,EAAAlD,eAEAvF,EAAAoF,YAAAjF,EAAAqF,UAAAf,EAAAtE,EAAAgC,UAAAlC,OACAsF,GACAvF,EAAA2I,UAEG,GAGHxI,GAlBAA,EAsBA,IAAAyI,EAAApF,SAAAqF,eAAA,GAAAxH,MAAAD,KAAAoC,SAAAsF,qBAAA,WAAAC,MAmBA,OAjBAH,IACAzI,EAAA6E,SAAA4D,EAAAI,IAEA7I,EAAAC,QAAAwI,EAAAK,aAAA,iBACA,YAAAzF,SAAA0F,WACAC,OAAAC,sBACAD,OAAAC,sBAAAjJ,EAAAkD,cAEA8F,OAAAE,WAAAlJ,EAAAkD,aAAA,IAIAG,SAAAgF,iBAAA,mBAAArI,EAAAkD,gBAKAlD,EA/gBA,CAdA,oBAAAgJ,OACAA,OAEA,oBAAAG,mBAAAC,gBAAAD,kBACAC,KACA,IA4hBiCC,EAAAC,UACjCD,EAAAC,QAAA1J,QAIA,IAAAyG,IACAA,EAAAzG,SAQAA,EAAAoC,UAAAuH,OAAA,CACAC,QAAA,kBACAC,OAAA,iBACAC,QAAA,sBACAC,MAAA,0BACA3B,IAAA,CACA/B,QAAA,yHACAE,QAAA,EACA/D,OAAA,CACA4F,IAAA,CACA/B,QAAA,kBACA7D,OAAA,CACAwH,YAAA,QACAC,UAAA,iBAGAC,aAAA,CACA7D,QAAA,sCACA7D,OAAA,CACAwH,YAAA,CACA,KACA,CACA3D,QAAA,mBACAC,YAAA,MAKA0D,YAAA,OACAG,YAAA,CACA9D,QAAA,YACA7D,OAAA,CACAyH,UAAA,mBAMAG,OAAA,qBAGApK,EAAAoC,UAAAuH,OAAA,IAAAnH,OAAA,cAAAA,OAAA,OACAxC,EAAAoC,UAAAuH,OAAA,OAGA3J,EAAA6D,MAAAkE,IAAA,gBAAApE,GAEA,WAAAA,EAAAhD,OACAgD,EAAA2E,WAAA,MAAA3E,EAAA/C,QAAAK,QAAA,QAAsD,QAItDE,OAAAM,eAAAzB,EAAAoC,UAAAuH,OAAAvB,IAAA,cAYA1G,MAAA,SAAA2I,EAAAnK,GACA,IAAAoK,EAAA,GACAA,EAAA,YAAApK,GAAA,CACAmG,QAAA,oCACAC,YAAA,EACA9D,OAAAxC,EAAAoC,UAAAlC,IAEAoK,EAAA,6BAEA,IAAA9H,EAAA,CACA+H,iBAAA,CACAlE,QAAA,4BACA7D,OAAA8H,IAGA9H,EAAA,YAAAtC,GAAA,CACAmG,QAAA,UACA7D,OAAAxC,EAAAoC,UAAAlC,IAGA,IAAAsK,EAAA,GACAA,EAAAH,GAAA,CACAhE,QAAAM,OAAA,mEAAAC,OAAA3F,QAAA,MAAAoJ,GAAA,KACA/D,YAAA,EACAC,QAAA,EACA/D,UAGAxC,EAAAoC,UAAAG,aAAA,iBAAAiI,MAIAxK,EAAAoC,UAAAqI,IAAAzK,EAAAoC,UAAAC,OAAA,aACArC,EAAAoC,UAAAsI,KAAA1K,EAAAoC,UAAAuH,OACA3J,EAAAoC,UAAAuI,OAAA3K,EAAAoC,UAAAuH,OACA3J,EAAAoC,UAAAwI,IAAA5K,EAAAoC,UAAAuH,OAOA,SAAA3J,GAEA,IAAA6K,EAAA,gDAEA7K,EAAAoC,UAAA0I,IAAA,CACAlB,QAAA,mBACAmB,OAAA,CACA1E,QAAA,mCACA7D,OAAA,CACAwI,KAAA,YAIAC,IAAAtE,OAAA,YAAAkE,EAAAjE,OAAA,gBACAhD,SAAA+C,OAAA,wBAAsCkE,EAAAjE,OAAA,kBACtCiE,OAAA,CACAxE,QAAAwE,EACAtE,QAAA,GAEApD,SAAA,+CACA+H,UAAA,gBACAC,SAAA,oBACAnB,YAAA,aAGAhK,EAAAoC,UAAA0I,IAAA,OAAAtI,OAAAqF,KAAA7H,EAAAoC,UAAA0I,IAEA,IAAAnB,EAAA3J,EAAAoC,UAAAuH,OACAA,IACAA,EAAAvB,IAAAgD,WAAA,eAEApL,EAAAoC,UAAAG,aAAA,uBACA8I,aAAA,CACAhF,QAAA,6CACA7D,OAAA,CACA2H,YAAA,CACA9D,QAAA,aACA7D,OAAAmH,EAAAvB,IAAA5F,QAEAwH,YAAA,wBACAE,aAAA,CACA7D,QAAA,MACA7D,OAAAxC,EAAAoC,UAAA0I,MAGAjK,MAAA,iBAEG8I,EAAAvB,MA/CH,CAkDCpI,GAODA,EAAAoC,UAAAkJ,MAAA,CACA1B,QAAA,CACA,CACAvD,QAAA,kCACAC,YAAA,GAEA,CACAD,QAAA,mBACAC,YAAA,EACAC,QAAA,IAGAsE,OAAA,CACAxE,QAAA,iDACAE,QAAA,GAEAgF,aAAA,CACAlF,QAAA,iGACAC,YAAA,EACA9D,OAAA,CACAwH,YAAA,UAGAwB,QAAA,6GACAC,QAAA,qBACAN,SAAA,YACAO,OAAA,wDACAC,SAAA,0DACA3B,YAAA,iBAQAhK,EAAAoC,UAAAwJ,WAAA5L,EAAAoC,UAAAC,OAAA,SACAkJ,aAAA,CACAvL,EAAAoC,UAAAkJ,MAAA,cACA,CACAjF,QAAA,0FACAC,YAAA,IAGAkF,QAAA,CACA,CACAnF,QAAA,kCACAC,YAAA,GAEA,CACAD,QAAA,6WACAC,YAAA,IAGAoF,OAAA,mHAEAP,SAAA,kFACAQ,SAAA,mGAGA3L,EAAAoC,UAAAwJ,WAAA,iBAAAvF,QAAA,uEAEArG,EAAAoC,UAAAG,aAAA,wBACAsJ,MAAA,CACAxF,QAAA,2HACAC,YAAA,EACAC,QAAA,GAGAuF,oBAAA,CACAzF,QAAA,8JACAxF,MAAA,YAEAkL,UAAA,CACA,CACA1F,QAAA,wGACAC,YAAA,EACA9D,OAAAxC,EAAAoC,UAAAwJ,YAEA,CACAvF,QAAA,gDACA7D,OAAAxC,EAAAoC,UAAAwJ,YAEA,CACAvF,QAAA,oDACAC,YAAA,EACA9D,OAAAxC,EAAAoC,UAAAwJ,YAEA,CACAvF,QAAA,qcACAC,YAAA,EACA9D,OAAAxC,EAAAoC,UAAAwJ,aAGAI,SAAA,8BAGAhM,EAAAoC,UAAAG,aAAA,uBACA0J,kBAAA,CACA5F,QAAA,mCACAE,QAAA,EACA/D,OAAA,CACA0J,cAAA,CACA7F,QAAA,YACA7D,OAAA,CACA2J,4BAAA,CACA9F,QAAA,UACAxF,MAAA,eAEAgH,KAAA7H,EAAAoC,UAAAwJ,aAGAf,OAAA,cAKA7K,EAAAoC,UAAAuH,QACA3J,EAAAoC,UAAAuH,OAAAvB,IAAAgD,WAAA,uBAGApL,EAAAoC,UAAAgK,GAAApM,EAAAoC,UAAAwJ,WAQA,oBAAApC,WAAAxJ,OAAAwJ,KAAA/F,mBAAA4I,gBAOA7C,KAAAxJ,MAAAsM,cAAA,SAAA5I,GACAA,KAAAD,SAEA,IAAA8I,EAAA,CACAH,GAAA,aACAI,GAAA,SACAC,GAAA,OACAC,IAAA,aACAC,KAAA,aACAC,GAAA,OACAC,IAAA,QACAC,EAAA,IACAC,IAAA,SAGAjM,MAAArB,UAAA6B,MAAAD,KAAAqC,EAAAO,iBAAA,kBAAAhC,QAAA,SAAA+K,GAEA,IAAAA,EAAA9D,aAAA,oBASA,IAJA,IAEA/E,EAFA8E,EAAA+D,EAAAC,aAAA,YAEA7I,EAAA4I,EACA9M,EAAA,8BACAkE,IAAAlE,EAAAmE,KAAAD,EAAAE,YACAF,IAAAG,WAOA,GAJAH,IACAD,GAAA6I,EAAA1I,UAAAxE,MAAAI,IAAA,YAGAiE,EAAA,CACA,IAAA+I,GAAAjE,EAAAnJ,MAAA,uBACAqE,EAAAoI,EAAAW,MAGA,IAAAxI,EAAAjB,SAAA0J,cAAA,QACAzI,EAAAJ,UAAA,YAAAH,EAEA6I,EAAArI,YAAA,GAEAD,EAAAC,YAAA,WAEAqI,EAAAI,YAAA1I,GAEA,IAAA2I,EAAA,IAAAC,eAEAD,EAAAE,KAAA,MAAAtE,GAAA,GAEAoE,EAAAG,mBAAA,WACA,GAAAH,EAAAlE,aAEAkE,EAAAI,OAAA,KAAAJ,EAAAK,cACAhJ,EAAAC,YAAA0I,EAAAK,aAEA1N,EAAAkE,iBAAAQ,GAEAsI,EAAAW,aAAA,uBAEAN,EAAAI,QAAA,IACA/I,EAAAC,YAAA,WAAA0I,EAAAI,OAAA,yBAAAJ,EAAAO,WAGAlJ,EAAAC,YAAA,6CAKA0I,EAAAQ,KAAA,SAGA7N,EAAAqD,QAAAyK,SACA9N,EAAAqD,QAAAyK,QAAAC,eAAA,yBAAApK,GACA,IAAAqJ,EAAArJ,EAAAI,QAAAQ,WACA,GAAAyI,GAAA,OAAA3I,KAAA2I,EAAAvI,WAAAuI,EAAA9D,aAAA,aAAA8D,EAAA9D,aAAA,uBAGA,IAAAD,EAAA+D,EAAAC,aAAA,YACAe,EAAAvK,SAAA0J,cAAA,KAIA,OAHAa,EAAArJ,YAAAqI,EAAAC,aAAA,wCACAe,EAAAL,aAAA,eACAK,EAAAC,KAAAhF,EACA+E,MAMAvK,SAAAgF,iBAAA,8BAEAe,KAAAxJ,MAAAsM,4DC57BA,SAAA7F,IAMC,SAAA9D,GACD,aAMA,IAAAuL,EAAA,CACAC,QAAA,OACAzJ,KAAA,oBACA0J,OAAAC,EACAC,GAAA,yDACAC,QAAA,6CACAC,QAAAH,EACAI,WAAA,0CACAC,KAAA,gEACAhE,KAAA,kYAUAF,IAAA,mFACAmE,MAAAN,EACAO,SAAA,oCACAC,UAAA,4GACAnJ,KAAA,WAmGA,SAAAoJ,EAAAC,GACAlP,KAAAY,OAAA,GACAZ,KAAAY,OAAAuO,MAAA7N,OAAA8N,OAAA,MACApP,KAAAkP,WAAAG,EAAAC,SACAtP,KAAAuP,MAAAlB,EAAAmB,OAEAxP,KAAAkP,QAAAO,SACAzP,KAAAuP,MAAAlB,EAAAoB,SACGzP,KAAAkP,QAAAQ,MACH1P,KAAAkP,QAAAS,OACA3P,KAAAuP,MAAAlB,EAAAsB,OAEA3P,KAAAuP,MAAAlB,EAAAqB,KA5GArB,EAAAuB,OAAA,iCACAvB,EAAAwB,OAAA,+DACAxB,EAAA1D,IAAAmF,EAAAzB,EAAA1D,KACAvJ,QAAA,QAAAiN,EAAAuB,QACAxO,QAAA,QAAAiN,EAAAwB,QACAE,WAEA1B,EAAA2B,OAAA,kBACA3B,EAAA4B,KAAA,6CACA5B,EAAA4B,KAAAH,EAAAzB,EAAA4B,KAAA,MACA7O,QAAA,QAAAiN,EAAA2B,QACAD,WAEA1B,EAAAQ,KAAAiB,EAAAzB,EAAAQ,MACAzN,QAAA,QAAAiN,EAAA2B,QACA5O,QAAA,wEACAA,QAAA,gBAAAiN,EAAA1D,IAAA5D,OAAA,KACAgJ,WAEA1B,EAAA6B,KAAA,gWAMA7B,EAAA8B,SAAA,yBACA9B,EAAAxD,KAAAiF,EAAAzB,EAAAxD,KAAA,KACAzJ,QAAA,UAAAiN,EAAA8B,UACA/O,QAAA,MAAAiN,EAAA6B,MACA9O,QAAA,wFACA2O,WAEA1B,EAAAW,UAAAc,EAAAzB,EAAAW,WACA5N,QAAA,KAAAiN,EAAAI,IACArN,QAAA,UAAAiN,EAAAK,SACAtN,QAAA,WAAAiN,EAAAU,UACA3N,QAAA,MAAAiN,EAAA6B,MACAH,WAEA1B,EAAAO,WAAAkB,EAAAzB,EAAAO,YACAxN,QAAA,YAAAiN,EAAAW,WACAe,WAMA1B,EAAAmB,OAAAY,EAAA,GAAuB/B,GAMvBA,EAAAqB,IAAAU,EAAA,GAAoB/B,EAAAmB,OAAA,CACpBjB,OAAA,+DACAS,UAAA,IACAN,QAAA,0CAGAL,EAAAqB,IAAAV,UAAAc,EAAAzB,EAAAW,WACA5N,QAAA,YACAiN,EAAAqB,IAAAnB,OAAAxH,OAAA3F,QAAA,iBACAiN,EAAAQ,KAAA9H,OAAA3F,QAAA,kBACA2O,WAMA1B,EAAAsB,OAAAS,EAAA,GAAuB/B,EAAAqB,IAAA,CACvBf,QAAA,gFACAG,MAAA,0EAOAT,EAAAoB,SAAAW,EAAA,GAAyB/B,EAAAmB,OAAA,CACzB3E,KAAAiF,EACA,8IAGA1O,QAAA,UAAAiN,EAAA8B,UACA/O,QAAA,4KAIA2O,WACApF,IAAA,sEA4BAsE,EAAAM,MAAAlB,EAMAY,EAAAoB,IAAA,SAAAjH,EAAA8F,GAEA,OADA,IAAAD,EAAAC,GACAmB,IAAAjH,IAOA6F,EAAArP,UAAAyQ,IAAA,SAAAjH,GAOA,OANAA,IACAhI,QAAA,iBACAA,QAAA,cACAA,QAAA,eACAA,QAAA,gBAEApB,KAAAiD,MAAAmG,GAAA,IAOA6F,EAAArP,UAAAqD,MAAA,SAAAmG,EAAAkH,GAEA,IAAAC,EACAC,EACAC,EACAC,EACAC,EACAV,EACAW,EACAC,EACAC,EACAC,EACAzO,EACAiG,EACAyI,EACAC,EACAC,EACAC,EAEA,IAlBA/H,IAAAhI,QAAA,aAkBAgI,GAYA,IAVAqH,EAAAzQ,KAAAuP,MAAAjB,QAAAnH,KAAAiC,MACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAkK,EAAA,GAAAlK,OAAA,GACAvG,KAAAY,OAAAgH,KAAA,CACA9G,KAAA,WAMA2P,EAAAzQ,KAAAuP,MAAA1K,KAAAsC,KAAAiC,GACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAkK,IAAA,GAAArP,QAAA,UAAiC,IACjCpB,KAAAY,OAAAgH,KAAA,CACA9G,KAAA,OACA+E,KAAA7F,KAAAkP,QAAAO,SAEAgB,EADAY,EAAAZ,EAAA,aAOA,GAAAA,EAAAzQ,KAAAuP,MAAAhB,OAAApH,KAAAiC,GACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAvG,KAAAY,OAAAgH,KAAA,CACA9G,KAAA,OACAT,KAAAoQ,EAAA,GACA5K,KAAA4K,EAAA,cAMA,GAAAA,EAAAzQ,KAAAuP,MAAAb,QAAAvH,KAAAiC,GACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAvG,KAAAY,OAAAgH,KAAA,CACA9G,KAAA,UACAwQ,MAAAb,EAAA,GAAAlK,OACAV,KAAA4K,EAAA,UAMA,GAAAH,IAAAG,EAAAzQ,KAAAuP,MAAAZ,QAAAxH,KAAAiC,MACA6G,EAAA,CACAnP,KAAA,QACAyQ,OAAAC,EAAAf,EAAA,GAAArP,QAAA,oBACAqQ,MAAAhB,EAAA,GAAArP,QAAA,iBAAAsQ,MAAA,UACAC,MAAAlB,EAAA,GAAAA,EAAA,GAAArP,QAAA,UAAAsQ,MAAA,WAGAH,OAAAhL,SAAA0J,EAAAwB,MAAAlL,OARA,CAWA,IAFA6C,IAAAgI,UAAAX,EAAA,GAAAlK,QAEAjE,EAAA,EAAmBA,EAAA2N,EAAAwB,MAAAlL,OAAuBjE,IAC1C,YAAAkC,KAAAyL,EAAAwB,MAAAnP,IACA2N,EAAAwB,MAAAnP,GAAA,QACW,aAAAkC,KAAAyL,EAAAwB,MAAAnP,IACX2N,EAAAwB,MAAAnP,GAAA,SACW,YAAAkC,KAAAyL,EAAAwB,MAAAnP,IACX2N,EAAAwB,MAAAnP,GAAA,OAEA2N,EAAAwB,MAAAnP,GAAA,KAIA,IAAAA,EAAA,EAAmBA,EAAA2N,EAAA0B,MAAApL,OAAuBjE,IAC1C2N,EAAA0B,MAAArP,GAAAkP,EAAAvB,EAAA0B,MAAArP,GAAA2N,EAAAsB,OAAAhL,QAGAvG,KAAAY,OAAAgH,KAAAqI,QAOA,GAAAQ,EAAAzQ,KAAAuP,MAAAd,GAAAtH,KAAAiC,GACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAvG,KAAAY,OAAAgH,KAAA,CACA9G,KAAA,YAMA,GAAA2P,EAAAzQ,KAAAuP,MAAAX,WAAAzH,KAAAiC,GACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QAEAvG,KAAAY,OAAAgH,KAAA,CACA9G,KAAA,qBAGA2P,IAAA,GAAArP,QAAA,eAKApB,KAAAiD,MAAAwN,EAAAH,GAEAtQ,KAAAY,OAAAgH,KAAA,CACA9G,KAAA,wBAOA,GAAA2P,EAAAzQ,KAAAuP,MAAAV,KAAA1H,KAAAiC,GAAA,CAsBA,IArBAA,IAAAgI,UAAAX,EAAA,GAAAlK,QAIAqK,EAAA,CACA9P,KAAA,aACA8Q,QAJAX,GADAP,EAAAD,EAAA,IACAlK,OAAA,EAKAsL,MAAAZ,GAAAP,EAAA,GACAF,OAAA,GAGAxQ,KAAAY,OAAAgH,KAAAgJ,GAKAC,EAAA,GACAN,GAAA,EACAS,GAJAP,IAAA,GAAAxQ,MAAAD,KAAAuP,MAAAU,OAIA1J,OACAjE,EAAA,EAEYA,EAAA0O,EAAO1O,IAKnByO,GAJAd,EAAAQ,EAAAnO,IAIAiE,SACA0J,IAAA7O,QAAA,0BAIA0Q,QAAA,SACAf,GAAAd,EAAA1J,OACA0J,EAAAjQ,KAAAkP,QAAAO,SAEAQ,EAAA7O,QAAA,YAAmC,IADnC6O,EAAA7O,QAAA,IAAA0F,OAAA,QAA0CiK,EAAA,IAAgB,WAM1D/Q,KAAAkP,QAAA6C,YAAAzP,IAAA0O,EAAA,IAEAN,KADAC,EAAAtC,EAAA2B,OAAA7I,KAAAsJ,EAAAnO,EAAA,SACAoO,EAAAnK,OAAA,GAAAoK,EAAApK,OAAA,IACA6C,EAAAqH,EAAAhP,MAAAa,EAAA,GAAAgG,KAAA,MAAAc,EACA9G,EAAA0O,EAAA,IAOAR,EAAAD,GAAA,eAAA/L,KAAAyL,GACA3N,IAAA0O,EAAA,IACAT,EAAA,OAAAN,EAAA+B,OAAA/B,EAAA1J,OAAA,GACAiK,MAAAD,IAGAC,IACAI,EAAAJ,OAAA,GAKAW,OAAAc,GADAf,EAAA,cAAA1M,KAAAyL,MAGAkB,EAAA,MAAAlB,EAAA,GACAA,IAAA7O,QAAA,oBAGA0P,EAAA,CACAhQ,KAAA,kBACAoR,KAAAhB,EACAiB,QAAAhB,EACAX,SAGAK,EAAAjJ,KAAAkJ,GACA9Q,KAAAY,OAAAgH,KAAAkJ,GAGA9Q,KAAAiD,MAAAgN,GAAA,GAEAjQ,KAAAY,OAAAgH,KAAA,CACA9G,KAAA,kBAIA,GAAA8P,EAAAJ,MAGA,IAFAQ,EAAAH,EAAAtK,OACAjE,EAAA,EACcA,EAAA0O,EAAO1O,IACrBuO,EAAAvO,GAAAkO,OAAA,EAIAxQ,KAAAY,OAAAgH,KAAA,CACA9G,KAAA,kBAOA,GAAA2P,EAAAzQ,KAAAuP,MAAA1E,KAAA1D,KAAAiC,GACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAvG,KAAAY,OAAAgH,KAAA,CACA9G,KAAAd,KAAAkP,QAAAkD,SACA,YACA,OACAjF,KAAAnN,KAAAkP,QAAAmD,YACA,QAAA5B,EAAA,eAAAA,EAAA,cAAAA,EAAA,IACA5K,KAAA4K,EAAA,UAMA,GAAAH,IAAAG,EAAAzQ,KAAAuP,MAAA5E,IAAAxD,KAAAiC,IACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAkK,EAAA,KAAAA,EAAA,GAAAA,EAAA,GAAAW,UAAA,EAAAX,EAAA,GAAAlK,OAAA,IACAgC,EAAAkI,EAAA,GAAA9L,cAAAvD,QAAA,YACApB,KAAAY,OAAAuO,MAAA5G,KACAvI,KAAAY,OAAAuO,MAAA5G,GAAA,CACA6F,KAAAqC,EAAA,GACA6B,MAAA7B,EAAA,UAOA,GAAAH,IAAAG,EAAAzQ,KAAAuP,MAAAT,MAAA3H,KAAAiC,MACA6G,EAAA,CACAnP,KAAA,QACAyQ,OAAAC,EAAAf,EAAA,GAAArP,QAAA,oBACAqQ,MAAAhB,EAAA,GAAArP,QAAA,iBAAAsQ,MAAA,UACAC,MAAAlB,EAAA,GAAAA,EAAA,GAAArP,QAAA,qBAAAsQ,MAAA,WAGAH,OAAAhL,SAAA0J,EAAAwB,MAAAlL,OARA,CAWA,IAFA6C,IAAAgI,UAAAX,EAAA,GAAAlK,QAEAjE,EAAA,EAAmBA,EAAA2N,EAAAwB,MAAAlL,OAAuBjE,IAC1C,YAAAkC,KAAAyL,EAAAwB,MAAAnP,IACA2N,EAAAwB,MAAAnP,GAAA,QACW,aAAAkC,KAAAyL,EAAAwB,MAAAnP,IACX2N,EAAAwB,MAAAnP,GAAA,SACW,YAAAkC,KAAAyL,EAAAwB,MAAAnP,IACX2N,EAAAwB,MAAAnP,GAAA,OAEA2N,EAAAwB,MAAAnP,GAAA,KAIA,IAAAA,EAAA,EAAmBA,EAAA2N,EAAA0B,MAAApL,OAAuBjE,IAC1C2N,EAAA0B,MAAArP,GAAAkP,EACAvB,EAAA0B,MAAArP,GAAAlB,QAAA,uBACA6O,EAAAsB,OAAAhL,QAGAvG,KAAAY,OAAAgH,KAAAqI,QAOA,GAAAQ,EAAAzQ,KAAAuP,MAAAR,SAAA5H,KAAAiC,GACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAvG,KAAAY,OAAAgH,KAAA,CACA9G,KAAA,UACAwQ,MAAA,MAAAb,EAAA,OACA5K,KAAA4K,EAAA,UAMA,GAAAH,IAAAG,EAAAzQ,KAAAuP,MAAAP,UAAA7H,KAAAiC,IACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAvG,KAAAY,OAAAgH,KAAA,CACA9G,KAAA,YACA+E,KAAA,OAAA4K,EAAA,GAAAuB,OAAAvB,EAAA,GAAAlK,OAAA,GACAkK,EAAA,GAAAhP,MAAA,MACAgP,EAAA,UAMA,GAAAA,EAAAzQ,KAAAuP,MAAA1J,KAAAsB,KAAAiC,GAEAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAvG,KAAAY,OAAAgH,KAAA,CACA9G,KAAA,OACA+E,KAAA4K,EAAA,UAKA,GAAArH,EACA,UAAAmJ,MAAA,0BAAAnJ,EAAAoJ,WAAA,IAIA,OAAAxS,KAAAY,QAOA,IAAA6R,EAAA,CACAC,OAAA,+CACAC,SAAA,sCACAvH,IAAAoD,EACAjG,IAAA,2JAMAqK,KAAA,2CACAC,QAAA,wDACAC,OAAA,gEACAC,OAAA,8GACAC,GAAA,+LACAnO,KAAA,sCACAoO,GAAA,wBACAC,IAAA1E,EACA3I,KAAA,kDAsFA,SAAAsN,EAAAhE,EAAAD,GAOA,GANAlP,KAAAkP,WAAAG,EAAAC,SACAtP,KAAAmP,QACAnP,KAAAuP,MAAAkD,EAAAjD,OACAxP,KAAAoT,SAAApT,KAAAkP,QAAAkE,UAAA,IAAAC,EACArT,KAAAoT,SAAAlE,QAAAlP,KAAAkP,SAEAlP,KAAAmP,MACA,UAAAoD,MAAA,6CAGAvS,KAAAkP,QAAAO,SACAzP,KAAAuP,MAAAkD,EAAAhD,SACGzP,KAAAkP,QAAAQ,MACH1P,KAAAkP,QAAAoE,OACAtT,KAAAuP,MAAAkD,EAAAa,OAEAtT,KAAAuP,MAAAkD,EAAA/C,KAuQA,SAAA2D,EAAAnE,GACAlP,KAAAkP,WAAAG,EAAAC,SA6JA,SAAAiE,KAyBA,SAAAC,EAAAtE,GACAlP,KAAAY,OAAA,GACAZ,KAAAiD,MAAA,KACAjD,KAAAkP,WAAAG,EAAAC,SACAtP,KAAAkP,QAAAkE,SAAApT,KAAAkP,QAAAkE,UAAA,IAAAC,EACArT,KAAAoT,SAAApT,KAAAkP,QAAAkE,SACApT,KAAAoT,SAAAlE,QAAAlP,KAAAkP,QA4KA,SAAAwD,EAAA7H,EAAAlK,GACA,GAAAA,GACA,GAAA+R,EAAAe,WAAAjP,KAAAqG,GACA,OAAAA,EAAAzJ,QAAAsR,EAAAgB,cAAA,SAAAC,GAA+D,OAAAjB,EAAAkB,aAAAD,UAG/D,GAAAjB,EAAAmB,mBAAArP,KAAAqG,GACA,OAAAA,EAAAzJ,QAAAsR,EAAAoB,sBAAA,SAAAH,GAAuE,OAAAjB,EAAAkB,aAAAD,KAIvE,OAAA9I,EAgBA,SAAAkJ,EAAAlJ,GAEA,OAAAA,EAAAzJ,QAAA,6CAA8D,SAAAb,EAAAyT,GAE9D,iBADAA,IAAArP,eACA,IACA,MAAAqP,EAAAhC,OAAA,GACA,MAAAgC,EAAAhC,OAAA,GACAiC,OAAAC,aAAAC,SAAAH,EAAA5C,UAAA,QACA6C,OAAAC,cAAAF,EAAA5C,UAAA,IAEA,KAIA,SAAAtB,EAAA9D,EAAAoI,GAGA,OAFApI,IAAAjF,QAAAiF,EACAoI,KAAA,GACA,CACAhT,QAAA,SAAA+G,EAAAkM,GAIA,OAFAA,GADAA,IAAAtN,QAAAsN,GACAjT,QAAA,qBACA4K,IAAA5K,QAAA+G,EAAAkM,GACArU,MAEA+P,SAAA,WACA,WAAAjJ,OAAAkF,EAAAoI,KAKA,SAAAE,EAAAlC,EAAAmC,EAAAnG,GACA,GAAAgE,EAAA,CACA,IACA,IAAAoC,EAAAC,mBAAAV,EAAA3F,IACAhN,QAAA,cACAuD,cACK,MAAAzE,GACL,YAEA,OAAAsU,EAAA1C,QAAA,oBAAA0C,EAAA1C,QAAA,kBAAA0C,EAAA1C,QAAA,SACA,YAGAyC,IAAAG,EAAAlQ,KAAA4J,KACAA,EAUA,SAAAmG,EAAAnG,GACAuG,EAAA,IAAAJ,KAIA,oBAAA/P,KAAA+P,GACAI,EAAA,IAAAJ,KAAA,IAEAI,EAAA,IAAAJ,GAAAlD,EAAAkD,EAAA,SAKA,OAFAA,EAAAI,EAAA,IAAAJ,GAEA,OAAAnG,EAAA3M,MAAA,KACA8S,EAAAnT,QAAA,gBAAAgN,EACG,MAAAA,EAAA4D,OAAA,GACHuC,EAAAnT,QAAA,4BAAAgN,EAEAmG,EAAAnG,EA5BAwG,CAAAL,EAAAnG,IAEA,IACAA,EAAAyG,UAAAzG,GAAAhN,QAAA,YACG,MAAAlB,GACH,YAEA,OAAAkO,EAlyBAqE,EAAAqC,SAAA,+CAEArC,EAAAsC,QAAA,+BACAtC,EAAAuC,OAAA,gJACAvC,EAAAE,SAAA7C,EAAA2C,EAAAE,UACAvR,QAAA,SAAAqR,EAAAsC,SACA3T,QAAA,QAAAqR,EAAAuC,QACAjF,WAEA0C,EAAAwC,WAAA,8EAEAxC,EAAAlK,IAAAuH,EAAA2C,EAAAlK,KACAnH,QAAA,UAAAiN,EAAA8B,UACA/O,QAAA,YAAAqR,EAAAwC,YACAlF,WAEA0C,EAAA7C,OAAA,iDACA6C,EAAAyC,MAAA,uFACAzC,EAAA5C,OAAA,8DAEA4C,EAAAG,KAAA9C,EAAA2C,EAAAG,MACAxR,QAAA,QAAAqR,EAAA7C,QACAxO,QAAA,OAAAqR,EAAAyC,OACA9T,QAAA,QAAAqR,EAAA5C,QACAE,WAEA0C,EAAAI,QAAA/C,EAAA2C,EAAAI,SACAzR,QAAA,QAAAqR,EAAA7C,QACAG,WAMA0C,EAAAjD,OAAAY,EAAA,GAAwBqC,GAMxBA,EAAAhD,SAAAW,EAAA,GAA0BqC,EAAAjD,OAAA,CAC1BuD,OAAA,iEACAC,GAAA,2DACAJ,KAAA9C,EAAA,2BACA1O,QAAA,QAAAqR,EAAA7C,QACAG,WACA8C,QAAA/C,EAAA,iCACA1O,QAAA,QAAAqR,EAAA7C,QACAG,aAOA0C,EAAA/C,IAAAU,EAAA,GAAqBqC,EAAAjD,OAAA,CACrBkD,OAAA5C,EAAA2C,EAAAC,QAAAtR,QAAA,aAAA2O,WACAoF,gBAAA,4EACA/J,IAAA,mEACAgK,WAAA,yEACAlC,IAAA,0BACArN,KAAAiK,EAAA2C,EAAA5M,MACAzE,QAAA,YACAA,QAAA,uEACA2O,aAGA0C,EAAA/C,IAAAtE,IAAA0E,EAAA2C,EAAA/C,IAAAtE,KACAhK,QAAA,QAAAqR,EAAA/C,IAAAyF,iBACApF,WAKA0C,EAAAa,OAAAlD,EAAA,GAAwBqC,EAAA/C,IAAA,CACxBuD,GAAAnD,EAAA2C,EAAAQ,IAAA7R,QAAA,OAAmC,KAAA2O,WACnClK,KAAAiK,EAAA2C,EAAA/C,IAAA7J,MAAAzE,QAAA,OAA2C,KAAA2O,aAiC3CoD,EAAA5D,MAAAkD,EAMAU,EAAAkC,OAAA,SAAAjM,EAAA+F,EAAAD,GAEA,OADA,IAAAiE,EAAAhE,EAAAD,GACAmG,OAAAjM,IAOA+J,EAAAvT,UAAAyV,OAAA,SAAAjM,GASA,IARA,IACAwJ,EACA/M,EACAuI,EACAkE,EACA7B,EACA6E,EANAC,EAAA,GAQAnM,GAEA,GAAAqH,EAAAzQ,KAAAuP,MAAAmD,OAAAvL,KAAAiC,GACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAgP,GAAA9E,EAAA,QAKA,GAAAA,EAAAzQ,KAAAuP,MAAAoD,SAAAxL,KAAAiC,GACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QAGA6H,EAFA,MAAAqC,EAAA,GAEA,WADA5K,EAAA6M,EAAA1S,KAAAwV,OAAA/E,EAAA,MAGA5K,EAAA6M,EAAAjC,EAAA,IAGA8E,GAAAvV,KAAAoT,SAAAR,KAAAxE,EAAA,KAAAvI,QAKA,GAAA7F,KAAAyV,UAAAhF,EAAAzQ,KAAAuP,MAAAnE,IAAAjE,KAAAiC,KAuBA,GAAAqH,EAAAzQ,KAAAuP,MAAAhH,IAAApB,KAAAiC,IACApJ,KAAAyV,QAAA,QAAAjR,KAAAiM,EAAA,IACAzQ,KAAAyV,QAAA,EACOzV,KAAAyV,QAAA,UAAAjR,KAAAiM,EAAA,MACPzQ,KAAAyV,QAAA,IAEAzV,KAAA0V,YAAA,iCAAAlR,KAAAiM,EAAA,IACAzQ,KAAA0V,YAAA,EACO1V,KAAA0V,YAAA,mCAAAlR,KAAAiM,EAAA,MACPzQ,KAAA0V,YAAA,GAGAtM,IAAAgI,UAAAX,EAAA,GAAAlK,QACAgP,GAAAvV,KAAAkP,QAAAkD,SACApS,KAAAkP,QAAAmD,UACArS,KAAAkP,QAAAmD,UAAA5B,EAAA,IACAiC,EAAAjC,EAAA,IACAA,EAAA,QAKA,GAAAA,EAAAzQ,KAAAuP,MAAAqD,KAAAzL,KAAAiC,GACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAvG,KAAAyV,QAAA,EACArH,EAAAqC,EAAA,GACAzQ,KAAAkP,QAAAO,UACAmD,EAAA,gCAAAzL,KAAAiH,KAGAA,EAAAwE,EAAA,GACAN,EAAAM,EAAA,IAEAN,EAAA,GAGAA,EAAA7B,EAAA,GAAAA,EAAA,GAAAhP,MAAA,SAEA2M,IAAAuH,OAAAvU,QAAA,sBACAmU,GAAAvV,KAAA4V,WAAAnF,EAAA,CACArC,KAAA+E,EAAA0C,QAAAzH,GACAkE,MAAAa,EAAA0C,QAAAvD,KAEAtS,KAAAyV,QAAA,OAKA,IAAAhF,EAAAzQ,KAAAuP,MAAAsD,QAAA1L,KAAAiC,MACAqH,EAAAzQ,KAAAuP,MAAAuD,OAAA3L,KAAAiC,IADA,CAKA,GAHAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAqM,GAAAnC,EAAA,IAAAA,EAAA,IAAArP,QAAA,cACAwR,EAAA5S,KAAAmP,MAAAyD,EAAAjO,kBACAiO,EAAAxE,KAAA,CACAmH,GAAA9E,EAAA,GAAAuB,OAAA,GACA5I,EAAAqH,EAAA,GAAAW,UAAA,GAAAhI,EACA,SAEApJ,KAAAyV,QAAA,EACAF,GAAAvV,KAAA4V,WAAAnF,EAAAmC,GACA5S,KAAAyV,QAAA,OAKA,GAAAhF,EAAAzQ,KAAAuP,MAAAwD,OAAA5L,KAAAiC,GACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAgP,GAAAvV,KAAAoT,SAAAL,OAAA/S,KAAAqV,OAAA5E,EAAA,IAAAA,EAAA,IAAAA,EAAA,IAAAA,EAAA,UAKA,GAAAA,EAAAzQ,KAAAuP,MAAAyD,GAAA7L,KAAAiC,GACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAgP,GAAAvV,KAAAoT,SAAAJ,GAAAhT,KAAAqV,OAAA5E,EAAA,IAAAA,EAAA,IAAAA,EAAA,IAAAA,EAAA,IAAAA,EAAA,IAAAA,EAAA,UAKA,GAAAA,EAAAzQ,KAAAuP,MAAA1K,KAAAsC,KAAAiC,GACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAgP,GAAAvV,KAAAoT,SAAA0C,SAAApD,EAAAjC,EAAA,GAAAkF,QAAA,SAKA,GAAAlF,EAAAzQ,KAAAuP,MAAA0D,GAAA9L,KAAAiC,GACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAgP,GAAAvV,KAAAoT,SAAAH,UAKA,GAAAxC,EAAAzQ,KAAAuP,MAAA2D,IAAA/L,KAAAiC,GACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAgP,GAAAvV,KAAAoT,SAAAF,IAAAlT,KAAAqV,OAAA5E,EAAA,UAKA,GAAAA,EAAAzQ,KAAAuP,MAAA1J,KAAAsB,KAAAiC,GACAA,IAAAgI,UAAAX,EAAA,GAAAlK,QACAvG,KAAA0V,WACAH,GAAAvV,KAAAoT,SAAAvN,KAAA4K,EAAA,IAEA8E,GAAAvV,KAAAoT,SAAAvN,KAAA6M,EAAA1S,KAAA+V,YAAAtF,EAAA,WAKA,GAAArH,EACA,UAAAmJ,MAAA,0BAAAnJ,EAAAoJ,WAAA,QAtIA,CACA,SAAA/B,EAAA,GAEArC,EAAA,WADAvI,EAAA6M,EAAAjC,EAAA,SAEO,CAEP,GACA6E,EAAA7E,EAAA,GACAA,EAAA,GAAAzQ,KAAAuP,MAAA6F,WAAAjO,KAAAsJ,EAAA,aACS6E,IAAA7E,EAAA,IACT5K,EAAA6M,EAAAjC,EAAA,IAEArC,EADA,SAAAqC,EAAA,GACA,UAAA5K,EAEAA,EAGAuD,IAAAgI,UAAAX,EAAA,GAAAlK,QACAgP,GAAAvV,KAAAoT,SAAAR,KAAAxE,EAAA,KAAAvI,GAwHA,OAAA0P,GAGApC,EAAA0C,QAAA,SAAAhQ,GACA,OAAAA,IAAAzE,QAAA+R,EAAA5D,MAAAuF,SAAA,MAAAjP,GAOAsN,EAAAvT,UAAAgW,WAAA,SAAAnF,EAAAmC,GACA,IAAAxE,EAAAwE,EAAAxE,KACAkE,EAAAM,EAAAN,MAAAI,EAAAE,EAAAN,OAAA,KAEA,YAAA7B,EAAA,GAAAuB,OAAA,GACAhS,KAAAoT,SAAAR,KAAAxE,EAAAkE,EAAAtS,KAAAqV,OAAA5E,EAAA,KACAzQ,KAAAoT,SAAA4C,MAAA5H,EAAAkE,EAAAI,EAAAjC,EAAA,MAOA0C,EAAAvT,UAAAmW,YAAA,SAAAlQ,GACA,OAAA7F,KAAAkP,QAAA6G,YACAlQ,EAEAzE,QAAA,YAEAA,QAAA,WAEAA,QAAA,2BAA8B,OAE9BA,QAAA,UAEAA,QAAA,gCAA8B,OAE9BA,QAAA,UAEAA,QAAA,SAAmB,KAfnByE,GAsBAsN,EAAAvT,UAAA4V,OAAA,SAAA3P,GACA,IAAA7F,KAAAkP,QAAAsG,OAAA,OAAA3P,EAMA,IALA,IAGA8N,EAHA4B,EAAA,GACAvE,EAAAnL,EAAAU,OACAjE,EAAA,EAGQA,EAAA0O,EAAO1O,IACfqR,EAAA9N,EAAA2M,WAAAlQ,GACA2T,KAAAC,SAAA,KACAvC,EAAA,IAAAA,EAAApS,SAAA,KAEAgU,GAAA,KAAA5B,EAAA,IAGA,OAAA4B,GAWAlC,EAAAzT,UAAAiF,KAAA,SAAAA,EAAAxE,EAAA8V,GACA,GAAAnW,KAAAkP,QAAAtJ,UAAA,CACA,IAAA2P,EAAAvV,KAAAkP,QAAAtJ,UAAAf,EAAAxE,GACA,MAAAkV,OAAA1Q,IACAsR,GAAA,EACAtR,EAAA0Q,GAIA,OAAAlV,EAMA,qBACAL,KAAAkP,QAAAkH,WACA1D,EAAArS,GAAA,GACA,MACA8V,EAAAtR,EAAA6N,EAAA7N,GAAA,IACA,kBAVA,eACAsR,EAAAtR,EAAA6N,EAAA7N,GAAA,IACA,iBAWAwO,EAAAzT,UAAAgP,WAAA,SAAAyH,GACA,uBAAAA,EAAA,mBAGAhD,EAAAzT,UAAAiL,KAAA,SAAAA,GACA,OAAAA,GAGAwI,EAAAzT,UAAA8O,QAAA,SAAA7I,EAAAyQ,EAAAC,GACA,OAAAvW,KAAAkP,QAAAsH,UACA,KACAF,EACA,QACAtW,KAAAkP,QAAAuH,aACAF,EAAA5R,cAAAvD,QAAA,eACA,KACAyE,EACA,MACAyQ,EACA,MAGA,KAAAA,EAAA,IAAAzQ,EAAA,MAAAyQ,EAAA,OAGAjD,EAAAzT,UAAA6O,GAAA,WACA,OAAAzO,KAAAkP,QAAAwH,MAAA,oBAGArD,EAAAzT,UAAAiP,KAAA,SAAA8H,EAAA/E,EAAAC,GACA,IAAA/Q,EAAA8Q,EAAA,UAEA,UAAA9Q,GADA8Q,GAAA,IAAAC,EAAA,WAAAA,EAAA,QACA,MAAA8E,EAAA,KAAA7V,EAAA,OAGAuS,EAAAzT,UAAAgX,SAAA,SAAA/Q,GACA,aAAAA,EAAA,WAGAwN,EAAAzT,UAAAiX,SAAA,SAAA1E,GACA,iBACAA,EAAA,kBACA,+BACAnS,KAAAkP,QAAAwH,MAAA,SACA,MAGArD,EAAAzT,UAAAoP,UAAA,SAAAnJ,GACA,YAAAA,EAAA,UAGAwN,EAAAzT,UAAAkP,MAAA,SAAAyC,EAAAoF,GAGA,OAFAA,MAAA,UAAAA,EAAA,YAEA,qBAEApF,EACA,aACAoF,EACA,cAGAtD,EAAAzT,UAAAkX,SAAA,SAAA/V,GACA,eAAAA,EAAA,WAGAsS,EAAAzT,UAAAmX,UAAA,SAAAhW,EAAA8F,GACA,IAAA/F,EAAA+F,EAAA0K,OAAA,UAIA,OAHA1K,EAAA4K,MACA,IAAA3Q,EAAA,WAAA+F,EAAA4K,MAAA,KACA,IAAA3Q,EAAA,KACAC,EAAA,KAAAD,EAAA,OAIAuS,EAAAzT,UAAAmT,OAAA,SAAAlN,GACA,iBAAAA,EAAA,aAGAwN,EAAAzT,UAAAoT,GAAA,SAAAnN,GACA,aAAAA,EAAA,SAGAwN,EAAAzT,UAAAkW,SAAA,SAAAjQ,GACA,eAAAA,EAAA,WAGAwN,EAAAzT,UAAAqT,GAAA,WACA,OAAAjT,KAAAkP,QAAAwH,MAAA,gBAGArD,EAAAzT,UAAAsT,IAAA,SAAArN,GACA,cAAAA,EAAA,UAGAwN,EAAAzT,UAAAgT,KAAA,SAAAxE,EAAAkE,EAAAzM,GAEA,WADAuI,EAAAkG,EAAAtU,KAAAkP,QAAAkD,SAAApS,KAAAkP,QAAA8H,QAAA5I,IAEA,OAAAvI,EAEA,IAAA0P,EAAA,YAAA7C,EAAAtE,GAAA,IAKA,OAJAkE,IACAiD,GAAA,WAAAjD,EAAA,KAEAiD,GAAA,IAAA1P,EAAA,QAIAwN,EAAAzT,UAAAoW,MAAA,SAAA5H,EAAAkE,EAAAzM,GAEA,WADAuI,EAAAkG,EAAAtU,KAAAkP,QAAAkD,SAAApS,KAAAkP,QAAA8H,QAAA5I,IAEA,OAAAvI,EAGA,IAAA0P,EAAA,aAAAnH,EAAA,UAAAvI,EAAA,IAKA,OAJAyM,IACAiD,GAAA,WAAAjD,EAAA,KAEAiD,GAAAvV,KAAAkP,QAAAwH,MAAA,UAIArD,EAAAzT,UAAAiG,KAAA,SAAAA,GACA,OAAAA,GAYA0N,EAAA3T,UAAAmT,OACAQ,EAAA3T,UAAAoT,GACAO,EAAA3T,UAAAkW,SACAvC,EAAA3T,UAAAsT,IACAK,EAAA3T,UAAAiG,KAAA,SAAAA,GACA,OAAAA,GAGA0N,EAAA3T,UAAAgT,KACAW,EAAA3T,UAAAoW,MAAA,SAAA5H,EAAAkE,EAAAzM,GACA,SAAAA,GAGA0N,EAAA3T,UAAAqT,GAAA,WACA,UAoBAO,EAAA1K,MAAA,SAAAM,EAAA8F,GAEA,OADA,IAAAsE,EAAAtE,GACApG,MAAAM,IAOAoK,EAAA5T,UAAAkJ,MAAA,SAAAM,GACApJ,KAAAyS,OAAA,IAAAU,EAAA/J,EAAA+F,MAAAnP,KAAAkP,SAEAlP,KAAAiX,WAAA,IAAA9D,EACA/J,EAAA+F,MACAiB,EAAA,GAAYpQ,KAAAkP,QAAA,CAAiBkE,SAAA,IAAAG,KAE7BvT,KAAAY,OAAAwI,EAAA8N,UAGA,IADA,IAAA3B,EAAA,GACAvV,KAAAuQ,QACAgF,GAAAvV,KAAAmX,MAGA,OAAA5B,GAOA/B,EAAA5T,UAAA2Q,KAAA,WACA,OAAAvQ,KAAAiD,MAAAjD,KAAAY,OAAAuI,OAOAqK,EAAA5T,UAAAwX,KAAA,WACA,OAAApX,KAAAY,OAAAZ,KAAAY,OAAA2F,OAAA,OAOAiN,EAAA5T,UAAAyX,UAAA,WAGA,IAFA,IAAAV,EAAA3W,KAAAiD,MAAA4C,KAEA,SAAA7F,KAAAoX,OAAAtW,MACA6V,GAAA,KAAA3W,KAAAuQ,OAAA1K,KAGA,OAAA7F,KAAAyS,OAAA4C,OAAAsB,IAOAnD,EAAA5T,UAAAuX,IAAA,WACA,OAAAnX,KAAAiD,MAAAnC,MACA,YACA,SAEA,SACA,OAAAd,KAAAoT,SAAA3E,KAEA,cACA,OAAAzO,KAAAoT,SAAA1E,QACA1O,KAAAyS,OAAA4C,OAAArV,KAAAiD,MAAA4C,MACA7F,KAAAiD,MAAAqO,MACAyC,EAAA/T,KAAAiX,WAAA5B,OAAArV,KAAAiD,MAAA4C,QAEA,WACA,OAAA7F,KAAAoT,SAAAvO,KAAA7E,KAAAiD,MAAA4C,KACA7F,KAAAiD,MAAA5C,KACAL,KAAAiD,MAAAkT,SAEA,YACA,IAEA7T,EACAgV,EACAC,EACAjR,EALAiL,EAAA,GACAoF,EAAA,GAQA,IADAY,EAAA,GACAjV,EAAA,EAAiBA,EAAAtC,KAAAiD,MAAAsO,OAAAhL,OAA8BjE,IAC/CiV,GAAAvX,KAAAoT,SAAA2D,UACA/W,KAAAyS,OAAA4C,OAAArV,KAAAiD,MAAAsO,OAAAjP,IACA,CAAWiP,QAAA,EAAAE,MAAAzR,KAAAiD,MAAAwO,MAAAnP,KAKX,IAFAiP,GAAAvR,KAAAoT,SAAA0D,SAAAS,GAEAjV,EAAA,EAAiBA,EAAAtC,KAAAiD,MAAA0O,MAAApL,OAA6BjE,IAAA,CAI9C,IAHAgV,EAAAtX,KAAAiD,MAAA0O,MAAArP,GAEAiV,EAAA,GACAjR,EAAA,EAAmBA,EAAAgR,EAAA/Q,OAAgBD,IACnCiR,GAAAvX,KAAAoT,SAAA2D,UACA/W,KAAAyS,OAAA4C,OAAAiC,EAAAhR,IACA,CAAaiL,QAAA,EAAAE,MAAAzR,KAAAiD,MAAAwO,MAAAnL,KAIbqQ,GAAA3W,KAAAoT,SAAA0D,SAAAS,GAEA,OAAAvX,KAAAoT,SAAAtE,MAAAyC,EAAAoF,GAEA,uBAGA,IAFAA,EAAA,GAEA,mBAAA3W,KAAAuQ,OAAAzP,MACA6V,GAAA3W,KAAAmX,MAGA,OAAAnX,KAAAoT,SAAAxE,WAAA+H,GAEA,iBACAA,EAAA,GAIA,IAHA,IAAA/E,EAAA5R,KAAAiD,MAAA2O,QACAC,EAAA7R,KAAAiD,MAAA4O,MAEA,aAAA7R,KAAAuQ,OAAAzP,MACA6V,GAAA3W,KAAAmX,MAGA,OAAAnX,KAAAoT,SAAAvE,KAAA8H,EAAA/E,EAAAC,GAEA,sBACA8E,EAAA,GACA,IAAAnG,EAAAxQ,KAAAiD,MAAAuN,MAMA,IAJAxQ,KAAAiD,MAAAiP,OACAyE,GAAA3W,KAAAoT,SAAAyD,SAAA7W,KAAAiD,MAAAkP,UAGA,kBAAAnS,KAAAuQ,OAAAzP,MACA6V,GAAAnG,GAAA,SAAAxQ,KAAAiD,MAAAnC,KAEAd,KAAAmX,MADAnX,KAAAqX,YAIA,OAAArX,KAAAoT,SAAAwD,SAAAD,GAEA,WAEA,OAAA3W,KAAAoT,SAAAvI,KAAA7K,KAAAiD,MAAA4C,MAEA,gBACA,OAAA7F,KAAAoT,SAAApE,UAAAhP,KAAAyS,OAAA4C,OAAArV,KAAAiD,MAAA4C,OAEA,WACA,OAAA7F,KAAAoT,SAAApE,UAAAhP,KAAAqX,eAuBA3E,EAAAe,WAAA,UACAf,EAAAgB,cAAA,WACAhB,EAAAkB,aAAA,CACA4D,IAAA,QACAC,IAAA,OACAC,IAAA,OACAC,IAAA,SACAC,IAAA,SAGAlF,EAAAmB,mBAAA,qBACAnB,EAAAoB,sBAAA,sBA6EA,IAAAa,EAAA,GACAD,EAAA,gCAEA,SAAAlG,KAGA,SAAA4B,EAAAzO,GAKA,IAJA,IACAyE,EACAlE,EAFAI,EAAA,EAIQA,EAAAuV,UAAAtR,OAAsBjE,IAE9B,IAAAJ,KADAkE,EAAAyR,UAAAvV,GAEAhB,OAAA1B,UAAAuC,eAAAX,KAAA4E,EAAAlE,KACAP,EAAAO,GAAAkE,EAAAlE,IAKA,OAAAP,EAGA,SAAA6P,EAAAsG,EAAAC,GAGA,IAaApG,EAbAmG,EAAA1W,QAAA,eAAAnB,EAAA+X,EAAA/Q,GAGA,IAFA,IAAAkP,GAAA,EACA8B,EAAAD,IACAC,GAAA,UAAAhR,EAAAgR,IAAA9B,KACA,OAAAA,EAGA,IAGA,OAGAzE,MAAA,OACApP,EAAA,EAEA,GAAAqP,EAAApL,OAAAwR,EACApG,EAAA7J,OAAAiQ,QAEA,KAAApG,EAAApL,OAAAwR,GAAApG,EAAA/J,KAAA,IAGA,KAAQtF,EAAAqP,EAAApL,OAAkBjE,IAE1BqP,EAAArP,GAAAqP,EAAArP,GAAAqT,OAAAvU,QAAA,aAEA,OAAAuQ,EAMA,SAAAN,EAAApK,EAAAiR,EAAAC,GACA,OAAAlR,EAAAV,OACA,SAOA,IAHA,IAAA6R,EAAA,EAGAA,EAAAnR,EAAAV,QAAA,CACA,IAAA8R,EAAApR,EAAA+K,OAAA/K,EAAAV,OAAA6R,EAAA,GACA,GAAAC,IAAAH,GAAAC,EAEK,IAAAE,IAAAH,IAAAC,EAGL,MAFAC,SAFAA,IAQA,OAAAnR,EAAAqR,OAAA,EAAArR,EAAAV,OAAA6R,GAOA,SAAA/I,EAAAjG,EAAAgL,EAAA/Q,GAEA,SAAA+F,EACA,UAAAmJ,MAAA,kDAEA,oBAAAnJ,EACA,UAAAmJ,MAAA,wCACAjR,OAAA1B,UAAA2B,SAAAC,KAAA4H,GAAA,qBAGA,GAAA/F,GAAA,mBAAA+Q,EAAA,CACA/Q,IACAA,EAAA+Q,EACAA,EAAA,MAKA,IACAxT,EACA2X,EAFA3S,GAFAwO,EAAAhE,EAAA,GAAkBf,EAAAC,SAAA8E,GAAA,KAElBxO,UAGAtD,EAAA,EAEA,IACA1B,EAAAqO,EAAAoB,IAAAjH,EAAAgL,GACK,MAAAlU,GACL,OAAAmD,EAAAnD,GAGAqY,EAAA3X,EAAA2F,OAEA,IAAAiS,EAAA,SAAAC,GACA,GAAAA,EAEA,OADArE,EAAAxO,YACAvC,EAAAoV,GAGA,IAAAlD,EAEA,IACAA,EAAA/B,EAAA1K,MAAAlI,EAAAwT,GACO,MAAAlU,GACPuY,EAAAvY,EAKA,OAFAkU,EAAAxO,YAEA6S,EACApV,EAAAoV,GACApV,EAAA,KAAAkS,IAGA,IAAA3P,KAAAW,OAAA,EACA,OAAAiS,IAKA,UAFApE,EAAAxO,WAEA2S,EAAA,OAAAC,IAEA,KAAUlW,EAAA1B,EAAA2F,OAAmBjE,KAC7B,SAAAW,GACA,SAAAA,EAAAnC,OACAyX,GAAAC,IAEA5S,EAAA3C,EAAA4C,KAAA5C,EAAA5C,KAAA,SAAAoY,EAAA5T,GACA,OAAA4T,EAAAD,EAAAC,GACA,MAAA5T,OAAA5B,EAAA4C,OACA0S,GAAAC,KAEAvV,EAAA4C,KAAAhB,EACA5B,EAAAkT,SAAA,SACAoC,GAAAC,QAXA,CAaO5X,EAAA0B,SAKP,IAEA,OADA8R,MAAAhE,EAAA,GAA2Bf,EAAAC,SAAA8E,IAC3BZ,EAAA1K,MAAAmG,EAAAoB,IAAAjH,EAAAgL,MACG,MAAAlU,GAEH,GADAA,EAAA2I,SAAA,+DACAuL,GAAA/E,EAAAC,UAAAoJ,OACA,uCACAhG,EAAAxS,EAAA2I,QAAA,OACA,SAEA,MAAA3I,GA1KAsO,EAAArH,KAAAqH,EAkLAa,EAAAH,QACAG,EAAAsJ,WAAA,SAAAvE,GAEA,OADAhE,EAAAf,EAAAC,SAAA8E,GACA/E,GAGAA,EAAAuJ,YAAA,WACA,OACA5B,QAAA,KACA1D,QAAA,EACA5D,KAAA,EACA8G,WAAA,EACAC,aAAA,GACA7Q,UAAA,KACAwQ,WAAA,YACAZ,QAAA,EACA/F,UAAA,EACA2D,SAAA,IAAAC,EACAjB,UAAA,EACAC,UAAA,KACAqG,QAAA,EACA3G,YAAA,EACAgE,aAAA,EACApG,QAAA,EACA+G,OAAA,IAIArH,EAAAC,SAAAD,EAAAuJ,cAMAvJ,EAAAmE,SACAnE,EAAAwJ,OAAArF,EAAA1K,MAEAuG,EAAAgE,WACAhE,EAAAkE,eAEAlE,EAAAJ,QACAI,EAAAyJ,MAAA7J,EAAAoB,IAEAhB,EAAA8D,cACA9D,EAAA0J,YAAA5F,EAAAkC,OAEAhG,EAAAvG,MAAAuG,EAGAzF,EAAAC,QAAAwF,EAjkDC,CAukDArP,MAAA,oBAAAuJ,wDC7kDD,IAAAyP,EAAAC,GAUA,WA6DA,IAqCArS,EA6uCAsS,EAwBAC,EAWA9W,EACA+W,EAQAC,EACAC,EACAC,EACAC,EAEAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EAEAC,EACAC,EAEAC,EAEAC,EACAC,EAEAC,EACAC,EACAC,EAt1CAC,EAAA,SAAAC,GACA,IAAAC,EAAA,IAAAF,EAAAG,MAUA,OARAD,EAAAE,SAAA3S,IACAuS,EAAAK,QACAL,EAAAM,eACAN,EAAAO,SAGAN,KAAAlZ,KAAAmZ,KAEAA,GAGAF,EAAAQ,QAAA,QAIAC,KAAAT,EAWAA,EAAAU,MAAA,GAQAV,EAAAU,MAAAC,MAAAxU,EAMC5G,KALD,SAAA6I,GACAjC,EAAAyU,iBAAAD,MACAC,QAAAD,KAAAvS,KAgBA4R,EAAAU,MAAA5Z,SAAA,SAAAI,GACA,OAAAA,QACA,GAGAA,EAAAJ,YAiBAkZ,EAAAa,aAAA,WACAtb,KAAAub,OAAA,IAYAd,EAAAa,aAAA1b,UAAA4b,YAAA,WACA,IAAA7T,EAAA1G,MAAArB,UAAA6B,MAAAD,KAAAqW,WACA4D,EAAA9T,EAAAwB,MACAuS,EAAA/T,EAEA,sBAAA8T,EAAA,UAAAE,UAAA,oCAEAD,EAAAtZ,QAAA,SAAA+F,GACAnI,KAAA4b,WAAAzT,KAAAnI,KAAAub,OAAApT,GAAA,IACAnI,KAAAub,OAAApT,GAAAP,KAAA6T,IACGzb,OAUHya,EAAAa,aAAA1b,UAAAic,eAAA,SAAA1T,EAAAsT,GACA,GAAAzb,KAAA4b,WAAAzT,GAAA,CAEA,IAAA2T,EAAA9b,KAAAub,OAAApT,GAAA2J,QAAA2J,IACA,IAAAK,IAEA9b,KAAAub,OAAApT,GAAAL,OAAAgU,EAAA,GAEA,GAAA9b,KAAAub,OAAApT,GAAA5B,eAAAvG,KAAAub,OAAApT,MAYAsS,EAAAa,aAAA1b,UAAAmc,KAAA,SAAA5T,GACA,GAAAnI,KAAA4b,WAAAzT,GAAA,CAEA,IAAAR,EAAA1G,MAAArB,UAAA6B,MAAAD,KAAAqW,UAAA,GAEA7X,KAAAub,OAAApT,GAAA/F,QAAA,SAAAqZ,GACAA,EAAA1T,WAAAkK,EAAAtK,IACG3H,QAUHya,EAAAa,aAAA1b,UAAAgc,WAAA,SAAAzT,GACA,OAAAA,KAAAnI,KAAAub,QAqBAd,EAAAuB,UAAA,SAAA/U,GACA,IAAA4Q,UAAAtR,QAAA,MAAAU,EAAA,SACA,GAAAhG,MAAAC,QAAA+F,GAAA,CACA,IAAAgV,EAAAhV,EAAAiV,OAAA,SAAAjZ,GACA,OAAAA,UAOAgZ,IAAA9a,IAAA,SAAA2P,GACA,OAAA2J,EAAAU,MAAA5Z,SAAAuP,GAAAnM,gBAGA,IAAA4Q,EAAA,GAMA,OALA0G,EAAA7Z,QAAA,SAAA6N,GACA,IAAArP,EAAAqP,EAAAyB,MAAA+I,EAAAuB,UAAAG,WACA5G,IAAA6G,OAAAxb,IACKZ,MAELuV,EAGA,OAAAtO,EAAA1F,WAAAoU,OAAAhR,cAAA+M,MAAA+I,EAAAuB,UAAAG,YAMA1B,EAAAuB,UAAAK,iBAAA,UASA5B,EAAAuB,UAAAG,UAAA1B,EAAAuB,UAAAK,iBAOA5B,EAAAuB,UAAAM,aAAA,SAAAC,GACAA,SAAA,qBACA9B,EAAAuB,UAAAG,UAAAI,IAQA9B,EAAAuB,UAAAQ,eAAA,WACA/B,EAAAuB,UAAAG,UAAA1B,EAAAuB,UAAAK,kBAOA5B,EAAAuB,UAAAS,aAAA,WACA,OAAAhC,EAAAuB,UAAAG,WAkCA1B,EAAAiC,SAAA,WACA1c,KAAA2c,OAAA,IAGAlC,EAAAiC,SAAAE,oBAAA,GAeAnC,EAAAiC,SAAAG,iBAAA,SAAApB,EAAAqB,GACAA,KAAArC,EAAAiC,SAAAE,qBACAnC,EAAAU,MAAAC,KAAA,6CAAA0B,GAGArB,EAAAqB,QACArC,EAAAiC,SAAAE,oBAAAE,GAAArB,GAUAhB,EAAAiC,SAAAK,sBAAA,SAAAD,GACA,OAAAA,KAAArC,EAAAiC,SAAAE,sBAAA,EACA,KAGAnC,EAAAiC,SAAAE,oBAAAE,IAUArC,EAAAiC,SAAAM,4BAAA,SAAAvB,GACAA,EAAAqB,OAAArB,EAAAqB,SAAA9c,KAAA4c,qBAGAnC,EAAAU,MAAAC,KAAA,kGAAAK,IAeAhB,EAAAiC,SAAAO,KAAA,SAAAC,GACA,IAAArC,EAAA,IAAAJ,EAAAiC,SAYA,OAVAQ,EAAA9a,QAAA,SAAA+a,GACA,IAAA1B,EAAAhB,EAAAiC,SAAAK,sBAAAI,GAEA,IAAA1B,EAGA,UAAAlJ,MAAA,uCAAA4K,GAFAtC,EAAA3S,IAAAuT,KAMAZ,GAWAJ,EAAAiC,SAAA9c,UAAAsI,IAAA,WACAjH,MAAArB,UAAA6B,MAAAD,KAAAqW,WAEAzV,QAAA,SAAAqZ,GACAhB,EAAAiC,SAAAM,4BAAAvB,GACAzb,KAAA2c,OAAA/U,KAAA6T,IACGzb,OAcHya,EAAAiC,SAAA9c,UAAA8H,MAAA,SAAA0V,EAAAC,GACA5C,EAAAiC,SAAAM,4BAAAK,GAEA,IAAArW,EAAAhH,KAAA2c,OAAA7K,QAAAsL,GACA,QAAApW,EACA,UAAAuL,MAAA,0BAGAvS,KAAA2c,OAAA7U,OAAAd,EAAA,IAAAqW,IAcA5C,EAAAiC,SAAA9c,UAAAgD,OAAA,SAAAwa,EAAAC,GACA5C,EAAAiC,SAAAM,4BAAAK,GAEA,IAAArW,EAAAhH,KAAA2c,OAAA7K,QAAAsL,GACA,QAAApW,EACA,UAAAuL,MAAA,0BAGAvS,KAAA2c,OAAA7U,OAAAd,EAAA,EAAAqW,IASA5C,EAAAiC,SAAA9c,UAAA0d,OAAA,SAAA7B,GACA,IAAAzU,EAAAhH,KAAA2c,OAAA7K,QAAA2J,IACA,IAAAzU,GAIAhH,KAAA2c,OAAA7U,OAAAd,EAAA,IAWAyT,EAAAiC,SAAA9c,UAAAqE,IAAA,SAAArD,GAKA,IAJA,IAAA2U,EAAA,GACAgI,EAAA3c,EAAA2F,OACAiX,EAAAxd,KAAA2c,OAAApW,OAEAjE,EAAA,EAAiBA,EAAAib,EAAiBjb,IAAA,CAGlC,IAFA,IAAAW,EAAArC,EAAA0B,GAEAgE,EAAA,EAAmBA,EAAAkX,GAEnBva,OADAA,EAAAjD,KAAA2c,OAAArW,GAAArD,EAAAX,EAAA1B,IADuC0F,KAKvCrD,SAAAsS,EAAA3N,KAAA3E,GAGA,OAAAsS,GAQAkF,EAAAiC,SAAA9c,UAAA6d,MAAA,WACAzd,KAAA2c,OAAA,IAQAlC,EAAAiC,SAAA9c,UAAAG,IAAA,WACA,OAAAC,KAAA2c,QAcAlC,EAAAiC,SAAA9c,UAAA8d,OAAA,WACA,OAAA1d,KAAA2c,OAAAxb,IAAA,SAAAsa,GAEA,OADAhB,EAAAiC,SAAAM,4BAAAvB,GACAA,EAAAqB,SAgBArC,EAAAG,MAAA,WACA5a,KAAA2d,QAAA,GACA3d,KAAA4d,KAAA,KACA5d,KAAA6a,SAAA,IAAAJ,EAAAiC,SACA1c,KAAA6d,cAAA,IAAApD,EAAAqD,cACA9d,KAAAiG,MAAA,GACAjG,KAAA+d,aAAA,IAAAtD,EAAAa,aACAtb,KAAAge,UAAA,GAEAhe,KAAAie,GAAA,mCACAje,KAAAge,UAAA,IACGE,KAAAle,QAYHya,EAAAG,MAAAhb,UAAAqe,GAAA,WACA,IAAAtW,EAAA1G,MAAArB,UAAA6B,MAAAD,KAAAqW,WACA,OAAA7X,KAAA+d,aAAAvC,YAAAzT,MAAA/H,KAAA+d,aAAApW,IAUA8S,EAAAG,MAAAhb,UAAAue,IAAA,SAAAhW,EAAAsT,GACA,OAAAzb,KAAA+d,aAAAlC,eAAA1T,EAAAsT,IAaAhB,EAAAG,MAAAqC,KAAA,SAAAmB,GACAA,EAAAnD,UAAAR,EAAAQ,SACAR,EAAAU,MAAAC,KAAA,6BACAX,EAAAQ,QAAA,cAAAmD,EAAAnD,SAGA,IAAAN,EAAA,IAAA3a,KAOA,QAAAqe,KALA1D,EAAAgD,QAAAS,EAAAE,OACA3D,EAAAiD,KAAAQ,EAAAG,IACA5D,EAAAkD,cAAApD,EAAAqD,cAAAb,KAAAmB,EAAAP,eACAlD,EAAAE,SAAAJ,EAAAiC,SAAAO,KAAAmB,EAAAvD,UACAF,EAAA1U,MAAA,GACAmY,EAAAnY,MACA0U,EAAA1U,MAAAoY,GAAA5D,EAAA+D,cAAAvB,KAAAmB,EAAAnY,MAAAoY,IAGA,OAAA1D,GAgBAF,EAAAG,MAAAhb,UAAA6e,SAAA,SAAAC,GAGA,OAFA1e,KAAA2d,QAAA/V,KAAA8W,GACA1e,KAAAiG,MAAAyY,GAAA,IAAAjE,EAAA+D,cACAxe,MAgBAya,EAAAG,MAAAhb,UAAA+e,OAAA,SAAAC,GAEA,OADA5e,KAAA4d,KAAAgB,EACA5e,MAaAya,EAAAG,MAAAhb,UAAAif,aAAA,SAAAC,GAEA,OADA9e,KAAA6d,cAAA,IAAApD,EAAAqD,cAAAgB,GACA9e,MAkBAya,EAAAG,MAAAhb,UAAAmf,OAAA,SAAAC,EAAAC,GACA,GAAAD,EAAA,CACAC,OAAAhN,IAAAgN,KAAA,IAEAC,EAAAF,EAAAhf,KAAA4d,MAEA5d,KAAA6d,cAAAkB,OAAAG,EAAAF,GACAhf,KAAA2d,QAAAvb,QAAA,SAAAic,GACA,IAAAc,EAAAnf,KAAA6a,SAAA5W,IAAAwW,EAAAuB,UAAAgD,EAAAX,KACAre,KAAA6d,cAAAuB,eAAAF,EAAAb,EAAAc,EAAA5Y,QAEA,IAAA8Y,EAAA,GAMA,QAAApc,KALAkc,EAAA/c,QAAA,SAAAa,GACAA,KAAAoc,IAAApc,IAAA,EACAoc,EAAApc,GAAA,GACKjD,MAELqf,EAAA,CACA,IAAAC,EAAAD,EAAApc,GACAqc,EAAArJ,KAAAsJ,KAAAD,GACAtf,KAAAiG,MAAAoY,GAAAmB,SAAAvc,EAAA,CAAyCsb,IAAAW,EAAAO,GAAAH,MAEtCtf,MAEHif,GAAAjf,KAAA+d,aAAAhC,KAAA,MAAAiD,EAAAhf,QAmBAya,EAAAG,MAAAhb,UAAA8f,eAAA,SAAAR,EAAAD,GACA,GAAAC,IACA,IAAAlf,KAAA6d,cAAA8B,eAIA3f,KAAA6d,cAAA+B,OAAAV,GAAA,CACA,IAAAF,EAAAhf,KAAA6d,cAAAgC,OAAAX,GACAlf,KAAA8f,UAAAd,GAAA,KAmBAvE,EAAAG,MAAAhb,UAAAkgB,UAAA,SAAAd,EAAAC,GACA,GAAAD,EAAA,CAEAC,OAAAhN,IAAAgN,KAAA,IAEAC,EAAAF,EAAAhf,KAAA4d,MACA5d,KAAA6d,cAAA+B,OAAAV,KAEAlf,KAAA6d,cAAAiC,UAAAZ,GAEAlf,KAAA2d,QAAAvb,QAAA,SAAAic,GACAre,KAAA6a,SAAA5W,IAAAwW,EAAAuB,UAAAgD,EAAAX,KACAjc,QAAA,SAAAa,GACAjD,KAAAiG,MAAAoY,GAAA0B,YAAA9c,EAAAic,IACKlf,OACFA,MAEHif,GAAAjf,KAAA+d,aAAAhC,KAAA,SAAAiD,EAAAhf,SAuBAya,EAAAG,MAAAhb,UAAAogB,UAAA,SAAAhB,EAAAC,GACAA,OAAAhN,IAAAgN,KAEAjf,KAAA0f,eAAAV,EAAAhf,KAAA4d,OAAA,GACA5d,KAAA+e,OAAAC,GAAA,GAEAC,GAAAjf,KAAA+d,aAAAhC,KAAA,SAAAiD,EAAAhf,OAYAya,EAAAG,MAAAhb,UAAAqgB,IAAA,SAAAC,EAAA7B,GACA,IAAA8B,EAAA,IAAA9B,EAAA,IAAA6B,EACA,GAAA5e,OAAA1B,UAAAuC,eAAAX,KAAAxB,KAAAge,UAAAmC,GAAA,OAAAngB,KAAAge,UAAAmC,GAEA,IAAAC,EAAApgB,KAAAiG,MAAAoY,GAAAgC,WAAAH,GACAD,EAAA,EAAAhK,KAAAqK,IAAAtgB,KAAA6d,cAAAtX,QAAA6Z,EAAA,IAGA,OAFApgB,KAAAge,UAAAmC,GAAAF,EAEAA,GAQAxF,EAAAG,MAAAhb,UAAA2gB,UAAA,WACA,OAAAvgB,KAAA2d,QAAAlc,SA4BAgZ,EAAAG,MAAAhb,UAAA4gB,OAAA,SAAAC,EAAAC,GACA,IAAAD,EAAA,SAEA,IAAAE,EAAA,KACA,MAAAD,IACAC,EAAAlb,KAAAC,UAAAgb,IAGA,IAAAhG,EAAA,IAAAD,EAAAmG,cAAAD,EAAA3gB,KAAAugB,aAAAxgB,MAEA8gB,EAAA7gB,KAAA6a,SAAA5W,IAAAwW,EAAAuB,UAAAyE,IAEAK,EAAA,GAEA,QAAAzC,KAAA3D,EAAA,CACA,IAAAqG,EAAA/gB,KAAAghB,YAAAH,EAAAxC,EAAA3D,GACAuG,EAAAvG,EAAA2D,GAAA6C,MAEA,QAAAhC,KAAA6B,EACAA,EAAA7B,GAAA6B,EAAA7B,GAAA+B,EAGA,QAAA/B,KAAA6B,EACA7B,KAAA4B,EACAA,EAAA5B,IAAA6B,EAAA7B,GAEA4B,EAAA5B,GAAA6B,EAAA7B,GAKA,IAAAiC,EAAA,GACA,QAAAjC,KAAA4B,EACAK,EAAAvZ,KAAA,CAAkB2W,IAAAW,EAAAkC,MAAAN,EAAA5B,KAIlB,OADAiC,EAAAE,KAAA,SAAAlT,EAAAwC,GAAgC,OAAAA,EAAAyQ,MAAAjT,EAAAiT,QAChCD,GAWA1G,EAAAG,MAAAhb,UAAAohB,YAAA,SAAAH,EAAAnC,EAAAhE,GACA,IAAA4G,EAAA5G,EAAAgE,GAAA6C,KACAC,EAAA9G,EAAAgE,GAAA8C,OACAN,EAAAxG,EAAAgE,GAAAwC,MACAO,EAAA,KACAC,EAAA,GAGA,OAAAR,EAmFA,OA/EAL,EAAAze,QAAA,SAAAa,GACA,IAAArC,EAAA,CAAAqC,GACA,GAAAue,IACA5gB,EAAAZ,KAAAiG,MAAAyY,GAAAiD,YAAA1e,IAoBA,IAAA2e,EAAA,GACAhhB,EAAAwB,QAAA,SAAAF,GACA,IAAA2f,EAAA7hB,KAAAiG,MAAAyY,GAAAoD,QAAA5f,GACA+d,EAAAjgB,KAAAigB,IAAA/d,EAAAwc,GAEA,GAAA+C,GAAA,OAAAH,EAAA,CAIA,IAAAS,EAAA,GACA,QAAA7C,KAAAuC,EACAvC,KAAA2C,IACAE,EAAA7C,GAAA2C,EAAA3C,IAGA2C,EAAAE,EAYA,QAAA7C,KAJAhd,GAAAe,GACAjD,KAAAgiB,iBAAAN,EAAAxf,EAAA2f,GAGAA,EAAA,CACA,IAAApC,EAAAzf,KAAAiG,MAAAyY,GAAAuD,iBAAA/f,EAAAgd,GACAgD,EAAAliB,KAAA6d,cAAAsE,eAAAjD,EAAAR,GACA0D,EAAA,EACA,GAAAF,IACAE,EAAA,EAAAnM,KAAAsJ,KAAA2C,IAGA,IAAAG,EAAA,EACAngB,GAAAe,IAGAof,EAAA,QAAAngB,EAAAqE,OAAAtD,EAAAsD,QAAArE,EAAAqE,SAGA,IAAA6a,EAAA3B,EAAAQ,EAAAmC,EAAAC,EAEAnD,KAAA0C,EACAA,EAAA1C,IAAAkC,EAEAQ,EAAA1C,GAAAkC,IAGKphB,MAELyhB,EAAAzhB,KAAAsiB,YAAAb,EAAAG,EAAAN,IACGthB,MAEHyhB,EAAAzhB,KAAAuiB,UAAAd,EAAAC,EAAAb,EAAAta,SAgBAkU,EAAAG,MAAAhb,UAAA0iB,YAAA,SAAAE,EAAAf,EAAAgB,GACA,IAAAD,EACA,OAAAf,EAEA,UAAAgB,EAAA,CACA,IAAAC,EAAA,GACA,QAAAxD,KAAAuC,EACAvC,KAAAsD,IACAE,EAAAxD,GAAAsD,EAAAtD,GAAAuC,EAAAvC,IAGA,OAAAwD,EAEA,QAAAxD,KAAAuC,EACAvC,KAAAsD,EACAA,EAAAtD,IAAAuC,EAAAvC,GAEAsD,EAAAtD,GAAAuC,EAAAvC,GAGA,OAAAsD,GAcA/H,EAAAG,MAAAhb,UAAAoiB,iBAAA,SAAAN,EAAAze,EAAA4e,GACA,QAAA7C,KAAA6C,EACA7C,KAAA0C,EACAA,EAAA1C,GAAApX,KAAA3E,GAEAye,EAAA1C,GAAA,CAAA/b,IAiBAwX,EAAAG,MAAAhb,UAAA2iB,UAAA,SAAAd,EAAAC,EAAA1N,GACA,QAAAgL,KAAAyC,EACA,GAAAzC,KAAA0C,EAAA,CACA,IAAA9gB,EAAA8gB,EAAA1C,GAAAzY,OACAkb,EAAAzC,GAAAyC,EAAAzC,GAAApe,EAAAoT,EAGA,OAAAyN,GASAhH,EAAAG,MAAAhb,UAAA8d,OAAA,WACA,IAAAiF,EAAA,GAKA,OAJA3iB,KAAA2d,QAAAvb,QAAA,SAAAic,GACAsE,EAAAtE,GAAAre,KAAAiG,MAAAoY,GAAAX,UACG1d,MAEH,CACAib,QAAAR,EAAAQ,QACAqD,OAAAte,KAAA2d,QACAY,IAAAve,KAAA4d,KACAC,cAAA7d,KAAA6d,cAAAH,SACAzX,MAAA0c,EACA9H,SAAA7a,KAAA6a,SAAA6C,WA8BAjD,EAAAG,MAAAhb,UAAAgjB,IAAA,SAAAC,GACA,IAAAlb,EAAA1G,MAAArB,UAAA6B,MAAAD,KAAAqW,UAAA,GACAlQ,EAAAmb,QAAA9iB,MACA6iB,EAAA9a,MAAA/H,KAAA2H,IAqBA8S,EAAAqD,cAAA,SAAAgB,GAEA9e,KAAA+iB,MADAjE,SAGAA,EAGA9e,KAAA6hB,KAAA,GACA7hB,KAAAgjB,QAAA,GACAhjB,KAAAuG,OAAA,GASAkU,EAAAqD,cAAAb,KAAA,SAAAmB,GACA,IAAA6E,EAAA,IAAAjjB,KAOA,OALAijB,EAAA1c,OAAA6X,EAAA7X,OACA0c,EAAApB,KAAAzD,EAAAyD,KACAoB,EAAAD,QAAA5E,EAAA4E,QACAC,EAAAF,MAAA3E,EAAAU,KAEAmE,GAQAxI,EAAAqD,cAAAle,UAAA+f,YAAA,WACA,OAAA3f,KAAA+iB,OAYAtI,EAAAqD,cAAAle,UAAAmf,OAAA,SAAAG,EAAAF,GACAhf,KAAA4f,OAAAV,IAAAlf,KAAAuG,UAEA,IAAAvG,KAAA+iB,MACA/iB,KAAA6hB,KAAA3C,GAiHA,SAAAvd,GACA,UAAAA,GAAA,iBAAAA,EAAA,OAAAA,EAEA,IAAAuhB,EAAAvhB,EAAAwhB,cAEA,QAAAC,KAAAzhB,EACAA,EAAAQ,eAAAihB,KAAAF,EAAAE,GAAAzhB,EAAAyhB,IAGA,OAAAF,EA1HAphB,CAAAkd,GAEAhf,KAAA6hB,KAAA3C,GAAA,MAcAzE,EAAAqD,cAAAle,UAAAigB,OAAA,SAAAX,GACA,WAAAlf,KAAA4f,OAAAV,GAAA,KACAlf,KAAA6hB,KAAA3C,IAUAzE,EAAAqD,cAAAle,UAAAggB,OAAA,SAAAV,GACA,OAAAA,KAAAlf,KAAA6hB,MASApH,EAAAqD,cAAAle,UAAAkgB,UAAA,SAAAZ,GACAlf,KAAA4f,OAAAV,YAEAlf,KAAA6hB,KAAA3C,UACAlf,KAAAgjB,QAAA9D,GACAlf,KAAAuG,WAWAkU,EAAAqD,cAAAle,UAAAwf,eAAA,SAAAF,EAAAR,EAAAnY,GACA2Y,SACA,GAAAlf,KAAA4f,OAAAV,KAEAlf,KAAAgjB,QAAA9D,KAAAlf,KAAAgjB,QAAA9D,GAAA,IACAlf,KAAAgjB,QAAA9D,GAAAR,GAAAnY,IAWAkU,EAAAqD,cAAAle,UAAAyjB,kBAAA,SAAAnE,EAAAR,EAAAnY,GACA2Y,SACA,GAAAlf,KAAA4f,OAAAV,IAEAlf,KAAAof,eAAAF,EAAAR,EAAAnY,IAUAkU,EAAAqD,cAAAle,UAAAuiB,eAAA,SAAAjD,EAAAR,GACA,OAAAQ,QAAA,EAEAA,KAAAlf,KAAA6hB,MACAnD,KAAA1e,KAAAgjB,QAAA9D,GACAlf,KAAAgjB,QAAA9D,GAAAR,GAFA,GAWAjE,EAAAqD,cAAAle,UAAA8d,OAAA,WACA,OACAmE,KAAA7hB,KAAA6hB,KACAmB,QAAAhjB,KAAAgjB,QACAzc,OAAAvG,KAAAuG,OACAuY,KAAA9e,KAAA+iB,QAqCAtI,EAAAO,SACA9B,EAAA,CACAoK,QAAA,MACAC,OAAA,OACAC,KAAA,OACAC,KAAA,OACAC,KAAA,MACAC,IAAA,MACAC,KAAA,KACAC,MAAA,MACAC,IAAA,IACAC,MAAA,MACAC,QAAA,MACAC,MAAA,MACAC,KAAA,MACAC,MAAA,KACAC,QAAA,MACAC,QAAA,MACAC,QAAA,MACAC,MAAA,KACAC,MAAA,MACAC,OAAA,MACAC,KAAA,OAGAvL,EAAA,CACAwL,MAAA,KACAC,MAAA,GACAC,MAAA,KACAC,MAAA,KACAC,KAAA,KACAC,IAAA,GACAC,KAAA,IAIA5iB,EAAA,WACA+W,EAAAlB,qBAQAmB,EAAA,IAAAvS,OALA,4DAMAwS,EAAA,IAAAxS,OAJA,8FAKAyS,EAAA,IAAAzS,OANA,gFAOA0S,EAAA,IAAA1S,OALA,kCAOA2S,EAAA,kBACAC,EAAA,iBACAC,EAAA,aACAC,EAAA,kBACAC,EAAA,KACAC,EAAA,cACAC,EAAA,IAAAjT,OAAA,sBACAkT,EAAA,IAAAlT,OAAA,IAAAsS,EAAA/W,EAAA,gBAEA4X,EAAA,mBACAC,EAAA,2IAEAC,EAAA,iDAEAC,EAAA,sFACAC,EAAA,oBAEAC,EAAA,WACAC,EAAA,MACAC,EAAA,IAAA1T,OAAA,IAAAsS,EAAA/W,EAAA,gBAEA,SAAA6iB,GACA,IAAAC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,EAEA,GAAAP,EAAA3e,OAAA,EAAuB,OAAA2e,EAiBvB,GAdA,MADAG,EAAAH,EAAA5M,OAAA,QAEA4M,EAAAG,EAAAK,cAAAR,EAAA5M,OAAA,IAKAiN,EAAA7L,GADA4L,EAAA7L,GAGAjV,KAAA0gB,GAAqBA,IAAA9jB,QAAAkkB,EAAA,QACrBC,EAAA/gB,KAAA0gB,KAA2BA,IAAA9jB,QAAAmkB,EAAA,SAI3BA,EAAA3L,GADA0L,EAAA3L,GAEAnV,KAAA0gB,GAAA,CACA,IAAAS,EAAAL,EAAAne,KAAA+d,IACAI,EAAAjM,GACA7U,KAAAmhB,EAAA,MACAL,EAAAzL,EACAqL,IAAA9jB,QAAAkkB,EAAA,UAEKC,EAAA/gB,KAAA0gB,KAELC,GADAQ,EAAAJ,EAAApe,KAAA+d,IACA,IACAK,EAAA/L,GACAhV,KAAA2gB,KAGAK,EAAAzL,EACA0L,EAAAzL,GAFAuL,EAAAzL,GAGAtV,KAJA0gB,EAAAC,GAI0BD,GAAA,IAC1BM,EAAAhhB,KAAA0gB,IAA+BI,EAAAzL,EAAcqL,IAAA9jB,QAAAkkB,EAAA,KAC7CG,EAAAjhB,KAAA0gB,KAA+BA,GAAA,OAiF/B,OA5EAI,EAAArL,GACAzV,KAAA0gB,KAGAA,GADAC,GADAQ,EAAAL,EAAAne,KAAA+d,IACA,IACA,MAIAI,EAAApL,GACA1V,KAAA0gB,KAEAC,GADAQ,EAAAL,EAAAne,KAAA+d,IACA,GACAE,EAAAO,EAAA,IACAL,EAAAjM,GACA7U,KAAA2gB,KACAD,EAAAC,EAAAjM,EAAAkM,MAKAE,EAAAnL,GACA3V,KAAA0gB,KAEAC,GADAQ,EAAAL,EAAAne,KAAA+d,IACA,GACAE,EAAAO,EAAA,IACAL,EAAAjM,GACA7U,KAAA2gB,KACAD,EAAAC,EAAAhM,EAAAiM,KAMAG,EAAAlL,GADAiL,EAAAlL,GAEA5V,KAAA0gB,IAEAC,GADAQ,EAAAL,EAAAne,KAAA+d,IACA,IACAI,EAAAhM,GACA9U,KAAA2gB,KACAD,EAAAC,IAEKI,EAAA/gB,KAAA0gB,KAELC,GADAQ,EAAAJ,EAAApe,KAAA+d,IACA,GAAAS,EAAA,IACAJ,EAAAjM,GACA9U,KAAA2gB,KACAD,EAAAC,KAKAG,EAAAhL,GACA9V,KAAA0gB,KAEAC,GADAQ,EAAAL,EAAAne,KAAA+d,IACA,GAEAK,EAAAhM,EACAiM,EAAAhL,IAFA8K,EAAAhM,GAGA9U,KAAA2gB,IAAAI,EAAA/gB,KAAA2gB,KAAAK,EAAAhhB,KAAA2gB,MACAD,EAAAC,IAKAI,EAAAjM,GADAgM,EAAA/K,GAEA/V,KAAA0gB,IAAAK,EAAA/gB,KAAA0gB,KACAI,EAAAzL,EACAqL,IAAA9jB,QAAAkkB,EAAA,KAKA,KAAAD,IACAH,EAAAG,EAAA1gB,cAAAugB,EAAA5M,OAAA,IAGA4M,IAMAzK,EAAAiC,SAAAG,iBAAApC,EAAAO,QAAA,WAoBAP,EAAAM,eAAA,SAAA9X,GACA,GAAAA,IAAA,IAAAwX,EAAAM,eAAA6K,UAAA3iB,GACA,OAAAA,GAWAwX,EAAAoL,eAAA,WACApL,EAAAM,eAAA6K,UAAA,IAUAnL,EAAAqL,aAAA,SAAAC,GACA,MAAAA,IAAA,IAAA9kB,MAAAC,QAAA6kB,IAEAA,EAAA3jB,QAAA,SAAA4jB,GACAvL,EAAAM,eAAA6K,UAAAI,IAAA,GACGhmB,OASHya,EAAAwL,eAAA,WACAxL,EAAAM,eAAA6K,UAAAnL,EAAAyL,kBAGAzL,EAAAyL,iBAAA,CACAC,IAAA,EACAhY,GAAA,EACAiY,MAAA,EACAC,OAAA,EACAC,QAAA,EACA5e,OAAA,EACAO,KAAA,EACAse,QAAA,EACAC,MAAA,EACAC,IAAA,EACAC,OAAA,EACAC,IAAA,EACAC,KAAA,EACAC,KAAA,EACAC,KAAA,EACAC,IAAA,EACAC,IAAA,EACAC,IAAA,EACAC,SAAA,EACAC,MAAA,EACAC,KAAA,EACAC,IAAA,EACAC,KAAA,EACAC,QAAA,EACAC,OAAA,EACAC,MAAA,EACAC,KAAA,EACAC,IAAA,EACAC,MAAA,EACAC,QAAA,EACAC,MAAA,EACAC,MAAA,EACAC,OAAA,EACAC,KAAA,EACA7gB,MAAA,EACArH,KAAA,EACAmoB,KAAA,EACAC,KAAA,EACAC,KAAA,EACAC,MAAA,EACAC,IAAA,EACAC,KAAA,EACAC,MAAA,EACAC,KAAA,EACAC,KAAA,EACAC,KAAA,EACAC,SAAA,EACAtmB,GAAA,EACAumB,IAAA,EACAC,IAAA,EACAC,MAAA,EACAC,IAAA,EACAC,IAAA,EACAC,KAAA,EACAC,MAAA,EACAC,OAAA,EACAC,KAAA,EACAC,MAAA,EACAC,QAAA,EACAC,KAAA,EACAC,IAAA,EACAC,OAAA,EACAC,MAAA,EACAC,MAAA,EACAC,IAAA,EACAC,SAAA,EACAC,IAAA,EACAC,KAAA,EACAC,KAAA,EACAC,IAAA,EACA/L,KAAA,EACAgM,OAAA,EACAlM,IAAA,EACAmM,MAAA,EACAC,IAAA,EACAC,OAAA,EACAC,KAAA,EACAC,KAAA,EACAC,QAAA,EACAC,MAAA,EACAC,KAAA,EACAC,MAAA,EACAC,KAAA,EACAC,QAAA,EACAC,OAAA,EACAC,IAAA,EACAC,MAAA,EACAC,MAAA,EACAC,MAAA,EACAC,KAAA,EACAC,OAAA,EACAC,MAAA,EACAC,MAAA,EACAC,OAAA,EACAC,OAAA,EACAC,MAAA,EACA1rB,MAAA,EACA2rB,KAAA,EACAtkB,IAAA,EACAukB,KAAA,EACAC,MAAA,EACAC,IAAA,EACAC,OAAA,EACAC,KAAA,EACAC,IAAA,EACAC,MAAA,EACAC,MAAA,EACAC,MAAA,EACAC,OAAA,EACAC,OAAA,EACAC,OAAA,EACAC,KAAA,EACAC,MAAA,EACAC,KAAA,EACAC,MAAA,EACAC,MAAA,EACAC,OAAA,EACAC,KAAA,EACAC,KAAA,EACAC,MAAA,GAGAvS,EAAAM,eAAA6K,UAAAnL,EAAAyL,iBAEAzL,EAAAiC,SAAAG,iBAAApC,EAAAM,eAAA,kBAqBAN,EAAAK,QAAA,SAAA7X,GACA,GAAAA,QACA,UAAAsP,MAAA,iCAGA,OAAAtP,EACA7B,QAAA,WACAA,QAAA,YAGAqZ,EAAAiC,SAAAG,iBAAApC,EAAAK,QAAA,WAaAL,EAAA+D,cAAA,WACAxe,KAAA8C,KAAA,CAAe+e,KAAA,GAASzB,GAAA,IASxB3F,EAAA+D,cAAAvB,KAAA,SAAAmB,GACA,IAAAzD,EAAA,IAAA3a,KAGA,OAFA2a,EAAA7X,KAAAsb,EAAAtb,KAEA6X,GAqBAF,EAAA+D,cAAA5e,UAAA4f,SAAA,SAAAvc,EAAAgqB,EAAAnqB,GACAA,KAAA9C,KAAA8C,KAGA,IAHA,IACA6X,EAAA,EAEAA,GAAA1X,EAAAsD,OAAA,IACA,IAAArE,EAAAe,EAAA0X,GAEAzY,KAAAY,MAAAZ,GAAA,CAAqC2f,KAAA,GAAQzB,GAAA,IAC7CzF,GAAA,EACA7X,IAAAZ,GAGA,IAAAgd,EAAA+N,EAAA1O,IACAzb,EAAA+e,KAAA3C,GAMApc,EAAA+e,KAAA3C,GAAA,CAAyBO,GAAAwN,EAAAxN,KAJzB3c,EAAA+e,KAAA3C,GAAA,CAAyBO,GAAAwN,EAAAxN,IACzB3c,EAAAsd,IAAA,IAeA3F,EAAA+D,cAAA5e,UAAAstB,SAAA,SAAAjqB,GACA,IAAAA,EAAA,SAIA,IAFA,IAAAkqB,EAAAntB,KAAA8C,KAEAR,EAAA,EAAiBA,EAAAW,EAAAsD,OAAkBjE,IAAA,CACnC,IAAA6qB,EAAAlqB,EAAAX,IAAA,SACA6qB,IAAAlqB,EAAAX,IAGA,UAaAmY,EAAA+D,cAAA5e,UAAAwtB,QAAA,SAAAnqB,GACA,IAAAA,EAAA,YAIA,IAFA,IAAAkqB,EAAAntB,KAAA8C,KAEAR,EAAA,EAAiBA,EAAAW,EAAAsD,OAAkBjE,IAAA,CACnC,IAAA6qB,EAAAlqB,EAAAX,IAAA,YACA6qB,IAAAlqB,EAAAX,IAGA,OAAA6qB,GAYA1S,EAAA+D,cAAA5e,UAAAkiB,QAAA,SAAA7e,GACA,IAAAkqB,EAAAntB,KAAAotB,QAAAnqB,GACA,aAAAkqB,EACA,GAGAA,EAAAtL,MAaApH,EAAA+D,cAAA5e,UAAAqiB,iBAAA,SAAAhf,EAAAic,GACA,IAAAiO,EAAAntB,KAAAotB,QAAAnqB,GAEA,aAAAkqB,EACA,EAGAjO,KAAAiO,EAAAtL,KAIAsL,EAAAtL,KAAA3C,GAAAO,GAHA,GAeAhF,EAAA+D,cAAA5e,UAAAygB,WAAA,SAAApd,GACA,IAAAkqB,EAAAntB,KAAAotB,QAAAnqB,GAEA,aAAAkqB,EACA,EAGAA,EAAA/M,IAWA3F,EAAA+D,cAAA5e,UAAAmgB,YAAA,SAAA9c,EAAAsb,GACA,GAAAtb,EAAA,CACA,IAAAkqB,EAAAntB,KAAAotB,QAAAnqB,GAEA,MAAAkqB,GAEA5O,KAAA4O,EAAAtL,cACAsL,EAAAtL,KAAAtD,GACA4O,EAAA/M,IAAA,KAYA3F,EAAA+D,cAAA5e,UAAA+hB,YAAA,SAAA1e,EAAAoqB,EAAAvqB,GACA,SAAAG,GAAA,IAAAA,EAAA,SACAoqB,KAAA,GAEA,SAAAvqB,GAEA,OADAA,EAAA9C,KAAAotB,QAAAnqB,IACA,OAAAoqB,EAKA,QAAAnrB,KAFAY,EAAAsd,GAAA,GAAAiN,EAAAzlB,KAAA3E,GAEAH,EACA,SAAAZ,GACA,OAAAA,GACAlC,KAAA2hB,YAAA1e,EAAAf,EAAAmrB,EAAAvqB,EAAAZ,IAGA,OAAAmrB,GASA5S,EAAA+D,cAAA5e,UAAA8d,OAAA,WACA,OACA5a,KAAA9C,KAAA8C,OAgFA2X,EAAAmG,cAAA,SAAAlG,EAAA4D,GACA,IAQAoC,EARAhG,KAAA,GAEA,GAAAzI,MAAAqM,GAAA,MAAAA,EACA,UAAA/L,MAAA,6BAGAvS,KAAA0a,OAAA,GAGA,IACAgG,EAAAjb,KAAAqD,MAAA4R,GACA1a,KAAAstB,gBAAA5M,EAAApC,GACG,MAAAiP,GACH9S,EAAAU,MAAAC,KAAA,mEACApb,KAAAwtB,mBAAAlP,KASA7D,EAAAmG,cAAAhhB,UAAA4tB,mBAAA,SAAAlP,GACAte,KAAAyd,QACAa,EAAAlc,QAAA,SAAAic,GACAre,KAAA0a,OAAA2D,GAAA,CACA6C,MAAA,EACAK,KAAA,KACAC,QAAA,IAEGxhB,OASHya,EAAAmG,cAAAhhB,UAAA0tB,gBAAA,SAAA5S,EAAA4D,GACA,IAAAmP,EAAA,KACAC,GAAA,EAWA,GATA1tB,KAAAyd,QACA,SAAA/C,IACA+S,EAAA/S,EAAA,MAAA+S,GAGA,WAAA/S,IACAgT,EAAAhT,EAAA,QAAAgT,GAGA,WAAAhT,EACA,QAAA2D,KAAA3D,EAAA,OACA,GAAA4D,EAAAxM,QAAAuM,IAAA,GACA,IAAAsP,EAAAjT,EAAA,OAAA2D,GACAuP,EAAAF,EACAzb,MAAA0b,EAAAnM,SACAoM,EAAAD,EAAAnM,QAGAxhB,KAAA0a,OAAA2D,GAAA,CACA6C,MAAAyM,EAAAzM,OAAA,IAAAyM,EAAAzM,MAAAyM,EAAAzM,MAAA,EACAK,KAAAoM,EAAApM,MAAAkM,EACAjM,OAAAoM,QAGAnT,EAAAU,MAAAC,KAAA,4EAIApb,KAAA6tB,wBAAAJ,EAAAC,EAAApP,IAWA7D,EAAAmG,cAAAhhB,UAAAiuB,wBAAA,SAAAtM,EAAAC,EAAAlD,GACAA,EAAAlc,QAAA,SAAAic,GACAre,KAAA0a,OAAA2D,GAAA,CACA6C,MAAA,EACAK,OACAC,WAEGxhB,OAMHya,EAAAmG,cAAAhhB,UAAAG,IAAA,WACA,OAAAC,KAAA0a,QAMAD,EAAAmG,cAAAhhB,UAAA6d,MAAA,WACAzd,KAAA0a,OAAA,IAqBAQ,KAAA4S,UAAA,WACA9tB,KAAAuG,OAAA,EACAvG,KAAAmE,SAAA,IAUA+W,KAAA4S,UAAA7Q,KAAA,SAAAmB,GACA,IAAA2P,EAAA,IAAA/tB,KAKA,OAHA+tB,EAAA5pB,SAAAia,EACA2P,EAAAxnB,OAAA6X,EAAA7X,OAEAwnB,GAUA7S,KAAA4S,UAAAluB,UAAAsI,IAAA,WACA,IAAA5F,EAAA4B,EAEA,IAAA5B,EAAA,EAAaA,EAAAuV,UAAAtR,OAAsBjE,IACnC4B,EAAA2T,UAAAvV,IACAtC,KAAA8R,QAAA5N,IACAlE,KAAAmE,SAAA2D,OAAA9H,KAAAguB,YAAA9pB,GAAA,EAAAA,GAGAlE,KAAAuG,OAAAvG,KAAAmE,SAAAoC,QASA2U,KAAA4S,UAAAluB,UAAAquB,QAAA,WACA,OAAAjuB,KAAAmE,SAAA1C,SAgBAyZ,KAAA4S,UAAAluB,UAAAuB,IAAA,SAAAsa,EAAAyS,GACA,OAAAluB,KAAAmE,SAAAhD,IAAAsa,EAAAyS,IAcAhT,KAAA4S,UAAAluB,UAAAwC,QAAA,SAAAqZ,EAAAyS,GACA,OAAAluB,KAAAmE,SAAA/B,QAAAqZ,EAAAyS,IAWAhT,KAAA4S,UAAAluB,UAAAkS,QAAA,SAAAqc,GAOA,IANA,IAAAtc,EAAA,EACAuc,EAAApuB,KAAAmE,SAAAoC,OACA8nB,EAAAD,EAAAvc,EACAyc,EAAAzc,EAAAoE,KAAAsY,MAAAF,EAAA,GACAG,EAAAxuB,KAAAmE,SAAAmqB,GAEAD,EAAA,IACA,GAAAG,IAAAL,EAAA,OAAAG,EAEAE,EAAAL,IAAAtc,EAAAyc,GACAE,EAAAL,IAAAC,EAAAE,GAEAD,EAAAD,EAAAvc,EACAyc,EAAAzc,EAAAoE,KAAAsY,MAAAF,EAAA,GACAG,EAAAxuB,KAAAmE,SAAAmqB,GAGA,OAAAE,IAAAL,EAAAG,GAEA,GAcApT,KAAA4S,UAAAluB,UAAAouB,YAAA,SAAAG,GAOA,IANA,IAAAtc,EAAA,EACAuc,EAAApuB,KAAAmE,SAAAoC,OACA8nB,EAAAD,EAAAvc,EACAyc,EAAAzc,EAAAoE,KAAAsY,MAAAF,EAAA,GACAG,EAAAxuB,KAAAmE,SAAAmqB,GAEAD,EAAA,GACAG,EAAAL,IAAAtc,EAAAyc,GACAE,EAAAL,IAAAC,EAAAE,GAEAD,EAAAD,EAAAvc,EACAyc,EAAAzc,EAAAoE,KAAAsY,MAAAF,EAAA,GACAG,EAAAxuB,KAAAmE,SAAAmqB,GAGA,OAAAE,EAAAL,EAAAG,EACAE,EAAAL,EAAAG,EAAA,UAWApT,KAAA4S,UAAAluB,UAAA6uB,UAAA,SAAAC,GAMA,IALA,IAAAC,EAAA,IAAAzT,KAAA4S,UACAxrB,EAAA,EAAAgE,EAAA,EACAsoB,EAAA5uB,KAAAuG,OAAAsoB,EAAAH,EAAAnoB,OACA4H,EAAAnO,KAAAmE,SAAAwM,EAAA+d,EAAAvqB,WAGA7B,EAAAssB,EAAA,GAAAtoB,EAAAuoB,EAAA,IAEA1gB,EAAA7L,KAAAqO,EAAArK,GAMA6H,EAAA7L,GAAAqO,EAAArK,GACAhE,IAIA6L,EAAA7L,GAAAqO,EAAArK,IACAA,KAXAqoB,EAAAzmB,IAAAiG,EAAA7L,IACAA,IAAAgE,KAeA,OAAAqoB,GASAzT,KAAA4S,UAAAluB,UAAAkC,MAAA,WACA,IAAAA,EAAA,IAAAoZ,KAAA4S,UAKA,OAHAhsB,EAAAqC,SAAAnE,KAAAiuB,UACAnsB,EAAAyE,OAAAzE,EAAAqC,SAAAoC,OAEAzE,GAWAoZ,KAAA4S,UAAAluB,UAAAkvB,MAAA,SAAAJ,GACA,IAAAK,EAAAC,EAAAC,EAEAjvB,KAAAuG,QAAAmoB,EAAAnoB,QACAwoB,EAAA/uB,KAAAgvB,EAAAN,IAEAK,EAAAL,EAAAM,EAAAhvB,MAGAivB,EAAAF,EAAAjtB,QAEA,QAAAQ,EAAA,EAAA4sB,EAAAF,EAAAf,UAAuD3rB,EAAA4sB,EAAA3oB,OAA6BjE,IACpF2sB,EAAA/mB,IAAAgnB,EAAA5sB,IAGA,OAAA2sB,GASA/T,KAAA4S,UAAAluB,UAAA8d,OAAA,WACA,OAAA1d,KAAAiuB,gBASoBhc,KAAAgH,EAAA,mBAAdD,EAYH,WAMH,OAAAyB,IAlBoBzB,EAAAxX,KAAAqI,EAAArK,EAAAqK,EAAAD,GAAAoP,KAAApP,EAAAC,QAAAoP,GAt5EpB","file":"5-d586234d91b4978359b4.js","sourcesContent":["var dP = require('./_object-dp').f;\nvar FProto = Function.prototype;\nvar nameRE = /^\\s*function ([^ (]*)/;\nvar NAME = 'name';\n\n// 19.2.4.2 name\nNAME in FProto || require('./_descriptors') && dP(FProto, NAME, {\n  configurable: true,\n  get: function () {\n    try {\n      return ('' + this).match(nameRE)[1];\n    } catch (e) {\n      return '';\n    }\n  }\n});\n","\n/* **********************************************\n     Begin prism-core.js\n********************************************** */\n\nvar _self = (typeof window !== 'undefined')\n\t? window   // if in browser\n\t: (\n\t\t(typeof WorkerGlobalScope !== 'undefined' && self instanceof WorkerGlobalScope)\n\t\t? self // if in worker\n\t\t: {}   // if in node js\n\t);\n\n/**\n * Prism: Lightweight, robust, elegant syntax highlighting\n * MIT license http://www.opensource.org/licenses/mit-license.php/\n * @author Lea Verou http://lea.verou.me\n */\n\nvar Prism = (function (_self){\n\n// Private helper vars\nvar lang = /\\blang(?:uage)?-([\\w-]+)\\b/i;\nvar uniqueId = 0;\n\nvar _ = {\n\tmanual: _self.Prism && _self.Prism.manual,\n\tdisableWorkerMessageHandler: _self.Prism && _self.Prism.disableWorkerMessageHandler,\n\tutil: {\n\t\tencode: function (tokens) {\n\t\t\tif (tokens instanceof Token) {\n\t\t\t\treturn new Token(tokens.type, _.util.encode(tokens.content), tokens.alias);\n\t\t\t} else if (Array.isArray(tokens)) {\n\t\t\t\treturn tokens.map(_.util.encode);\n\t\t\t} else {\n\t\t\t\treturn tokens.replace(/&/g, '&amp;').replace(/</g, '&lt;').replace(/\\u00a0/g, ' ');\n\t\t\t}\n\t\t},\n\n\t\ttype: function (o) {\n\t\t\treturn Object.prototype.toString.call(o).slice(8, -1);\n\t\t},\n\n\t\tobjId: function (obj) {\n\t\t\tif (!obj['__id']) {\n\t\t\t\tObject.defineProperty(obj, '__id', { value: ++uniqueId });\n\t\t\t}\n\t\t\treturn obj['__id'];\n\t\t},\n\n\t\t// Deep clone a language definition (e.g. to extend it)\n\t\tclone: function deepClone(o, visited) {\n\t\t\tvar clone, id, type = _.util.type(o);\n\t\t\tvisited = visited || {};\n\n\t\t\tswitch (type) {\n\t\t\t\tcase 'Object':\n\t\t\t\t\tid = _.util.objId(o);\n\t\t\t\t\tif (visited[id]) {\n\t\t\t\t\t\treturn visited[id];\n\t\t\t\t\t}\n\t\t\t\t\tclone = {};\n\t\t\t\t\tvisited[id] = clone;\n\n\t\t\t\t\tfor (var key in o) {\n\t\t\t\t\t\tif (o.hasOwnProperty(key)) {\n\t\t\t\t\t\t\tclone[key] = deepClone(o[key], visited);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\treturn clone;\n\n\t\t\t\tcase 'Array':\n\t\t\t\t\tid = _.util.objId(o);\n\t\t\t\t\tif (visited[id]) {\n\t\t\t\t\t\treturn visited[id];\n\t\t\t\t\t}\n\t\t\t\t\tclone = [];\n\t\t\t\t\tvisited[id] = clone;\n\n\t\t\t\t\to.forEach(function (v, i) {\n\t\t\t\t\t\tclone[i] = deepClone(v, visited);\n\t\t\t\t\t});\n\n\t\t\t\t\treturn clone;\n\n\t\t\t\tdefault:\n\t\t\t\t\treturn o;\n\t\t\t}\n\t\t}\n\t},\n\n\tlanguages: {\n\t\textend: function (id, redef) {\n\t\t\tvar lang = _.util.clone(_.languages[id]);\n\n\t\t\tfor (var key in redef) {\n\t\t\t\tlang[key] = redef[key];\n\t\t\t}\n\n\t\t\treturn lang;\n\t\t},\n\n\t\t/**\n\t\t * Insert a token before another token in a language literal\n\t\t * As this needs to recreate the object (we cannot actually insert before keys in object literals),\n\t\t * we cannot just provide an object, we need an object and a key.\n\t\t * @param inside The key (or language id) of the parent\n\t\t * @param before The key to insert before.\n\t\t * @param insert Object with the key/value pairs to insert\n\t\t * @param root The object that contains `inside`. If equal to Prism.languages, it can be omitted.\n\t\t */\n\t\tinsertBefore: function (inside, before, insert, root) {\n\t\t\troot = root || _.languages;\n\t\t\tvar grammar = root[inside];\n\t\t\tvar ret = {};\n\n\t\t\tfor (var token in grammar) {\n\t\t\t\tif (grammar.hasOwnProperty(token)) {\n\n\t\t\t\t\tif (token == before) {\n\t\t\t\t\t\tfor (var newToken in insert) {\n\t\t\t\t\t\t\tif (insert.hasOwnProperty(newToken)) {\n\t\t\t\t\t\t\t\tret[newToken] = insert[newToken];\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Do not insert token which also occur in insert. See #1525\n\t\t\t\t\tif (!insert.hasOwnProperty(token)) {\n\t\t\t\t\t\tret[token] = grammar[token];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tvar old = root[inside];\n\t\t\troot[inside] = ret;\n\n\t\t\t// Update references in other language definitions\n\t\t\t_.languages.DFS(_.languages, function(key, value) {\n\t\t\t\tif (value === old && key != inside) {\n\t\t\t\t\tthis[key] = ret;\n\t\t\t\t}\n\t\t\t});\n\n\t\t\treturn ret;\n\t\t},\n\n\t\t// Traverse a language definition with Depth First Search\n\t\tDFS: function DFS(o, callback, type, visited) {\n\t\t\tvisited = visited || {};\n\n\t\t\tvar objId = _.util.objId;\n\n\t\t\tfor (var i in o) {\n\t\t\t\tif (o.hasOwnProperty(i)) {\n\t\t\t\t\tcallback.call(o, i, o[i], type || i);\n\n\t\t\t\t\tvar property = o[i],\n\t\t\t\t\t    propertyType = _.util.type(property);\n\n\t\t\t\t\tif (propertyType === 'Object' && !visited[objId(property)]) {\n\t\t\t\t\t\tvisited[objId(property)] = true;\n\t\t\t\t\t\tDFS(property, callback, null, visited);\n\t\t\t\t\t}\n\t\t\t\t\telse if (propertyType === 'Array' && !visited[objId(property)]) {\n\t\t\t\t\t\tvisited[objId(property)] = true;\n\t\t\t\t\t\tDFS(property, callback, i, visited);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\tplugins: {},\n\n\thighlightAll: function(async, callback) {\n\t\t_.highlightAllUnder(document, async, callback);\n\t},\n\n\thighlightAllUnder: function(container, async, callback) {\n\t\tvar env = {\n\t\t\tcallback: callback,\n\t\t\tselector: 'code[class*=\"language-\"], [class*=\"language-\"] code, code[class*=\"lang-\"], [class*=\"lang-\"] code'\n\t\t};\n\n\t\t_.hooks.run(\"before-highlightall\", env);\n\n\t\tvar elements = env.elements || container.querySelectorAll(env.selector);\n\n\t\tfor (var i=0, element; element = elements[i++];) {\n\t\t\t_.highlightElement(element, async === true, env.callback);\n\t\t}\n\t},\n\n\thighlightElement: function(element, async, callback) {\n\t\t// Find language\n\t\tvar language, grammar, parent = element;\n\n\t\twhile (parent && !lang.test(parent.className)) {\n\t\t\tparent = parent.parentNode;\n\t\t}\n\n\t\tif (parent) {\n\t\t\tlanguage = (parent.className.match(lang) || [,''])[1].toLowerCase();\n\t\t\tgrammar = _.languages[language];\n\t\t}\n\n\t\t// Set language on the element, if not present\n\t\telement.className = element.className.replace(lang, '').replace(/\\s+/g, ' ') + ' language-' + language;\n\n\t\tif (element.parentNode) {\n\t\t\t// Set language on the parent, for styling\n\t\t\tparent = element.parentNode;\n\n\t\t\tif (/pre/i.test(parent.nodeName)) {\n\t\t\t\tparent.className = parent.className.replace(lang, '').replace(/\\s+/g, ' ') + ' language-' + language;\n\t\t\t}\n\t\t}\n\n\t\tvar code = element.textContent;\n\n\t\tvar env = {\n\t\t\telement: element,\n\t\t\tlanguage: language,\n\t\t\tgrammar: grammar,\n\t\t\tcode: code\n\t\t};\n\n\t\tvar insertHighlightedCode = function (highlightedCode) {\n\t\t\tenv.highlightedCode = highlightedCode;\n\n\t\t\t_.hooks.run('before-insert', env);\n\n\t\t\tenv.element.innerHTML = env.highlightedCode;\n\n\t\t\t_.hooks.run('after-highlight', env);\n\t\t\t_.hooks.run('complete', env);\n\t\t\tcallback && callback.call(env.element);\n\t\t}\n\n\t\t_.hooks.run('before-sanity-check', env);\n\n\t\tif (!env.code) {\n\t\t\t_.hooks.run('complete', env);\n\t\t\treturn;\n\t\t}\n\n\t\t_.hooks.run('before-highlight', env);\n\n\t\tif (!env.grammar) {\n\t\t\tinsertHighlightedCode(_.util.encode(env.code));\n\t\t\treturn;\n\t\t}\n\n\t\tif (async && _self.Worker) {\n\t\t\tvar worker = new Worker(_.filename);\n\n\t\t\tworker.onmessage = function(evt) {\n\t\t\t\tinsertHighlightedCode(evt.data);\n\t\t\t};\n\n\t\t\tworker.postMessage(JSON.stringify({\n\t\t\t\tlanguage: env.language,\n\t\t\t\tcode: env.code,\n\t\t\t\timmediateClose: true\n\t\t\t}));\n\t\t}\n\t\telse {\n\t\t\tinsertHighlightedCode(_.highlight(env.code, env.grammar, env.language));\n\t\t}\n\t},\n\n\thighlight: function (text, grammar, language) {\n\t\tvar env = {\n\t\t\tcode: text,\n\t\t\tgrammar: grammar,\n\t\t\tlanguage: language\n\t\t};\n\t\t_.hooks.run('before-tokenize', env);\n\t\tenv.tokens = _.tokenize(env.code, env.grammar);\n\t\t_.hooks.run('after-tokenize', env);\n\t\treturn Token.stringify(_.util.encode(env.tokens), env.language);\n\t},\n\n\tmatchGrammar: function (text, strarr, grammar, index, startPos, oneshot, target) {\n\t\tfor (var token in grammar) {\n\t\t\tif(!grammar.hasOwnProperty(token) || !grammar[token]) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (token == target) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tvar patterns = grammar[token];\n\t\t\tpatterns = (_.util.type(patterns) === \"Array\") ? patterns : [patterns];\n\n\t\t\tfor (var j = 0; j < patterns.length; ++j) {\n\t\t\t\tvar pattern = patterns[j],\n\t\t\t\t\tinside = pattern.inside,\n\t\t\t\t\tlookbehind = !!pattern.lookbehind,\n\t\t\t\t\tgreedy = !!pattern.greedy,\n\t\t\t\t\tlookbehindLength = 0,\n\t\t\t\t\talias = pattern.alias;\n\n\t\t\t\tif (greedy && !pattern.pattern.global) {\n\t\t\t\t\t// Without the global flag, lastIndex won't work\n\t\t\t\t\tvar flags = pattern.pattern.toString().match(/[imuy]*$/)[0];\n\t\t\t\t\tpattern.pattern = RegExp(pattern.pattern.source, flags + \"g\");\n\t\t\t\t}\n\n\t\t\t\tpattern = pattern.pattern || pattern;\n\n\t\t\t\t// Don’t cache length as it changes during the loop\n\t\t\t\tfor (var i = index, pos = startPos; i < strarr.length; pos += strarr[i].length, ++i) {\n\n\t\t\t\t\tvar str = strarr[i];\n\n\t\t\t\t\tif (strarr.length > text.length) {\n\t\t\t\t\t\t// Something went terribly wrong, ABORT, ABORT!\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (str instanceof Token) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (greedy && i != strarr.length - 1) {\n\t\t\t\t\t\tpattern.lastIndex = pos;\n\t\t\t\t\t\tvar match = pattern.exec(text);\n\t\t\t\t\t\tif (!match) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tvar from = match.index + (lookbehind ? match[1].length : 0),\n\t\t\t\t\t\t    to = match.index + match[0].length,\n\t\t\t\t\t\t    k = i,\n\t\t\t\t\t\t    p = pos;\n\n\t\t\t\t\t\tfor (var len = strarr.length; k < len && (p < to || (!strarr[k].type && !strarr[k - 1].greedy)); ++k) {\n\t\t\t\t\t\t\tp += strarr[k].length;\n\t\t\t\t\t\t\t// Move the index i to the element in strarr that is closest to from\n\t\t\t\t\t\t\tif (from >= p) {\n\t\t\t\t\t\t\t\t++i;\n\t\t\t\t\t\t\t\tpos = p;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// If strarr[i] is a Token, then the match starts inside another Token, which is invalid\n\t\t\t\t\t\tif (strarr[i] instanceof Token) {\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// Number of tokens to delete and replace with the new match\n\t\t\t\t\t\tdelNum = k - i;\n\t\t\t\t\t\tstr = text.slice(pos, p);\n\t\t\t\t\t\tmatch.index -= pos;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tpattern.lastIndex = 0;\n\n\t\t\t\t\t\tvar match = pattern.exec(str),\n\t\t\t\t\t\t\tdelNum = 1;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!match) {\n\t\t\t\t\t\tif (oneshot) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\n\t\t\t\t\tif(lookbehind) {\n\t\t\t\t\t\tlookbehindLength = match[1] ? match[1].length : 0;\n\t\t\t\t\t}\n\n\t\t\t\t\tvar from = match.index + lookbehindLength,\n\t\t\t\t\t    match = match[0].slice(lookbehindLength),\n\t\t\t\t\t    to = from + match.length,\n\t\t\t\t\t    before = str.slice(0, from),\n\t\t\t\t\t    after = str.slice(to);\n\n\t\t\t\t\tvar args = [i, delNum];\n\n\t\t\t\t\tif (before) {\n\t\t\t\t\t\t++i;\n\t\t\t\t\t\tpos += before.length;\n\t\t\t\t\t\targs.push(before);\n\t\t\t\t\t}\n\n\t\t\t\t\tvar wrapped = new Token(token, inside? _.tokenize(match, inside) : match, alias, match, greedy);\n\n\t\t\t\t\targs.push(wrapped);\n\n\t\t\t\t\tif (after) {\n\t\t\t\t\t\targs.push(after);\n\t\t\t\t\t}\n\n\t\t\t\t\tArray.prototype.splice.apply(strarr, args);\n\n\t\t\t\t\tif (delNum != 1)\n\t\t\t\t\t\t_.matchGrammar(text, strarr, grammar, i, pos, true, token);\n\n\t\t\t\t\tif (oneshot)\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t},\n\n\ttokenize: function(text, grammar) {\n\t\tvar strarr = [text];\n\n\t\tvar rest = grammar.rest;\n\n\t\tif (rest) {\n\t\t\tfor (var token in rest) {\n\t\t\t\tgrammar[token] = rest[token];\n\t\t\t}\n\n\t\t\tdelete grammar.rest;\n\t\t}\n\n\t\t_.matchGrammar(text, strarr, grammar, 0, 0, false);\n\n\t\treturn strarr;\n\t},\n\n\thooks: {\n\t\tall: {},\n\n\t\tadd: function (name, callback) {\n\t\t\tvar hooks = _.hooks.all;\n\n\t\t\thooks[name] = hooks[name] || [];\n\n\t\t\thooks[name].push(callback);\n\t\t},\n\n\t\trun: function (name, env) {\n\t\t\tvar callbacks = _.hooks.all[name];\n\n\t\t\tif (!callbacks || !callbacks.length) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tfor (var i=0, callback; callback = callbacks[i++];) {\n\t\t\t\tcallback(env);\n\t\t\t}\n\t\t}\n\t},\n\n\tToken: Token\n};\n\n_self.Prism = _;\n\nfunction Token(type, content, alias, matchedStr, greedy) {\n\tthis.type = type;\n\tthis.content = content;\n\tthis.alias = alias;\n\t// Copy of the full string this token was created from\n\tthis.length = (matchedStr || \"\").length|0;\n\tthis.greedy = !!greedy;\n}\n\nToken.stringify = function(o, language, parent) {\n\tif (typeof o == 'string') {\n\t\treturn o;\n\t}\n\n\tif (Array.isArray(o)) {\n\t\treturn o.map(function(element) {\n\t\t\treturn Token.stringify(element, language, o);\n\t\t}).join('');\n\t}\n\n\tvar env = {\n\t\ttype: o.type,\n\t\tcontent: Token.stringify(o.content, language, parent),\n\t\ttag: 'span',\n\t\tclasses: ['token', o.type],\n\t\tattributes: {},\n\t\tlanguage: language,\n\t\tparent: parent\n\t};\n\n\tif (o.alias) {\n\t\tvar aliases = Array.isArray(o.alias) ? o.alias : [o.alias];\n\t\tArray.prototype.push.apply(env.classes, aliases);\n\t}\n\n\t_.hooks.run('wrap', env);\n\n\tvar attributes = Object.keys(env.attributes).map(function(name) {\n\t\treturn name + '=\"' + (env.attributes[name] || '').replace(/\"/g, '&quot;') + '\"';\n\t}).join(' ');\n\n\treturn '<' + env.tag + ' class=\"' + env.classes.join(' ') + '\"' + (attributes ? ' ' + attributes : '') + '>' + env.content + '</' + env.tag + '>';\n\n};\n\nif (!_self.document) {\n\tif (!_self.addEventListener) {\n\t\t// in Node.js\n\t\treturn _;\n\t}\n\n\tif (!_.disableWorkerMessageHandler) {\n\t\t// In worker\n\t\t_self.addEventListener('message', function (evt) {\n\t\t\tvar message = JSON.parse(evt.data),\n\t\t\t\tlang = message.language,\n\t\t\t\tcode = message.code,\n\t\t\t\timmediateClose = message.immediateClose;\n\n\t\t\t_self.postMessage(_.highlight(code, _.languages[lang], lang));\n\t\t\tif (immediateClose) {\n\t\t\t\t_self.close();\n\t\t\t}\n\t\t}, false);\n\t}\n\n\treturn _;\n}\n\n//Get current script and highlight\nvar script = document.currentScript || [].slice.call(document.getElementsByTagName(\"script\")).pop();\n\nif (script) {\n\t_.filename = script.src;\n\n\tif (!_.manual && !script.hasAttribute('data-manual')) {\n\t\tif(document.readyState !== \"loading\") {\n\t\t\tif (window.requestAnimationFrame) {\n\t\t\t\twindow.requestAnimationFrame(_.highlightAll);\n\t\t\t} else {\n\t\t\t\twindow.setTimeout(_.highlightAll, 16);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tdocument.addEventListener('DOMContentLoaded', _.highlightAll);\n\t\t}\n\t}\n}\n\nreturn _;\n\n})(_self);\n\nif (typeof module !== 'undefined' && module.exports) {\n\tmodule.exports = Prism;\n}\n\n// hack for components to work correctly in node.js\nif (typeof global !== 'undefined') {\n\tglobal.Prism = Prism;\n}\n\n\n/* **********************************************\n     Begin prism-markup.js\n********************************************** */\n\nPrism.languages.markup = {\n\t'comment': /<!--[\\s\\S]*?-->/,\n\t'prolog': /<\\?[\\s\\S]+?\\?>/,\n\t'doctype': /<!DOCTYPE[\\s\\S]+?>/i,\n\t'cdata': /<!\\[CDATA\\[[\\s\\S]*?]]>/i,\n\t'tag': {\n\t\tpattern: /<\\/?(?!\\d)[^\\s>\\/=$<%]+(?:\\s(?:\\s*[^\\s>\\/=]+(?:\\s*=\\s*(?:\"[^\"]*\"|'[^']*'|[^\\s'\">=]+(?=[\\s>]))|(?=[\\s/>])))+)?\\s*\\/?>/i,\n\t\tgreedy: true,\n\t\tinside: {\n\t\t\t'tag': {\n\t\t\t\tpattern: /^<\\/?[^\\s>\\/]+/i,\n\t\t\t\tinside: {\n\t\t\t\t\t'punctuation': /^<\\/?/,\n\t\t\t\t\t'namespace': /^[^\\s>\\/:]+:/\n\t\t\t\t}\n\t\t\t},\n\t\t\t'attr-value': {\n\t\t\t\tpattern: /=\\s*(?:\"[^\"]*\"|'[^']*'|[^\\s'\">=]+)/i,\n\t\t\t\tinside: {\n\t\t\t\t\t'punctuation': [\n\t\t\t\t\t\t/^=/,\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tpattern: /^(\\s*)[\"']|[\"']$/,\n\t\t\t\t\t\t\tlookbehind: true\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t},\n\t\t\t'punctuation': /\\/?>/,\n\t\t\t'attr-name': {\n\t\t\t\tpattern: /[^\\s>\\/]+/,\n\t\t\t\tinside: {\n\t\t\t\t\t'namespace': /^[^\\s>\\/:]+:/\n\t\t\t\t}\n\t\t\t}\n\n\t\t}\n\t},\n\t'entity': /&#?[\\da-z]{1,8};/i\n};\n\nPrism.languages.markup['tag'].inside['attr-value'].inside['entity'] =\n\tPrism.languages.markup['entity'];\n\n// Plugin to make entity title show the real entity, idea by Roman Komarov\nPrism.hooks.add('wrap', function(env) {\n\n\tif (env.type === 'entity') {\n\t\tenv.attributes['title'] = env.content.replace(/&amp;/, '&');\n\t}\n});\n\nObject.defineProperty(Prism.languages.markup.tag, 'addInlined', {\n\t/**\n\t * Adds an inlined language to markup.\n\t *\n\t * An example of an inlined language is CSS with `<style>` tags.\n\t *\n\t * @param {string} tagName The name of the tag that contains the inlined language. This name will be treated as\n\t * case insensitive.\n\t * @param {string} lang The language key.\n\t * @example\n\t * addInlined('style', 'css');\n\t */\n\tvalue: function addInlined(tagName, lang) {\n\t\tvar includedCdataInside = {};\n\t\tincludedCdataInside['language-' + lang] = {\n\t\t\tpattern: /(^<!\\[CDATA\\[)[\\s\\S]+?(?=\\]\\]>$)/i,\n\t\t\tlookbehind: true,\n\t\t\tinside: Prism.languages[lang]\n\t\t};\n\t\tincludedCdataInside['cdata'] = /^<!\\[CDATA\\[|\\]\\]>$/i;\n\n\t\tvar inside = {\n\t\t\t'included-cdata': {\n\t\t\t\tpattern: /<!\\[CDATA\\[[\\s\\S]*?\\]\\]>/i,\n\t\t\t\tinside: includedCdataInside\n\t\t\t}\n\t\t};\n\t\tinside['language-' + lang] = {\n\t\t\tpattern: /[\\s\\S]+/,\n\t\t\tinside: Prism.languages[lang]\n\t\t};\n\n\t\tvar def = {};\n\t\tdef[tagName] = {\n\t\t\tpattern: RegExp(/(<__[\\s\\S]*?>)(?:<!\\[CDATA\\[[\\s\\S]*?\\]\\]>\\s*|[\\s\\S])*?(?=<\\/__>)/.source.replace(/__/g, tagName), 'i'),\n\t\t\tlookbehind: true,\n\t\t\tgreedy: true,\n\t\t\tinside: inside\n\t\t};\n\n\t\tPrism.languages.insertBefore('markup', 'cdata', def);\n\t}\n});\n\nPrism.languages.xml = Prism.languages.extend('markup', {});\nPrism.languages.html = Prism.languages.markup;\nPrism.languages.mathml = Prism.languages.markup;\nPrism.languages.svg = Prism.languages.markup;\n\n\n/* **********************************************\n     Begin prism-css.js\n********************************************** */\n\n(function (Prism) {\n\n\tvar string = /(\"|')(?:\\\\(?:\\r\\n|[\\s\\S])|(?!\\1)[^\\\\\\r\\n])*\\1/;\n\n\tPrism.languages.css = {\n\t\t'comment': /\\/\\*[\\s\\S]*?\\*\\//,\n\t\t'atrule': {\n\t\t\tpattern: /@[\\w-]+?[\\s\\S]*?(?:;|(?=\\s*\\{))/i,\n\t\t\tinside: {\n\t\t\t\t'rule': /@[\\w-]+/\n\t\t\t\t// See rest below\n\t\t\t}\n\t\t},\n\t\t'url': RegExp('url\\\\((?:' + string.source + '|.*?)\\\\)', 'i'),\n\t\t'selector': RegExp('[^{}\\\\s](?:[^{};\"\\']|' + string.source + ')*?(?=\\\\s*\\\\{)'),\n\t\t'string': {\n\t\t\tpattern: string,\n\t\t\tgreedy: true\n\t\t},\n\t\t'property': /[-_a-z\\xA0-\\uFFFF][-\\w\\xA0-\\uFFFF]*(?=\\s*:)/i,\n\t\t'important': /!important\\b/i,\n\t\t'function': /[-a-z0-9]+(?=\\()/i,\n\t\t'punctuation': /[(){};:,]/\n\t};\n\n\tPrism.languages.css['atrule'].inside.rest = Prism.languages.css;\n\n\tvar markup = Prism.languages.markup;\n\tif (markup) {\n\t\tmarkup.tag.addInlined('style', 'css');\n\n\t\tPrism.languages.insertBefore('inside', 'attr-value', {\n\t\t\t'style-attr': {\n\t\t\t\tpattern: /\\s*style=(\"|')(?:\\\\[\\s\\S]|(?!\\1)[^\\\\])*\\1/i,\n\t\t\t\tinside: {\n\t\t\t\t\t'attr-name': {\n\t\t\t\t\t\tpattern: /^\\s*style/i,\n\t\t\t\t\t\tinside: markup.tag.inside\n\t\t\t\t\t},\n\t\t\t\t\t'punctuation': /^\\s*=\\s*['\"]|['\"]\\s*$/,\n\t\t\t\t\t'attr-value': {\n\t\t\t\t\t\tpattern: /.+/i,\n\t\t\t\t\t\tinside: Prism.languages.css\n\t\t\t\t\t}\n\t\t\t\t},\n\t\t\t\talias: 'language-css'\n\t\t\t}\n\t\t}, markup.tag);\n\t}\n\n}(Prism));\n\n\n/* **********************************************\n     Begin prism-clike.js\n********************************************** */\n\nPrism.languages.clike = {\n\t'comment': [\n\t\t{\n\t\t\tpattern: /(^|[^\\\\])\\/\\*[\\s\\S]*?(?:\\*\\/|$)/,\n\t\t\tlookbehind: true\n\t\t},\n\t\t{\n\t\t\tpattern: /(^|[^\\\\:])\\/\\/.*/,\n\t\t\tlookbehind: true,\n\t\t\tgreedy: true\n\t\t}\n\t],\n\t'string': {\n\t\tpattern: /([\"'])(?:\\\\(?:\\r\\n|[\\s\\S])|(?!\\1)[^\\\\\\r\\n])*\\1/,\n\t\tgreedy: true\n\t},\n\t'class-name': {\n\t\tpattern: /((?:\\b(?:class|interface|extends|implements|trait|instanceof|new)\\s+)|(?:catch\\s+\\())[\\w.\\\\]+/i,\n\t\tlookbehind: true,\n\t\tinside: {\n\t\t\tpunctuation: /[.\\\\]/\n\t\t}\n\t},\n\t'keyword': /\\b(?:if|else|while|do|for|return|in|instanceof|function|new|try|throw|catch|finally|null|break|continue)\\b/,\n\t'boolean': /\\b(?:true|false)\\b/,\n\t'function': /\\w+(?=\\()/,\n\t'number': /\\b0x[\\da-f]+\\b|(?:\\b\\d+\\.?\\d*|\\B\\.\\d+)(?:e[+-]?\\d+)?/i,\n\t'operator': /--?|\\+\\+?|!=?=?|<=?|>=?|==?=?|&&?|\\|\\|?|\\?|\\*|\\/|~|\\^|%/,\n\t'punctuation': /[{}[\\];(),.:]/\n};\n\n\n/* **********************************************\n     Begin prism-javascript.js\n********************************************** */\n\nPrism.languages.javascript = Prism.languages.extend('clike', {\n\t'class-name': [\n\t\tPrism.languages.clike['class-name'],\n\t\t{\n\t\t\tpattern: /(^|[^$\\w\\xA0-\\uFFFF])[_$A-Z\\xA0-\\uFFFF][$\\w\\xA0-\\uFFFF]*(?=\\.(?:prototype|constructor))/,\n\t\t\tlookbehind: true\n\t\t}\n\t],\n\t'keyword': [\n\t\t{\n\t\t\tpattern: /((?:^|})\\s*)(?:catch|finally)\\b/,\n\t\t\tlookbehind: true\n\t\t},\n\t\t{\n\t\t\tpattern: /(^|[^.])\\b(?:as|async(?=\\s*(?:function\\b|\\(|[$\\w\\xA0-\\uFFFF]|$))|await|break|case|class|const|continue|debugger|default|delete|do|else|enum|export|extends|for|from|function|get|if|implements|import|in|instanceof|interface|let|new|null|of|package|private|protected|public|return|set|static|super|switch|this|throw|try|typeof|undefined|var|void|while|with|yield)\\b/,\n\t\t\tlookbehind: true\n\t\t},\n\t],\n\t'number': /\\b(?:(?:0[xX][\\dA-Fa-f]+|0[bB][01]+|0[oO][0-7]+)n?|\\d+n|NaN|Infinity)\\b|(?:\\b\\d+\\.?\\d*|\\B\\.\\d+)(?:[Ee][+-]?\\d+)?/,\n\t// Allow for all non-ASCII characters (See http://stackoverflow.com/a/2008444)\n\t'function': /[_$a-zA-Z\\xA0-\\uFFFF][$\\w\\xA0-\\uFFFF]*(?=\\s*(?:\\.\\s*(?:apply|bind|call)\\s*)?\\()/,\n\t'operator': /-[-=]?|\\+[+=]?|!=?=?|<<?=?|>>?>?=?|=(?:==?|>)?|&[&=]?|\\|[|=]?|\\*\\*?=?|\\/=?|~|\\^=?|%=?|\\?|\\.{3}/\n});\n\nPrism.languages.javascript['class-name'][0].pattern = /(\\b(?:class|interface|extends|implements|instanceof|new)\\s+)[\\w.\\\\]+/\n\nPrism.languages.insertBefore('javascript', 'keyword', {\n\t'regex': {\n\t\tpattern: /((?:^|[^$\\w\\xA0-\\uFFFF.\"'\\])\\s])\\s*)\\/(\\[(?:[^\\]\\\\\\r\\n]|\\\\.)*]|\\\\.|[^/\\\\\\[\\r\\n])+\\/[gimyu]{0,5}(?=\\s*($|[\\r\\n,.;})\\]]))/,\n\t\tlookbehind: true,\n\t\tgreedy: true\n\t},\n\t// This must be declared before keyword because we use \"function\" inside the look-forward\n\t'function-variable': {\n\t\tpattern: /[_$a-zA-Z\\xA0-\\uFFFF][$\\w\\xA0-\\uFFFF]*(?=\\s*[=:]\\s*(?:async\\s*)?(?:\\bfunction\\b|(?:\\((?:[^()]|\\([^()]*\\))*\\)|[_$a-zA-Z\\xA0-\\uFFFF][$\\w\\xA0-\\uFFFF]*)\\s*=>))/,\n\t\talias: 'function'\n\t},\n\t'parameter': [\n\t\t{\n\t\t\tpattern: /(function(?:\\s+[_$A-Za-z\\xA0-\\uFFFF][$\\w\\xA0-\\uFFFF]*)?\\s*\\(\\s*)(?!\\s)(?:[^()]|\\([^()]*\\))+?(?=\\s*\\))/,\n\t\t\tlookbehind: true,\n\t\t\tinside: Prism.languages.javascript\n\t\t},\n\t\t{\n\t\t\tpattern: /[_$a-z\\xA0-\\uFFFF][$\\w\\xA0-\\uFFFF]*(?=\\s*=>)/i,\n\t\t\tinside: Prism.languages.javascript\n\t\t},\n\t\t{\n\t\t\tpattern: /(\\(\\s*)(?!\\s)(?:[^()]|\\([^()]*\\))+?(?=\\s*\\)\\s*=>)/,\n\t\t\tlookbehind: true,\n\t\t\tinside: Prism.languages.javascript\n\t\t},\n\t\t{\n\t\t\tpattern: /((?:\\b|\\s|^)(?!(?:as|async|await|break|case|catch|class|const|continue|debugger|default|delete|do|else|enum|export|extends|finally|for|from|function|get|if|implements|import|in|instanceof|interface|let|new|null|of|package|private|protected|public|return|set|static|super|switch|this|throw|try|typeof|undefined|var|void|while|with|yield)(?![$\\w\\xA0-\\uFFFF]))(?:[_$A-Za-z\\xA0-\\uFFFF][$\\w\\xA0-\\uFFFF]*\\s*)\\(\\s*)(?!\\s)(?:[^()]|\\([^()]*\\))+?(?=\\s*\\)\\s*\\{)/,\n\t\t\tlookbehind: true,\n\t\t\tinside: Prism.languages.javascript\n\t\t}\n\t],\n\t'constant': /\\b[A-Z](?:[A-Z_]|\\dx?)*\\b/\n});\n\nPrism.languages.insertBefore('javascript', 'string', {\n\t'template-string': {\n\t\tpattern: /`(?:\\\\[\\s\\S]|\\${[^}]+}|[^\\\\`])*`/,\n\t\tgreedy: true,\n\t\tinside: {\n\t\t\t'interpolation': {\n\t\t\t\tpattern: /\\${[^}]+}/,\n\t\t\t\tinside: {\n\t\t\t\t\t'interpolation-punctuation': {\n\t\t\t\t\t\tpattern: /^\\${|}$/,\n\t\t\t\t\t\talias: 'punctuation'\n\t\t\t\t\t},\n\t\t\t\t\trest: Prism.languages.javascript\n\t\t\t\t}\n\t\t\t},\n\t\t\t'string': /[\\s\\S]+/\n\t\t}\n\t}\n});\n\nif (Prism.languages.markup) {\n\tPrism.languages.markup.tag.addInlined('script', 'javascript');\n}\n\nPrism.languages.js = Prism.languages.javascript;\n\n\n/* **********************************************\n     Begin prism-file-highlight.js\n********************************************** */\n\n(function () {\n\tif (typeof self === 'undefined' || !self.Prism || !self.document || !document.querySelector) {\n\t\treturn;\n\t}\n\n\t/**\n\t * @param {Element} [container=document]\n\t */\n\tself.Prism.fileHighlight = function(container) {\n\t\tcontainer = container || document;\n\n\t\tvar Extensions = {\n\t\t\t'js': 'javascript',\n\t\t\t'py': 'python',\n\t\t\t'rb': 'ruby',\n\t\t\t'ps1': 'powershell',\n\t\t\t'psm1': 'powershell',\n\t\t\t'sh': 'bash',\n\t\t\t'bat': 'batch',\n\t\t\t'h': 'c',\n\t\t\t'tex': 'latex'\n\t\t};\n\n\t\tArray.prototype.slice.call(container.querySelectorAll('pre[data-src]')).forEach(function (pre) {\n\t\t\t// ignore if already loaded\n\t\t\tif (pre.hasAttribute('data-src-loaded')) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// load current\n\t\t\tvar src = pre.getAttribute('data-src');\n\n\t\t\tvar language, parent = pre;\n\t\t\tvar lang = /\\blang(?:uage)?-([\\w-]+)\\b/i;\n\t\t\twhile (parent && !lang.test(parent.className)) {\n\t\t\t\tparent = parent.parentNode;\n\t\t\t}\n\n\t\t\tif (parent) {\n\t\t\t\tlanguage = (pre.className.match(lang) || [, ''])[1];\n\t\t\t}\n\n\t\t\tif (!language) {\n\t\t\t\tvar extension = (src.match(/\\.(\\w+)$/) || [, ''])[1];\n\t\t\t\tlanguage = Extensions[extension] || extension;\n\t\t\t}\n\n\t\t\tvar code = document.createElement('code');\n\t\t\tcode.className = 'language-' + language;\n\n\t\t\tpre.textContent = '';\n\n\t\t\tcode.textContent = 'Loading…';\n\n\t\t\tpre.appendChild(code);\n\n\t\t\tvar xhr = new XMLHttpRequest();\n\n\t\t\txhr.open('GET', src, true);\n\n\t\t\txhr.onreadystatechange = function () {\n\t\t\t\tif (xhr.readyState == 4) {\n\n\t\t\t\t\tif (xhr.status < 400 && xhr.responseText) {\n\t\t\t\t\t\tcode.textContent = xhr.responseText;\n\n\t\t\t\t\t\tPrism.highlightElement(code);\n\t\t\t\t\t\t// mark as loaded\n\t\t\t\t\t\tpre.setAttribute('data-src-loaded', '');\n\t\t\t\t\t}\n\t\t\t\t\telse if (xhr.status >= 400) {\n\t\t\t\t\t\tcode.textContent = '✖ Error ' + xhr.status + ' while fetching file: ' + xhr.statusText;\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tcode.textContent = '✖ Error: File does not exist or is empty';\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\n\t\t\txhr.send(null);\n\t\t});\n\n\t\tif (Prism.plugins.toolbar) {\n\t\t\tPrism.plugins.toolbar.registerButton('download-file', function (env) {\n\t\t\t\tvar pre = env.element.parentNode;\n\t\t\t\tif (!pre || !/pre/i.test(pre.nodeName) || !pre.hasAttribute('data-src') || !pre.hasAttribute('data-download-link')) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tvar src = pre.getAttribute('data-src');\n\t\t\t\tvar a = document.createElement('a');\n\t\t\t\ta.textContent = pre.getAttribute('data-download-link-label') || 'Download';\n\t\t\t\ta.setAttribute('download', '');\n\t\t\t\ta.href = src;\n\t\t\t\treturn a;\n\t\t\t});\n\t\t}\n\n\t};\n\n\tdocument.addEventListener('DOMContentLoaded', function () {\n\t\t// execute inside handler, for dropping Event as argument\n\t\tself.Prism.fileHighlight();\n\t});\n\n})();\n","/**\n * marked - a markdown parser\n * Copyright (c) 2011-2018, Christopher Jeffrey. (MIT Licensed)\n * https://github.com/markedjs/marked\n */\n\n;(function(root) {\n'use strict';\n\n/**\n * Block-Level Grammar\n */\n\nvar block = {\n  newline: /^\\n+/,\n  code: /^( {4}[^\\n]+\\n*)+/,\n  fences: noop,\n  hr: /^ {0,3}((?:- *){3,}|(?:_ *){3,}|(?:\\* *){3,})(?:\\n+|$)/,\n  heading: /^ *(#{1,6}) *([^\\n]+?) *(?:#+ *)?(?:\\n+|$)/,\n  nptable: noop,\n  blockquote: /^( {0,3}> ?(paragraph|[^\\n]*)(?:\\n|$))+/,\n  list: /^( *)(bull) [\\s\\S]+?(?:hr|def|\\n{2,}(?! )(?!\\1bull )\\n*|\\s*$)/,\n  html: '^ {0,3}(?:' // optional indentation\n    + '<(script|pre|style)[\\\\s>][\\\\s\\\\S]*?(?:</\\\\1>[^\\\\n]*\\\\n+|$)' // (1)\n    + '|comment[^\\\\n]*(\\\\n+|$)' // (2)\n    + '|<\\\\?[\\\\s\\\\S]*?\\\\?>\\\\n*' // (3)\n    + '|<![A-Z][\\\\s\\\\S]*?>\\\\n*' // (4)\n    + '|<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?\\\\]\\\\]>\\\\n*' // (5)\n    + '|</?(tag)(?: +|\\\\n|/?>)[\\\\s\\\\S]*?(?:\\\\n{2,}|$)' // (6)\n    + '|<(?!script|pre|style)([a-z][\\\\w-]*)(?:attribute)*? */?>(?=\\\\h*\\\\n)[\\\\s\\\\S]*?(?:\\\\n{2,}|$)' // (7) open tag\n    + '|</(?!script|pre|style)[a-z][\\\\w-]*\\\\s*>(?=\\\\h*\\\\n)[\\\\s\\\\S]*?(?:\\\\n{2,}|$)' // (7) closing tag\n    + ')',\n  def: /^ {0,3}\\[(label)\\]: *\\n? *<?([^\\s>]+)>?(?:(?: +\\n? *| *\\n *)(title))? *(?:\\n+|$)/,\n  table: noop,\n  lheading: /^([^\\n]+)\\n *(=|-){2,} *(?:\\n+|$)/,\n  paragraph: /^([^\\n]+(?:\\n(?!hr|heading|lheading| {0,3}>|<\\/?(?:tag)(?: +|\\n|\\/?>)|<(?:script|pre|style|!--))[^\\n]+)*)/,\n  text: /^[^\\n]+/\n};\n\nblock._label = /(?!\\s*\\])(?:\\\\[\\[\\]]|[^\\[\\]])+/;\nblock._title = /(?:\"(?:\\\\\"?|[^\"\\\\])*\"|'[^'\\n]*(?:\\n[^'\\n]+)*\\n?'|\\([^()]*\\))/;\nblock.def = edit(block.def)\n  .replace('label', block._label)\n  .replace('title', block._title)\n  .getRegex();\n\nblock.bullet = /(?:[*+-]|\\d+\\.)/;\nblock.item = /^( *)(bull) [^\\n]*(?:\\n(?!\\1bull )[^\\n]*)*/;\nblock.item = edit(block.item, 'gm')\n  .replace(/bull/g, block.bullet)\n  .getRegex();\n\nblock.list = edit(block.list)\n  .replace(/bull/g, block.bullet)\n  .replace('hr', '\\\\n+(?=\\\\1?(?:(?:- *){3,}|(?:_ *){3,}|(?:\\\\* *){3,})(?:\\\\n+|$))')\n  .replace('def', '\\\\n+(?=' + block.def.source + ')')\n  .getRegex();\n\nblock._tag = 'address|article|aside|base|basefont|blockquote|body|caption'\n  + '|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption'\n  + '|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe'\n  + '|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option'\n  + '|p|param|section|source|summary|table|tbody|td|tfoot|th|thead|title|tr'\n  + '|track|ul';\nblock._comment = /<!--(?!-?>)[\\s\\S]*?-->/;\nblock.html = edit(block.html, 'i')\n  .replace('comment', block._comment)\n  .replace('tag', block._tag)\n  .replace('attribute', / +[a-zA-Z:_][\\w.:-]*(?: *= *\"[^\"\\n]*\"| *= *'[^'\\n]*'| *= *[^\\s\"'=<>`]+)?/)\n  .getRegex();\n\nblock.paragraph = edit(block.paragraph)\n  .replace('hr', block.hr)\n  .replace('heading', block.heading)\n  .replace('lheading', block.lheading)\n  .replace('tag', block._tag) // pars can be interrupted by type (6) html blocks\n  .getRegex();\n\nblock.blockquote = edit(block.blockquote)\n  .replace('paragraph', block.paragraph)\n  .getRegex();\n\n/**\n * Normal Block Grammar\n */\n\nblock.normal = merge({}, block);\n\n/**\n * GFM Block Grammar\n */\n\nblock.gfm = merge({}, block.normal, {\n  fences: /^ *(`{3,}|~{3,})[ \\.]*(\\S+)? *\\n([\\s\\S]*?)\\n? *\\1 *(?:\\n+|$)/,\n  paragraph: /^/,\n  heading: /^ *(#{1,6}) +([^\\n]+?) *#* *(?:\\n+|$)/\n});\n\nblock.gfm.paragraph = edit(block.paragraph)\n  .replace('(?!', '(?!'\n    + block.gfm.fences.source.replace('\\\\1', '\\\\2') + '|'\n    + block.list.source.replace('\\\\1', '\\\\3') + '|')\n  .getRegex();\n\n/**\n * GFM + Tables Block Grammar\n */\n\nblock.tables = merge({}, block.gfm, {\n  nptable: /^ *([^|\\n ].*\\|.*)\\n *([-:]+ *\\|[-| :]*)(?:\\n((?:.*[^>\\n ].*(?:\\n|$))*)\\n*|$)/,\n  table: /^ *\\|(.+)\\n *\\|?( *[-:]+[-| :]*)(?:\\n((?: *[^>\\n ].*(?:\\n|$))*)\\n*|$)/\n});\n\n/**\n * Pedantic grammar\n */\n\nblock.pedantic = merge({}, block.normal, {\n  html: edit(\n    '^ *(?:comment *(?:\\\\n|\\\\s*$)'\n    + '|<(tag)[\\\\s\\\\S]+?</\\\\1> *(?:\\\\n{2,}|\\\\s*$)' // closed tag\n    + '|<tag(?:\"[^\"]*\"|\\'[^\\']*\\'|\\\\s[^\\'\"/>\\\\s]*)*?/?> *(?:\\\\n{2,}|\\\\s*$))')\n    .replace('comment', block._comment)\n    .replace(/tag/g, '(?!(?:'\n      + 'a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub'\n      + '|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)'\n      + '\\\\b)\\\\w+(?!:|[^\\\\w\\\\s@]*@)\\\\b')\n    .getRegex(),\n  def: /^ *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +([\"(][^\\n]+[\")]))? *(?:\\n+|$)/\n});\n\n/**\n * Block Lexer\n */\n\nfunction Lexer(options) {\n  this.tokens = [];\n  this.tokens.links = Object.create(null);\n  this.options = options || marked.defaults;\n  this.rules = block.normal;\n\n  if (this.options.pedantic) {\n    this.rules = block.pedantic;\n  } else if (this.options.gfm) {\n    if (this.options.tables) {\n      this.rules = block.tables;\n    } else {\n      this.rules = block.gfm;\n    }\n  }\n}\n\n/**\n * Expose Block Rules\n */\n\nLexer.rules = block;\n\n/**\n * Static Lex Method\n */\n\nLexer.lex = function(src, options) {\n  var lexer = new Lexer(options);\n  return lexer.lex(src);\n};\n\n/**\n * Preprocessing\n */\n\nLexer.prototype.lex = function(src) {\n  src = src\n    .replace(/\\r\\n|\\r/g, '\\n')\n    .replace(/\\t/g, '    ')\n    .replace(/\\u00a0/g, ' ')\n    .replace(/\\u2424/g, '\\n');\n\n  return this.token(src, true);\n};\n\n/**\n * Lexing\n */\n\nLexer.prototype.token = function(src, top) {\n  src = src.replace(/^ +$/gm, '');\n  var next,\n      loose,\n      cap,\n      bull,\n      b,\n      item,\n      listStart,\n      listItems,\n      t,\n      space,\n      i,\n      tag,\n      l,\n      isordered,\n      istask,\n      ischecked;\n\n  while (src) {\n    // newline\n    if (cap = this.rules.newline.exec(src)) {\n      src = src.substring(cap[0].length);\n      if (cap[0].length > 1) {\n        this.tokens.push({\n          type: 'space'\n        });\n      }\n    }\n\n    // code\n    if (cap = this.rules.code.exec(src)) {\n      src = src.substring(cap[0].length);\n      cap = cap[0].replace(/^ {4}/gm, '');\n      this.tokens.push({\n        type: 'code',\n        text: !this.options.pedantic\n          ? rtrim(cap, '\\n')\n          : cap\n      });\n      continue;\n    }\n\n    // fences (gfm)\n    if (cap = this.rules.fences.exec(src)) {\n      src = src.substring(cap[0].length);\n      this.tokens.push({\n        type: 'code',\n        lang: cap[2],\n        text: cap[3] || ''\n      });\n      continue;\n    }\n\n    // heading\n    if (cap = this.rules.heading.exec(src)) {\n      src = src.substring(cap[0].length);\n      this.tokens.push({\n        type: 'heading',\n        depth: cap[1].length,\n        text: cap[2]\n      });\n      continue;\n    }\n\n    // table no leading pipe (gfm)\n    if (top && (cap = this.rules.nptable.exec(src))) {\n      item = {\n        type: 'table',\n        header: splitCells(cap[1].replace(/^ *| *\\| *$/g, '')),\n        align: cap[2].replace(/^ *|\\| *$/g, '').split(/ *\\| */),\n        cells: cap[3] ? cap[3].replace(/\\n$/, '').split('\\n') : []\n      };\n\n      if (item.header.length === item.align.length) {\n        src = src.substring(cap[0].length);\n\n        for (i = 0; i < item.align.length; i++) {\n          if (/^ *-+: *$/.test(item.align[i])) {\n            item.align[i] = 'right';\n          } else if (/^ *:-+: *$/.test(item.align[i])) {\n            item.align[i] = 'center';\n          } else if (/^ *:-+ *$/.test(item.align[i])) {\n            item.align[i] = 'left';\n          } else {\n            item.align[i] = null;\n          }\n        }\n\n        for (i = 0; i < item.cells.length; i++) {\n          item.cells[i] = splitCells(item.cells[i], item.header.length);\n        }\n\n        this.tokens.push(item);\n\n        continue;\n      }\n    }\n\n    // hr\n    if (cap = this.rules.hr.exec(src)) {\n      src = src.substring(cap[0].length);\n      this.tokens.push({\n        type: 'hr'\n      });\n      continue;\n    }\n\n    // blockquote\n    if (cap = this.rules.blockquote.exec(src)) {\n      src = src.substring(cap[0].length);\n\n      this.tokens.push({\n        type: 'blockquote_start'\n      });\n\n      cap = cap[0].replace(/^ *> ?/gm, '');\n\n      // Pass `top` to keep the current\n      // \"toplevel\" state. This is exactly\n      // how markdown.pl works.\n      this.token(cap, top);\n\n      this.tokens.push({\n        type: 'blockquote_end'\n      });\n\n      continue;\n    }\n\n    // list\n    if (cap = this.rules.list.exec(src)) {\n      src = src.substring(cap[0].length);\n      bull = cap[2];\n      isordered = bull.length > 1;\n\n      listStart = {\n        type: 'list_start',\n        ordered: isordered,\n        start: isordered ? +bull : '',\n        loose: false\n      };\n\n      this.tokens.push(listStart);\n\n      // Get each top-level item.\n      cap = cap[0].match(this.rules.item);\n\n      listItems = [];\n      next = false;\n      l = cap.length;\n      i = 0;\n\n      for (; i < l; i++) {\n        item = cap[i];\n\n        // Remove the list item's bullet\n        // so it is seen as the next token.\n        space = item.length;\n        item = item.replace(/^ *([*+-]|\\d+\\.) +/, '');\n\n        // Outdent whatever the\n        // list item contains. Hacky.\n        if (~item.indexOf('\\n ')) {\n          space -= item.length;\n          item = !this.options.pedantic\n            ? item.replace(new RegExp('^ {1,' + space + '}', 'gm'), '')\n            : item.replace(/^ {1,4}/gm, '');\n        }\n\n        // Determine whether the next list item belongs here.\n        // Backpedal if it does not belong in this list.\n        if (this.options.smartLists && i !== l - 1) {\n          b = block.bullet.exec(cap[i + 1])[0];\n          if (bull !== b && !(bull.length > 1 && b.length > 1)) {\n            src = cap.slice(i + 1).join('\\n') + src;\n            i = l - 1;\n          }\n        }\n\n        // Determine whether item is loose or not.\n        // Use: /(^|\\n)(?! )[^\\n]+\\n\\n(?!\\s*$)/\n        // for discount behavior.\n        loose = next || /\\n\\n(?!\\s*$)/.test(item);\n        if (i !== l - 1) {\n          next = item.charAt(item.length - 1) === '\\n';\n          if (!loose) loose = next;\n        }\n\n        if (loose) {\n          listStart.loose = true;\n        }\n\n        // Check for task list items\n        istask = /^\\[[ xX]\\] /.test(item);\n        ischecked = undefined;\n        if (istask) {\n          ischecked = item[1] !== ' ';\n          item = item.replace(/^\\[[ xX]\\] +/, '');\n        }\n\n        t = {\n          type: 'list_item_start',\n          task: istask,\n          checked: ischecked,\n          loose: loose\n        };\n\n        listItems.push(t);\n        this.tokens.push(t);\n\n        // Recurse.\n        this.token(item, false);\n\n        this.tokens.push({\n          type: 'list_item_end'\n        });\n      }\n\n      if (listStart.loose) {\n        l = listItems.length;\n        i = 0;\n        for (; i < l; i++) {\n          listItems[i].loose = true;\n        }\n      }\n\n      this.tokens.push({\n        type: 'list_end'\n      });\n\n      continue;\n    }\n\n    // html\n    if (cap = this.rules.html.exec(src)) {\n      src = src.substring(cap[0].length);\n      this.tokens.push({\n        type: this.options.sanitize\n          ? 'paragraph'\n          : 'html',\n        pre: !this.options.sanitizer\n          && (cap[1] === 'pre' || cap[1] === 'script' || cap[1] === 'style'),\n        text: cap[0]\n      });\n      continue;\n    }\n\n    // def\n    if (top && (cap = this.rules.def.exec(src))) {\n      src = src.substring(cap[0].length);\n      if (cap[3]) cap[3] = cap[3].substring(1, cap[3].length - 1);\n      tag = cap[1].toLowerCase().replace(/\\s+/g, ' ');\n      if (!this.tokens.links[tag]) {\n        this.tokens.links[tag] = {\n          href: cap[2],\n          title: cap[3]\n        };\n      }\n      continue;\n    }\n\n    // table (gfm)\n    if (top && (cap = this.rules.table.exec(src))) {\n      item = {\n        type: 'table',\n        header: splitCells(cap[1].replace(/^ *| *\\| *$/g, '')),\n        align: cap[2].replace(/^ *|\\| *$/g, '').split(/ *\\| */),\n        cells: cap[3] ? cap[3].replace(/(?: *\\| *)?\\n$/, '').split('\\n') : []\n      };\n\n      if (item.header.length === item.align.length) {\n        src = src.substring(cap[0].length);\n\n        for (i = 0; i < item.align.length; i++) {\n          if (/^ *-+: *$/.test(item.align[i])) {\n            item.align[i] = 'right';\n          } else if (/^ *:-+: *$/.test(item.align[i])) {\n            item.align[i] = 'center';\n          } else if (/^ *:-+ *$/.test(item.align[i])) {\n            item.align[i] = 'left';\n          } else {\n            item.align[i] = null;\n          }\n        }\n\n        for (i = 0; i < item.cells.length; i++) {\n          item.cells[i] = splitCells(\n            item.cells[i].replace(/^ *\\| *| *\\| *$/g, ''),\n            item.header.length);\n        }\n\n        this.tokens.push(item);\n\n        continue;\n      }\n    }\n\n    // lheading\n    if (cap = this.rules.lheading.exec(src)) {\n      src = src.substring(cap[0].length);\n      this.tokens.push({\n        type: 'heading',\n        depth: cap[2] === '=' ? 1 : 2,\n        text: cap[1]\n      });\n      continue;\n    }\n\n    // top-level paragraph\n    if (top && (cap = this.rules.paragraph.exec(src))) {\n      src = src.substring(cap[0].length);\n      this.tokens.push({\n        type: 'paragraph',\n        text: cap[1].charAt(cap[1].length - 1) === '\\n'\n          ? cap[1].slice(0, -1)\n          : cap[1]\n      });\n      continue;\n    }\n\n    // text\n    if (cap = this.rules.text.exec(src)) {\n      // Top-level should never reach here.\n      src = src.substring(cap[0].length);\n      this.tokens.push({\n        type: 'text',\n        text: cap[0]\n      });\n      continue;\n    }\n\n    if (src) {\n      throw new Error('Infinite loop on byte: ' + src.charCodeAt(0));\n    }\n  }\n\n  return this.tokens;\n};\n\n/**\n * Inline-Level Grammar\n */\n\nvar inline = {\n  escape: /^\\\\([!\"#$%&'()*+,\\-./:;<=>?@\\[\\]\\\\^_`{|}~])/,\n  autolink: /^<(scheme:[^\\s\\x00-\\x1f<>]*|email)>/,\n  url: noop,\n  tag: '^comment'\n    + '|^</[a-zA-Z][\\\\w:-]*\\\\s*>' // self-closing tag\n    + '|^<[a-zA-Z][\\\\w-]*(?:attribute)*?\\\\s*/?>' // open tag\n    + '|^<\\\\?[\\\\s\\\\S]*?\\\\?>' // processing instruction, e.g. <?php ?>\n    + '|^<![a-zA-Z]+\\\\s[\\\\s\\\\S]*?>' // declaration, e.g. <!DOCTYPE html>\n    + '|^<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?\\\\]\\\\]>', // CDATA section\n  link: /^!?\\[(label)\\]\\(href(?:\\s+(title))?\\s*\\)/,\n  reflink: /^!?\\[(label)\\]\\[(?!\\s*\\])((?:\\\\[\\[\\]]?|[^\\[\\]\\\\])+)\\]/,\n  nolink: /^!?\\[(?!\\s*\\])((?:\\[[^\\[\\]]*\\]|\\\\[\\[\\]]|[^\\[\\]])*)\\](?:\\[\\])?/,\n  strong: /^__([^\\s])__(?!_)|^\\*\\*([^\\s])\\*\\*(?!\\*)|^__([^\\s][\\s\\S]*?[^\\s])__(?!_)|^\\*\\*([^\\s][\\s\\S]*?[^\\s])\\*\\*(?!\\*)/,\n  em: /^_([^\\s_])_(?!_)|^\\*([^\\s*\"<\\[])\\*(?!\\*)|^_([^\\s][\\s\\S]*?[^\\s_])_(?!_|[^\\s.])|^_([^\\s_][\\s\\S]*?[^\\s])_(?!_|[^\\s.])|^\\*([^\\s\"<\\[][\\s\\S]*?[^\\s*])\\*(?!\\*)|^\\*([^\\s*\"<\\[][\\s\\S]*?[^\\s])\\*(?!\\*)/,\n  code: /^(`+)([^`]|[^`][\\s\\S]*?[^`])\\1(?!`)/,\n  br: /^( {2,}|\\\\)\\n(?!\\s*$)/,\n  del: noop,\n  text: /^(`+|[^`])[\\s\\S]*?(?=[\\\\<!\\[`*]|\\b_| {2,}\\n|$)/\n};\n\ninline._escapes = /\\\\([!\"#$%&'()*+,\\-./:;<=>?@\\[\\]\\\\^_`{|}~])/g;\n\ninline._scheme = /[a-zA-Z][a-zA-Z0-9+.-]{1,31}/;\ninline._email = /[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/;\ninline.autolink = edit(inline.autolink)\n  .replace('scheme', inline._scheme)\n  .replace('email', inline._email)\n  .getRegex();\n\ninline._attribute = /\\s+[a-zA-Z:_][\\w.:-]*(?:\\s*=\\s*\"[^\"]*\"|\\s*=\\s*'[^']*'|\\s*=\\s*[^\\s\"'=<>`]+)?/;\n\ninline.tag = edit(inline.tag)\n  .replace('comment', block._comment)\n  .replace('attribute', inline._attribute)\n  .getRegex();\n\ninline._label = /(?:\\[[^\\[\\]]*\\]|\\\\[\\[\\]]?|`[^`]*`|[^\\[\\]\\\\])*?/;\ninline._href = /\\s*(<(?:\\\\[<>]?|[^\\s<>\\\\])*>|(?:\\\\[()]?|\\([^\\s\\x00-\\x1f\\\\]*\\)|[^\\s\\x00-\\x1f()\\\\])*?)/;\ninline._title = /\"(?:\\\\\"?|[^\"\\\\])*\"|'(?:\\\\'?|[^'\\\\])*'|\\((?:\\\\\\)?|[^)\\\\])*\\)/;\n\ninline.link = edit(inline.link)\n  .replace('label', inline._label)\n  .replace('href', inline._href)\n  .replace('title', inline._title)\n  .getRegex();\n\ninline.reflink = edit(inline.reflink)\n  .replace('label', inline._label)\n  .getRegex();\n\n/**\n * Normal Inline Grammar\n */\n\ninline.normal = merge({}, inline);\n\n/**\n * Pedantic Inline Grammar\n */\n\ninline.pedantic = merge({}, inline.normal, {\n  strong: /^__(?=\\S)([\\s\\S]*?\\S)__(?!_)|^\\*\\*(?=\\S)([\\s\\S]*?\\S)\\*\\*(?!\\*)/,\n  em: /^_(?=\\S)([\\s\\S]*?\\S)_(?!_)|^\\*(?=\\S)([\\s\\S]*?\\S)\\*(?!\\*)/,\n  link: edit(/^!?\\[(label)\\]\\((.*?)\\)/)\n    .replace('label', inline._label)\n    .getRegex(),\n  reflink: edit(/^!?\\[(label)\\]\\s*\\[([^\\]]*)\\]/)\n    .replace('label', inline._label)\n    .getRegex()\n});\n\n/**\n * GFM Inline Grammar\n */\n\ninline.gfm = merge({}, inline.normal, {\n  escape: edit(inline.escape).replace('])', '~|])').getRegex(),\n  _extended_email: /[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/,\n  url: /^((?:ftp|https?):\\/\\/|www\\.)(?:[a-zA-Z0-9\\-]+\\.?)+[^\\s<]*|^email/,\n  _backpedal: /(?:[^?!.,:;*_~()&]+|\\([^)]*\\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_~)]+(?!$))+/,\n  del: /^~+(?=\\S)([\\s\\S]*?\\S)~+/,\n  text: edit(inline.text)\n    .replace(']|', '~]|')\n    .replace('|$', '|https?://|ftp://|www\\\\.|[a-zA-Z0-9.!#$%&\\'*+/=?^_`{\\\\|}~-]+@|$')\n    .getRegex()\n});\n\ninline.gfm.url = edit(inline.gfm.url)\n  .replace('email', inline.gfm._extended_email)\n  .getRegex();\n/**\n * GFM + Line Breaks Inline Grammar\n */\n\ninline.breaks = merge({}, inline.gfm, {\n  br: edit(inline.br).replace('{2,}', '*').getRegex(),\n  text: edit(inline.gfm.text).replace('{2,}', '*').getRegex()\n});\n\n/**\n * Inline Lexer & Compiler\n */\n\nfunction InlineLexer(links, options) {\n  this.options = options || marked.defaults;\n  this.links = links;\n  this.rules = inline.normal;\n  this.renderer = this.options.renderer || new Renderer();\n  this.renderer.options = this.options;\n\n  if (!this.links) {\n    throw new Error('Tokens array requires a `links` property.');\n  }\n\n  if (this.options.pedantic) {\n    this.rules = inline.pedantic;\n  } else if (this.options.gfm) {\n    if (this.options.breaks) {\n      this.rules = inline.breaks;\n    } else {\n      this.rules = inline.gfm;\n    }\n  }\n}\n\n/**\n * Expose Inline Rules\n */\n\nInlineLexer.rules = inline;\n\n/**\n * Static Lexing/Compiling Method\n */\n\nInlineLexer.output = function(src, links, options) {\n  var inline = new InlineLexer(links, options);\n  return inline.output(src);\n};\n\n/**\n * Lexing/Compiling\n */\n\nInlineLexer.prototype.output = function(src) {\n  var out = '',\n      link,\n      text,\n      href,\n      title,\n      cap,\n      prevCapZero;\n\n  while (src) {\n    // escape\n    if (cap = this.rules.escape.exec(src)) {\n      src = src.substring(cap[0].length);\n      out += cap[1];\n      continue;\n    }\n\n    // autolink\n    if (cap = this.rules.autolink.exec(src)) {\n      src = src.substring(cap[0].length);\n      if (cap[2] === '@') {\n        text = escape(this.mangle(cap[1]));\n        href = 'mailto:' + text;\n      } else {\n        text = escape(cap[1]);\n        href = text;\n      }\n      out += this.renderer.link(href, null, text);\n      continue;\n    }\n\n    // url (gfm)\n    if (!this.inLink && (cap = this.rules.url.exec(src))) {\n      if (cap[2] === '@') {\n        text = escape(cap[0]);\n        href = 'mailto:' + text;\n      } else {\n        // do extended autolink path validation\n        do {\n          prevCapZero = cap[0];\n          cap[0] = this.rules._backpedal.exec(cap[0])[0];\n        } while (prevCapZero !== cap[0]);\n        text = escape(cap[0]);\n        if (cap[1] === 'www.') {\n          href = 'http://' + text;\n        } else {\n          href = text;\n        }\n      }\n      src = src.substring(cap[0].length);\n      out += this.renderer.link(href, null, text);\n      continue;\n    }\n\n    // tag\n    if (cap = this.rules.tag.exec(src)) {\n      if (!this.inLink && /^<a /i.test(cap[0])) {\n        this.inLink = true;\n      } else if (this.inLink && /^<\\/a>/i.test(cap[0])) {\n        this.inLink = false;\n      }\n      if (!this.inRawBlock && /^<(pre|code|kbd|script)(\\s|>)/i.test(cap[0])) {\n        this.inRawBlock = true;\n      } else if (this.inRawBlock && /^<\\/(pre|code|kbd|script)(\\s|>)/i.test(cap[0])) {\n        this.inRawBlock = false;\n      }\n\n      src = src.substring(cap[0].length);\n      out += this.options.sanitize\n        ? this.options.sanitizer\n          ? this.options.sanitizer(cap[0])\n          : escape(cap[0])\n        : cap[0];\n      continue;\n    }\n\n    // link\n    if (cap = this.rules.link.exec(src)) {\n      src = src.substring(cap[0].length);\n      this.inLink = true;\n      href = cap[2];\n      if (this.options.pedantic) {\n        link = /^([^'\"]*[^\\s])\\s+(['\"])(.*)\\2/.exec(href);\n\n        if (link) {\n          href = link[1];\n          title = link[3];\n        } else {\n          title = '';\n        }\n      } else {\n        title = cap[3] ? cap[3].slice(1, -1) : '';\n      }\n      href = href.trim().replace(/^<([\\s\\S]*)>$/, '$1');\n      out += this.outputLink(cap, {\n        href: InlineLexer.escapes(href),\n        title: InlineLexer.escapes(title)\n      });\n      this.inLink = false;\n      continue;\n    }\n\n    // reflink, nolink\n    if ((cap = this.rules.reflink.exec(src))\n        || (cap = this.rules.nolink.exec(src))) {\n      src = src.substring(cap[0].length);\n      link = (cap[2] || cap[1]).replace(/\\s+/g, ' ');\n      link = this.links[link.toLowerCase()];\n      if (!link || !link.href) {\n        out += cap[0].charAt(0);\n        src = cap[0].substring(1) + src;\n        continue;\n      }\n      this.inLink = true;\n      out += this.outputLink(cap, link);\n      this.inLink = false;\n      continue;\n    }\n\n    // strong\n    if (cap = this.rules.strong.exec(src)) {\n      src = src.substring(cap[0].length);\n      out += this.renderer.strong(this.output(cap[4] || cap[3] || cap[2] || cap[1]));\n      continue;\n    }\n\n    // em\n    if (cap = this.rules.em.exec(src)) {\n      src = src.substring(cap[0].length);\n      out += this.renderer.em(this.output(cap[6] || cap[5] || cap[4] || cap[3] || cap[2] || cap[1]));\n      continue;\n    }\n\n    // code\n    if (cap = this.rules.code.exec(src)) {\n      src = src.substring(cap[0].length);\n      out += this.renderer.codespan(escape(cap[2].trim(), true));\n      continue;\n    }\n\n    // br\n    if (cap = this.rules.br.exec(src)) {\n      src = src.substring(cap[0].length);\n      out += this.renderer.br();\n      continue;\n    }\n\n    // del (gfm)\n    if (cap = this.rules.del.exec(src)) {\n      src = src.substring(cap[0].length);\n      out += this.renderer.del(this.output(cap[1]));\n      continue;\n    }\n\n    // text\n    if (cap = this.rules.text.exec(src)) {\n      src = src.substring(cap[0].length);\n      if (this.inRawBlock) {\n        out += this.renderer.text(cap[0]);\n      } else {\n        out += this.renderer.text(escape(this.smartypants(cap[0])));\n      }\n      continue;\n    }\n\n    if (src) {\n      throw new Error('Infinite loop on byte: ' + src.charCodeAt(0));\n    }\n  }\n\n  return out;\n};\n\nInlineLexer.escapes = function(text) {\n  return text ? text.replace(InlineLexer.rules._escapes, '$1') : text;\n};\n\n/**\n * Compile Link\n */\n\nInlineLexer.prototype.outputLink = function(cap, link) {\n  var href = link.href,\n      title = link.title ? escape(link.title) : null;\n\n  return cap[0].charAt(0) !== '!'\n    ? this.renderer.link(href, title, this.output(cap[1]))\n    : this.renderer.image(href, title, escape(cap[1]));\n};\n\n/**\n * Smartypants Transformations\n */\n\nInlineLexer.prototype.smartypants = function(text) {\n  if (!this.options.smartypants) return text;\n  return text\n    // em-dashes\n    .replace(/---/g, '\\u2014')\n    // en-dashes\n    .replace(/--/g, '\\u2013')\n    // opening singles\n    .replace(/(^|[-\\u2014/(\\[{\"\\s])'/g, '$1\\u2018')\n    // closing singles & apostrophes\n    .replace(/'/g, '\\u2019')\n    // opening doubles\n    .replace(/(^|[-\\u2014/(\\[{\\u2018\\s])\"/g, '$1\\u201c')\n    // closing doubles\n    .replace(/\"/g, '\\u201d')\n    // ellipses\n    .replace(/\\.{3}/g, '\\u2026');\n};\n\n/**\n * Mangle Links\n */\n\nInlineLexer.prototype.mangle = function(text) {\n  if (!this.options.mangle) return text;\n  var out = '',\n      l = text.length,\n      i = 0,\n      ch;\n\n  for (; i < l; i++) {\n    ch = text.charCodeAt(i);\n    if (Math.random() > 0.5) {\n      ch = 'x' + ch.toString(16);\n    }\n    out += '&#' + ch + ';';\n  }\n\n  return out;\n};\n\n/**\n * Renderer\n */\n\nfunction Renderer(options) {\n  this.options = options || marked.defaults;\n}\n\nRenderer.prototype.code = function(code, lang, escaped) {\n  if (this.options.highlight) {\n    var out = this.options.highlight(code, lang);\n    if (out != null && out !== code) {\n      escaped = true;\n      code = out;\n    }\n  }\n\n  if (!lang) {\n    return '<pre><code>'\n      + (escaped ? code : escape(code, true))\n      + '</code></pre>';\n  }\n\n  return '<pre><code class=\"'\n    + this.options.langPrefix\n    + escape(lang, true)\n    + '\">'\n    + (escaped ? code : escape(code, true))\n    + '</code></pre>\\n';\n};\n\nRenderer.prototype.blockquote = function(quote) {\n  return '<blockquote>\\n' + quote + '</blockquote>\\n';\n};\n\nRenderer.prototype.html = function(html) {\n  return html;\n};\n\nRenderer.prototype.heading = function(text, level, raw) {\n  if (this.options.headerIds) {\n    return '<h'\n      + level\n      + ' id=\"'\n      + this.options.headerPrefix\n      + raw.toLowerCase().replace(/[^\\w]+/g, '-')\n      + '\">'\n      + text\n      + '</h'\n      + level\n      + '>\\n';\n  }\n  // ignore IDs\n  return '<h' + level + '>' + text + '</h' + level + '>\\n';\n};\n\nRenderer.prototype.hr = function() {\n  return this.options.xhtml ? '<hr/>\\n' : '<hr>\\n';\n};\n\nRenderer.prototype.list = function(body, ordered, start) {\n  var type = ordered ? 'ol' : 'ul',\n      startatt = (ordered && start !== 1) ? (' start=\"' + start + '\"') : '';\n  return '<' + type + startatt + '>\\n' + body + '</' + type + '>\\n';\n};\n\nRenderer.prototype.listitem = function(text) {\n  return '<li>' + text + '</li>\\n';\n};\n\nRenderer.prototype.checkbox = function(checked) {\n  return '<input '\n    + (checked ? 'checked=\"\" ' : '')\n    + 'disabled=\"\" type=\"checkbox\"'\n    + (this.options.xhtml ? ' /' : '')\n    + '> ';\n};\n\nRenderer.prototype.paragraph = function(text) {\n  return '<p>' + text + '</p>\\n';\n};\n\nRenderer.prototype.table = function(header, body) {\n  if (body) body = '<tbody>' + body + '</tbody>';\n\n  return '<table>\\n'\n    + '<thead>\\n'\n    + header\n    + '</thead>\\n'\n    + body\n    + '</table>\\n';\n};\n\nRenderer.prototype.tablerow = function(content) {\n  return '<tr>\\n' + content + '</tr>\\n';\n};\n\nRenderer.prototype.tablecell = function(content, flags) {\n  var type = flags.header ? 'th' : 'td';\n  var tag = flags.align\n    ? '<' + type + ' align=\"' + flags.align + '\">'\n    : '<' + type + '>';\n  return tag + content + '</' + type + '>\\n';\n};\n\n// span level renderer\nRenderer.prototype.strong = function(text) {\n  return '<strong>' + text + '</strong>';\n};\n\nRenderer.prototype.em = function(text) {\n  return '<em>' + text + '</em>';\n};\n\nRenderer.prototype.codespan = function(text) {\n  return '<code>' + text + '</code>';\n};\n\nRenderer.prototype.br = function() {\n  return this.options.xhtml ? '<br/>' : '<br>';\n};\n\nRenderer.prototype.del = function(text) {\n  return '<del>' + text + '</del>';\n};\n\nRenderer.prototype.link = function(href, title, text) {\n  href = cleanUrl(this.options.sanitize, this.options.baseUrl, href);\n  if (href === null) {\n    return text;\n  }\n  var out = '<a href=\"' + escape(href) + '\"';\n  if (title) {\n    out += ' title=\"' + title + '\"';\n  }\n  out += '>' + text + '</a>';\n  return out;\n};\n\nRenderer.prototype.image = function(href, title, text) {\n  href = cleanUrl(this.options.sanitize, this.options.baseUrl, href);\n  if (href === null) {\n    return text;\n  }\n\n  var out = '<img src=\"' + href + '\" alt=\"' + text + '\"';\n  if (title) {\n    out += ' title=\"' + title + '\"';\n  }\n  out += this.options.xhtml ? '/>' : '>';\n  return out;\n};\n\nRenderer.prototype.text = function(text) {\n  return text;\n};\n\n/**\n * TextRenderer\n * returns only the textual part of the token\n */\n\nfunction TextRenderer() {}\n\n// no need for block level renderers\n\nTextRenderer.prototype.strong =\nTextRenderer.prototype.em =\nTextRenderer.prototype.codespan =\nTextRenderer.prototype.del =\nTextRenderer.prototype.text = function (text) {\n  return text;\n};\n\nTextRenderer.prototype.link =\nTextRenderer.prototype.image = function(href, title, text) {\n  return '' + text;\n};\n\nTextRenderer.prototype.br = function() {\n  return '';\n};\n\n/**\n * Parsing & Compiling\n */\n\nfunction Parser(options) {\n  this.tokens = [];\n  this.token = null;\n  this.options = options || marked.defaults;\n  this.options.renderer = this.options.renderer || new Renderer();\n  this.renderer = this.options.renderer;\n  this.renderer.options = this.options;\n}\n\n/**\n * Static Parse Method\n */\n\nParser.parse = function(src, options) {\n  var parser = new Parser(options);\n  return parser.parse(src);\n};\n\n/**\n * Parse Loop\n */\n\nParser.prototype.parse = function(src) {\n  this.inline = new InlineLexer(src.links, this.options);\n  // use an InlineLexer with a TextRenderer to extract pure text\n  this.inlineText = new InlineLexer(\n    src.links,\n    merge({}, this.options, {renderer: new TextRenderer()})\n  );\n  this.tokens = src.reverse();\n\n  var out = '';\n  while (this.next()) {\n    out += this.tok();\n  }\n\n  return out;\n};\n\n/**\n * Next Token\n */\n\nParser.prototype.next = function() {\n  return this.token = this.tokens.pop();\n};\n\n/**\n * Preview Next Token\n */\n\nParser.prototype.peek = function() {\n  return this.tokens[this.tokens.length - 1] || 0;\n};\n\n/**\n * Parse Text Tokens\n */\n\nParser.prototype.parseText = function() {\n  var body = this.token.text;\n\n  while (this.peek().type === 'text') {\n    body += '\\n' + this.next().text;\n  }\n\n  return this.inline.output(body);\n};\n\n/**\n * Parse Current Token\n */\n\nParser.prototype.tok = function() {\n  switch (this.token.type) {\n    case 'space': {\n      return '';\n    }\n    case 'hr': {\n      return this.renderer.hr();\n    }\n    case 'heading': {\n      return this.renderer.heading(\n        this.inline.output(this.token.text),\n        this.token.depth,\n        unescape(this.inlineText.output(this.token.text)));\n    }\n    case 'code': {\n      return this.renderer.code(this.token.text,\n        this.token.lang,\n        this.token.escaped);\n    }\n    case 'table': {\n      var header = '',\n          body = '',\n          i,\n          row,\n          cell,\n          j;\n\n      // header\n      cell = '';\n      for (i = 0; i < this.token.header.length; i++) {\n        cell += this.renderer.tablecell(\n          this.inline.output(this.token.header[i]),\n          { header: true, align: this.token.align[i] }\n        );\n      }\n      header += this.renderer.tablerow(cell);\n\n      for (i = 0; i < this.token.cells.length; i++) {\n        row = this.token.cells[i];\n\n        cell = '';\n        for (j = 0; j < row.length; j++) {\n          cell += this.renderer.tablecell(\n            this.inline.output(row[j]),\n            { header: false, align: this.token.align[j] }\n          );\n        }\n\n        body += this.renderer.tablerow(cell);\n      }\n      return this.renderer.table(header, body);\n    }\n    case 'blockquote_start': {\n      body = '';\n\n      while (this.next().type !== 'blockquote_end') {\n        body += this.tok();\n      }\n\n      return this.renderer.blockquote(body);\n    }\n    case 'list_start': {\n      body = '';\n      var ordered = this.token.ordered,\n          start = this.token.start;\n\n      while (this.next().type !== 'list_end') {\n        body += this.tok();\n      }\n\n      return this.renderer.list(body, ordered, start);\n    }\n    case 'list_item_start': {\n      body = '';\n      var loose = this.token.loose;\n\n      if (this.token.task) {\n        body += this.renderer.checkbox(this.token.checked);\n      }\n\n      while (this.next().type !== 'list_item_end') {\n        body += !loose && this.token.type === 'text'\n          ? this.parseText()\n          : this.tok();\n      }\n\n      return this.renderer.listitem(body);\n    }\n    case 'html': {\n      // TODO parse inline content if parameter markdown=1\n      return this.renderer.html(this.token.text);\n    }\n    case 'paragraph': {\n      return this.renderer.paragraph(this.inline.output(this.token.text));\n    }\n    case 'text': {\n      return this.renderer.paragraph(this.parseText());\n    }\n  }\n};\n\n/**\n * Helpers\n */\n\nfunction escape(html, encode) {\n  if (encode) {\n    if (escape.escapeTest.test(html)) {\n      return html.replace(escape.escapeReplace, function (ch) { return escape.replacements[ch]; });\n    }\n  } else {\n    if (escape.escapeTestNoEncode.test(html)) {\n      return html.replace(escape.escapeReplaceNoEncode, function (ch) { return escape.replacements[ch]; });\n    }\n  }\n\n  return html;\n}\n\nescape.escapeTest = /[&<>\"']/;\nescape.escapeReplace = /[&<>\"']/g;\nescape.replacements = {\n  '&': '&amp;',\n  '<': '&lt;',\n  '>': '&gt;',\n  '\"': '&quot;',\n  \"'\": '&#39;'\n};\n\nescape.escapeTestNoEncode = /[<>\"']|&(?!#?\\w+;)/;\nescape.escapeReplaceNoEncode = /[<>\"']|&(?!#?\\w+;)/g;\n\nfunction unescape(html) {\n  // explicitly match decimal, hex, and named HTML entities\n  return html.replace(/&(#(?:\\d+)|(?:#x[0-9A-Fa-f]+)|(?:\\w+));?/ig, function(_, n) {\n    n = n.toLowerCase();\n    if (n === 'colon') return ':';\n    if (n.charAt(0) === '#') {\n      return n.charAt(1) === 'x'\n        ? String.fromCharCode(parseInt(n.substring(2), 16))\n        : String.fromCharCode(+n.substring(1));\n    }\n    return '';\n  });\n}\n\nfunction edit(regex, opt) {\n  regex = regex.source || regex;\n  opt = opt || '';\n  return {\n    replace: function(name, val) {\n      val = val.source || val;\n      val = val.replace(/(^|[^\\[])\\^/g, '$1');\n      regex = regex.replace(name, val);\n      return this;\n    },\n    getRegex: function() {\n      return new RegExp(regex, opt);\n    }\n  };\n}\n\nfunction cleanUrl(sanitize, base, href) {\n  if (sanitize) {\n    try {\n      var prot = decodeURIComponent(unescape(href))\n        .replace(/[^\\w:]/g, '')\n        .toLowerCase();\n    } catch (e) {\n      return null;\n    }\n    if (prot.indexOf('javascript:') === 0 || prot.indexOf('vbscript:') === 0 || prot.indexOf('data:') === 0) {\n      return null;\n    }\n  }\n  if (base && !originIndependentUrl.test(href)) {\n    href = resolveUrl(base, href);\n  }\n  try {\n    href = encodeURI(href).replace(/%25/g, '%');\n  } catch (e) {\n    return null;\n  }\n  return href;\n}\n\nfunction resolveUrl(base, href) {\n  if (!baseUrls[' ' + base]) {\n    // we can ignore everything in base after the last slash of its path component,\n    // but we might need to add _that_\n    // https://tools.ietf.org/html/rfc3986#section-3\n    if (/^[^:]+:\\/*[^/]*$/.test(base)) {\n      baseUrls[' ' + base] = base + '/';\n    } else {\n      baseUrls[' ' + base] = rtrim(base, '/', true);\n    }\n  }\n  base = baseUrls[' ' + base];\n\n  if (href.slice(0, 2) === '//') {\n    return base.replace(/:[\\s\\S]*/, ':') + href;\n  } else if (href.charAt(0) === '/') {\n    return base.replace(/(:\\/*[^/]*)[\\s\\S]*/, '$1') + href;\n  } else {\n    return base + href;\n  }\n}\nvar baseUrls = {};\nvar originIndependentUrl = /^$|^[a-z][a-z0-9+.-]*:|^[?#]/i;\n\nfunction noop() {}\nnoop.exec = noop;\n\nfunction merge(obj) {\n  var i = 1,\n      target,\n      key;\n\n  for (; i < arguments.length; i++) {\n    target = arguments[i];\n    for (key in target) {\n      if (Object.prototype.hasOwnProperty.call(target, key)) {\n        obj[key] = target[key];\n      }\n    }\n  }\n\n  return obj;\n}\n\nfunction splitCells(tableRow, count) {\n  // ensure that every cell-delimiting pipe has a space\n  // before it to distinguish it from an escaped pipe\n  var row = tableRow.replace(/\\|/g, function (match, offset, str) {\n        var escaped = false,\n            curr = offset;\n        while (--curr >= 0 && str[curr] === '\\\\') escaped = !escaped;\n        if (escaped) {\n          // odd number of slashes means | is escaped\n          // so we leave it alone\n          return '|';\n        } else {\n          // add space before unescaped |\n          return ' |';\n        }\n      }),\n      cells = row.split(/ \\|/),\n      i = 0;\n\n  if (cells.length > count) {\n    cells.splice(count);\n  } else {\n    while (cells.length < count) cells.push('');\n  }\n\n  for (; i < cells.length; i++) {\n    // leading or trailing whitespace is ignored per the gfm spec\n    cells[i] = cells[i].trim().replace(/\\\\\\|/g, '|');\n  }\n  return cells;\n}\n\n// Remove trailing 'c's. Equivalent to str.replace(/c*$/, '').\n// /c*$/ is vulnerable to REDOS.\n// invert: Remove suffix of non-c chars instead. Default falsey.\nfunction rtrim(str, c, invert) {\n  if (str.length === 0) {\n    return '';\n  }\n\n  // Length of suffix matching the invert condition.\n  var suffLen = 0;\n\n  // Step left until we fail to match the invert condition.\n  while (suffLen < str.length) {\n    var currChar = str.charAt(str.length - suffLen - 1);\n    if (currChar === c && !invert) {\n      suffLen++;\n    } else if (currChar !== c && invert) {\n      suffLen++;\n    } else {\n      break;\n    }\n  }\n\n  return str.substr(0, str.length - suffLen);\n}\n\n/**\n * Marked\n */\n\nfunction marked(src, opt, callback) {\n  // throw error in case of non string input\n  if (typeof src === 'undefined' || src === null) {\n    throw new Error('marked(): input parameter is undefined or null');\n  }\n  if (typeof src !== 'string') {\n    throw new Error('marked(): input parameter is of type '\n      + Object.prototype.toString.call(src) + ', string expected');\n  }\n\n  if (callback || typeof opt === 'function') {\n    if (!callback) {\n      callback = opt;\n      opt = null;\n    }\n\n    opt = merge({}, marked.defaults, opt || {});\n\n    var highlight = opt.highlight,\n        tokens,\n        pending,\n        i = 0;\n\n    try {\n      tokens = Lexer.lex(src, opt);\n    } catch (e) {\n      return callback(e);\n    }\n\n    pending = tokens.length;\n\n    var done = function(err) {\n      if (err) {\n        opt.highlight = highlight;\n        return callback(err);\n      }\n\n      var out;\n\n      try {\n        out = Parser.parse(tokens, opt);\n      } catch (e) {\n        err = e;\n      }\n\n      opt.highlight = highlight;\n\n      return err\n        ? callback(err)\n        : callback(null, out);\n    };\n\n    if (!highlight || highlight.length < 3) {\n      return done();\n    }\n\n    delete opt.highlight;\n\n    if (!pending) return done();\n\n    for (; i < tokens.length; i++) {\n      (function(token) {\n        if (token.type !== 'code') {\n          return --pending || done();\n        }\n        return highlight(token.text, token.lang, function(err, code) {\n          if (err) return done(err);\n          if (code == null || code === token.text) {\n            return --pending || done();\n          }\n          token.text = code;\n          token.escaped = true;\n          --pending || done();\n        });\n      })(tokens[i]);\n    }\n\n    return;\n  }\n  try {\n    if (opt) opt = merge({}, marked.defaults, opt);\n    return Parser.parse(Lexer.lex(src, opt), opt);\n  } catch (e) {\n    e.message += '\\nPlease report this to https://github.com/markedjs/marked.';\n    if ((opt || marked.defaults).silent) {\n      return '<p>An error occurred:</p><pre>'\n        + escape(e.message + '', true)\n        + '</pre>';\n    }\n    throw e;\n  }\n}\n\n/**\n * Options\n */\n\nmarked.options =\nmarked.setOptions = function(opt) {\n  merge(marked.defaults, opt);\n  return marked;\n};\n\nmarked.getDefaults = function () {\n  return {\n    baseUrl: null,\n    breaks: false,\n    gfm: true,\n    headerIds: true,\n    headerPrefix: '',\n    highlight: null,\n    langPrefix: 'language-',\n    mangle: true,\n    pedantic: false,\n    renderer: new Renderer(),\n    sanitize: false,\n    sanitizer: null,\n    silent: false,\n    smartLists: false,\n    smartypants: false,\n    tables: true,\n    xhtml: false\n  };\n};\n\nmarked.defaults = marked.getDefaults();\n\n/**\n * Expose\n */\n\nmarked.Parser = Parser;\nmarked.parser = Parser.parse;\n\nmarked.Renderer = Renderer;\nmarked.TextRenderer = TextRenderer;\n\nmarked.Lexer = Lexer;\nmarked.lexer = Lexer.lex;\n\nmarked.InlineLexer = InlineLexer;\nmarked.inlineLexer = InlineLexer.output;\n\nmarked.parse = marked;\n\nif (typeof module !== 'undefined' && typeof exports === 'object') {\n  module.exports = marked;\n} else if (typeof define === 'function' && define.amd) {\n  define(function() { return marked; });\n} else {\n  root.marked = marked;\n}\n})(this || (typeof window !== 'undefined' ? window : global));\n","/**\n * elasticlunr - http://weixsong.github.io\n * Lightweight full-text search engine in Javascript for browser search and offline search. - 0.9.5\n *\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n * MIT Licensed\n * @license\n */\n\n(function(){\n\n/*!\n * elasticlunr.js\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * Convenience function for instantiating a new elasticlunr index and configuring it\n * with the default pipeline functions and the passed config function.\n *\n * When using this convenience function a new index will be created with the\n * following functions already in the pipeline:\n * \n * 1. elasticlunr.trimmer - trim non-word character\n * 2. elasticlunr.StopWordFilter - filters out any stop words before they enter the\n * index\n * 3. elasticlunr.stemmer - stems the tokens before entering the index.\n *\n *\n * Example:\n *\n *     var idx = elasticlunr(function () {\n *       this.addField('id');\n *       this.addField('title');\n *       this.addField('body');\n *       \n *       //this.setRef('id'); // default ref is 'id'\n *\n *       this.pipeline.add(function () {\n *         // some custom pipeline function\n *       });\n *     });\n * \n *    idx.addDoc({\n *      id: 1, \n *      title: 'Oracle released database 12g',\n *      body: 'Yestaday, Oracle has released their latest database, named 12g, more robust. this product will increase Oracle profit.'\n *    });\n * \n *    idx.addDoc({\n *      id: 2, \n *      title: 'Oracle released annual profit report',\n *      body: 'Yestaday, Oracle has released their annual profit report of 2015, total profit is 12.5 Billion.'\n *    });\n * \n *    # simple search\n *    idx.search('oracle database');\n * \n *    # search with query-time boosting\n *    idx.search('oracle database', {fields: {title: {boost: 2}, body: {boost: 1}}});\n *\n * @param {Function} config A function that will be called with the new instance\n * of the elasticlunr.Index as both its context and first parameter. It can be used to\n * customize the instance of new elasticlunr.Index.\n * @namespace\n * @module\n * @return {elasticlunr.Index}\n *\n */\nvar elasticlunr = function (config) {\n  var idx = new elasticlunr.Index;\n\n  idx.pipeline.add(\n    elasticlunr.trimmer,\n    elasticlunr.stopWordFilter,\n    elasticlunr.stemmer\n  );\n\n  if (config) config.call(idx, idx);\n\n  return idx;\n};\n\nelasticlunr.version = \"0.9.5\";\n\n// only used this to make elasticlunr.js compatible with lunr-languages\n// this is a trick to define a global alias of elasticlunr\nlunr = elasticlunr;\n\n/*!\n * elasticlunr.utils\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * A namespace containing utils for the rest of the elasticlunr library\n */\nelasticlunr.utils = {};\n\n/**\n * Print a warning message to the console.\n *\n * @param {String} message The message to be printed.\n * @memberOf Utils\n */\nelasticlunr.utils.warn = (function (global) {\n  return function (message) {\n    if (global.console && console.warn) {\n      console.warn(message);\n    }\n  };\n})(this);\n\n/**\n * Convert an object to string.\n *\n * In the case of `null` and `undefined` the function returns\n * an empty string, in all other cases the result of calling\n * `toString` on the passed object is returned.\n *\n * @param {object} obj The object to convert to a string.\n * @return {String} string representation of the passed object.\n * @memberOf Utils\n */\nelasticlunr.utils.toString = function (obj) {\n  if (obj === void 0 || obj === null) {\n    return \"\";\n  }\n\n  return obj.toString();\n};\n/*!\n * elasticlunr.EventEmitter\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * elasticlunr.EventEmitter is an event emitter for elasticlunr.\n * It manages adding and removing event handlers and triggering events and their handlers.\n *\n * Each event could has multiple corresponding functions,\n * these functions will be called as the sequence that they are added into the event.\n * \n * @constructor\n */\nelasticlunr.EventEmitter = function () {\n  this.events = {};\n};\n\n/**\n * Binds a handler function to a specific event(s).\n *\n * Can bind a single function to many different events in one call.\n *\n * @param {String} [eventName] The name(s) of events to bind this function to.\n * @param {Function} fn The function to call when an event is fired.\n * @memberOf EventEmitter\n */\nelasticlunr.EventEmitter.prototype.addListener = function () {\n  var args = Array.prototype.slice.call(arguments),\n      fn = args.pop(),\n      names = args;\n\n  if (typeof fn !== \"function\") throw new TypeError (\"last argument must be a function\");\n\n  names.forEach(function (name) {\n    if (!this.hasHandler(name)) this.events[name] = [];\n    this.events[name].push(fn);\n  }, this);\n};\n\n/**\n * Removes a handler function from a specific event.\n *\n * @param {String} eventName The name of the event to remove this function from.\n * @param {Function} fn The function to remove from an event.\n * @memberOf EventEmitter\n */\nelasticlunr.EventEmitter.prototype.removeListener = function (name, fn) {\n  if (!this.hasHandler(name)) return;\n\n  var fnIndex = this.events[name].indexOf(fn);\n  if (fnIndex === -1) return;\n\n  this.events[name].splice(fnIndex, 1);\n\n  if (this.events[name].length == 0) delete this.events[name];\n};\n\n/**\n * Call all functions that bounded to the given event.\n *\n * Additional data can be passed to the event handler as arguments to `emit`\n * after the event name.\n *\n * @param {String} eventName The name of the event to emit.\n * @memberOf EventEmitter\n */\nelasticlunr.EventEmitter.prototype.emit = function (name) {\n  if (!this.hasHandler(name)) return;\n\n  var args = Array.prototype.slice.call(arguments, 1);\n\n  this.events[name].forEach(function (fn) {\n    fn.apply(undefined, args);\n  }, this);\n};\n\n/**\n * Checks whether a handler has ever been stored against an event.\n *\n * @param {String} eventName The name of the event to check.\n * @private\n * @memberOf EventEmitter\n */\nelasticlunr.EventEmitter.prototype.hasHandler = function (name) {\n  return name in this.events;\n};\n/*!\n * elasticlunr.tokenizer\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * A function for splitting a string into tokens.\n * Currently English is supported as default.\n * Uses `elasticlunr.tokenizer.seperator` to split strings, you could change\n * the value of this property to set how you want strings are split into tokens.\n * IMPORTANT: use elasticlunr.tokenizer.seperator carefully, if you are not familiar with\n * text process, then you'd better not change it.\n *\n * @module\n * @param {String} str The string that you want to tokenize.\n * @see elasticlunr.tokenizer.seperator\n * @return {Array}\n */\nelasticlunr.tokenizer = function (str) {\n  if (!arguments.length || str === null || str === undefined) return [];\n  if (Array.isArray(str)) {\n    var arr = str.filter(function(token) {\n      if (token === null || token === undefined) {\n        return false;\n      }\n\n      return true;\n    });\n\n    arr = arr.map(function (t) {\n      return elasticlunr.utils.toString(t).toLowerCase();\n    });\n\n    var out = [];\n    arr.forEach(function(item) {\n      var tokens = item.split(elasticlunr.tokenizer.seperator);\n      out = out.concat(tokens);\n    }, this);\n\n    return out;\n  }\n\n  return str.toString().trim().toLowerCase().split(elasticlunr.tokenizer.seperator);\n};\n\n/**\n * Default string seperator.\n */\nelasticlunr.tokenizer.defaultSeperator = /[\\s\\-]+/;\n\n/**\n * The sperator used to split a string into tokens. Override this property to change the behaviour of\n * `elasticlunr.tokenizer` behaviour when tokenizing strings. By default this splits on whitespace and hyphens.\n *\n * @static\n * @see elasticlunr.tokenizer\n */\nelasticlunr.tokenizer.seperator = elasticlunr.tokenizer.defaultSeperator;\n\n/**\n * Set up customized string seperator\n *\n * @param {Object} sep The customized seperator that you want to use to tokenize a string.\n */\nelasticlunr.tokenizer.setSeperator = function(sep) {\n    if (sep !== null && sep !== undefined && typeof(sep) === 'object') {\n        elasticlunr.tokenizer.seperator = sep;\n    }\n}\n\n/**\n * Reset string seperator\n *\n */\nelasticlunr.tokenizer.resetSeperator = function() {\n    elasticlunr.tokenizer.seperator = elasticlunr.tokenizer.defaultSeperator;\n}\n\n/**\n * Get string seperator\n *\n */\nelasticlunr.tokenizer.getSeperator = function() {\n    return elasticlunr.tokenizer.seperator;\n}\n/*!\n * elasticlunr.Pipeline\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * elasticlunr.Pipelines maintain an ordered list of functions to be applied to \n * both documents tokens and query tokens.\n *\n * An instance of elasticlunr.Index will contain a pipeline\n * with a trimmer, a stop word filter, an English stemmer. Extra\n * functions can be added before or after either of these functions or these\n * default functions can be removed.\n *\n * When run the pipeline, it will call each function in turn.\n *\n * The output of the functions in the pipeline will be passed to the next function\n * in the pipeline. To exclude a token from entering the index the function\n * should return undefined, the rest of the pipeline will not be called with\n * this token.\n *\n * For serialisation of pipelines to work, all functions used in an instance of\n * a pipeline should be registered with elasticlunr.Pipeline. Registered functions can\n * then be loaded. If trying to load a serialised pipeline that uses functions\n * that are not registered an error will be thrown.\n *\n * If not planning on serialising the pipeline then registering pipeline functions\n * is not necessary.\n *\n * @constructor\n */\nelasticlunr.Pipeline = function () {\n  this._queue = [];\n};\n\nelasticlunr.Pipeline.registeredFunctions = {};\n\n/**\n * Register a function in the pipeline.\n *\n * Functions that are used in the pipeline should be registered if the pipeline\n * needs to be serialised, or a serialised pipeline needs to be loaded.\n *\n * Registering a function does not add it to a pipeline, functions must still be\n * added to instances of the pipeline for them to be used when running a pipeline.\n *\n * @param {Function} fn The function to register.\n * @param {String} label The label to register this function with\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.registerFunction = function (fn, label) {\n  if (label in elasticlunr.Pipeline.registeredFunctions) {\n    elasticlunr.utils.warn('Overwriting existing registered function: ' + label);\n  }\n\n  fn.label = label;\n  elasticlunr.Pipeline.registeredFunctions[label] = fn;\n};\n\n/**\n * Get a registered function in the pipeline.\n *\n * @param {String} label The label of registered function.\n * @return {Function}\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.getRegisteredFunction = function (label) {\n  if ((label in elasticlunr.Pipeline.registeredFunctions) !== true) {\n    return null;\n  }\n\n  return elasticlunr.Pipeline.registeredFunctions[label];\n};\n\n/**\n * Warns if the function is not registered as a Pipeline function.\n *\n * @param {Function} fn The function to check for.\n * @private\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.warnIfFunctionNotRegistered = function (fn) {\n  var isRegistered = fn.label && (fn.label in this.registeredFunctions);\n\n  if (!isRegistered) {\n    elasticlunr.utils.warn('Function is not registered with pipeline. This may cause problems when serialising the index.\\n', fn);\n  }\n};\n\n/**\n * Loads a previously serialised pipeline.\n *\n * All functions to be loaded must already be registered with elasticlunr.Pipeline.\n * If any function from the serialised data has not been registered then an\n * error will be thrown.\n *\n * @param {Object} serialised The serialised pipeline to load.\n * @return {elasticlunr.Pipeline}\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.load = function (serialised) {\n  var pipeline = new elasticlunr.Pipeline;\n\n  serialised.forEach(function (fnName) {\n    var fn = elasticlunr.Pipeline.getRegisteredFunction(fnName);\n\n    if (fn) {\n      pipeline.add(fn);\n    } else {\n      throw new Error('Cannot load un-registered function: ' + fnName);\n    }\n  });\n\n  return pipeline;\n};\n\n/**\n * Adds new functions to the end of the pipeline.\n *\n * Logs a warning if the function has not been registered.\n *\n * @param {Function} functions Any number of functions to add to the pipeline.\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.prototype.add = function () {\n  var fns = Array.prototype.slice.call(arguments);\n\n  fns.forEach(function (fn) {\n    elasticlunr.Pipeline.warnIfFunctionNotRegistered(fn);\n    this._queue.push(fn);\n  }, this);\n};\n\n/**\n * Adds a single function after a function that already exists in the\n * pipeline.\n *\n * Logs a warning if the function has not been registered.\n * If existingFn is not found, throw an Exception.\n *\n * @param {Function} existingFn A function that already exists in the pipeline.\n * @param {Function} newFn The new function to add to the pipeline.\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.prototype.after = function (existingFn, newFn) {\n  elasticlunr.Pipeline.warnIfFunctionNotRegistered(newFn);\n\n  var pos = this._queue.indexOf(existingFn);\n  if (pos === -1) {\n    throw new Error('Cannot find existingFn');\n  }\n\n  this._queue.splice(pos + 1, 0, newFn);\n};\n\n/**\n * Adds a single function before a function that already exists in the\n * pipeline.\n *\n * Logs a warning if the function has not been registered.\n * If existingFn is not found, throw an Exception.\n *\n * @param {Function} existingFn A function that already exists in the pipeline.\n * @param {Function} newFn The new function to add to the pipeline.\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.prototype.before = function (existingFn, newFn) {\n  elasticlunr.Pipeline.warnIfFunctionNotRegistered(newFn);\n\n  var pos = this._queue.indexOf(existingFn);\n  if (pos === -1) {\n    throw new Error('Cannot find existingFn');\n  }\n\n  this._queue.splice(pos, 0, newFn);\n};\n\n/**\n * Removes a function from the pipeline.\n *\n * @param {Function} fn The function to remove from the pipeline.\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.prototype.remove = function (fn) {\n  var pos = this._queue.indexOf(fn);\n  if (pos === -1) {\n    return;\n  }\n\n  this._queue.splice(pos, 1);\n};\n\n/**\n * Runs the current list of functions that registered in the pipeline against the\n * input tokens.\n *\n * @param {Array} tokens The tokens to run through the pipeline.\n * @return {Array}\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.prototype.run = function (tokens) {\n  var out = [],\n      tokenLength = tokens.length,\n      pipelineLength = this._queue.length;\n\n  for (var i = 0; i < tokenLength; i++) {\n    var token = tokens[i];\n\n    for (var j = 0; j < pipelineLength; j++) {\n      token = this._queue[j](token, i, tokens);\n      if (token === void 0 || token === null) break;\n    };\n\n    if (token !== void 0 && token !== null) out.push(token);\n  };\n\n  return out;\n};\n\n/**\n * Resets the pipeline by removing any existing processors.\n *\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.prototype.reset = function () {\n  this._queue = [];\n};\n\n /**\n  * Get the pipeline if user want to check the pipeline.\n  *\n  * @memberOf Pipeline\n  */\n elasticlunr.Pipeline.prototype.get = function () {\n   return this._queue;\n };\n\n/**\n * Returns a representation of the pipeline ready for serialisation.\n * Only serialize pipeline function's name. Not storing function, so when\n * loading the archived JSON index file, corresponding pipeline function is \n * added by registered function of elasticlunr.Pipeline.registeredFunctions\n *\n * Logs a warning if the function has not been registered.\n *\n * @return {Array}\n * @memberOf Pipeline\n */\nelasticlunr.Pipeline.prototype.toJSON = function () {\n  return this._queue.map(function (fn) {\n    elasticlunr.Pipeline.warnIfFunctionNotRegistered(fn);\n    return fn.label;\n  });\n};\n/*!\n * elasticlunr.Index\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * elasticlunr.Index is object that manages a search index.  It contains the indexes\n * and stores all the tokens and document lookups.  It also provides the main\n * user facing API for the library.\n *\n * @constructor\n */\nelasticlunr.Index = function () {\n  this._fields = [];\n  this._ref = 'id';\n  this.pipeline = new elasticlunr.Pipeline;\n  this.documentStore = new elasticlunr.DocumentStore;\n  this.index = {};\n  this.eventEmitter = new elasticlunr.EventEmitter;\n  this._idfCache = {};\n\n  this.on('add', 'remove', 'update', (function () {\n    this._idfCache = {};\n  }).bind(this));\n};\n\n/**\n * Bind a handler to events being emitted by the index.\n *\n * The handler can be bound to many events at the same time.\n *\n * @param {String} [eventName] The name(s) of events to bind the function to.\n * @param {Function} fn The serialised set to load.\n * @memberOf Index\n */\nelasticlunr.Index.prototype.on = function () {\n  var args = Array.prototype.slice.call(arguments);\n  return this.eventEmitter.addListener.apply(this.eventEmitter, args);\n};\n\n/**\n * Removes a handler from an event being emitted by the index.\n *\n * @param {String} eventName The name of events to remove the function from.\n * @param {Function} fn The serialised set to load.\n * @memberOf Index\n */\nelasticlunr.Index.prototype.off = function (name, fn) {\n  return this.eventEmitter.removeListener(name, fn);\n};\n\n/**\n * Loads a previously serialised index.\n *\n * Issues a warning if the index being imported was serialised\n * by a different version of elasticlunr.\n *\n * @param {Object} serialisedData The serialised set to load.\n * @return {elasticlunr.Index}\n * @memberOf Index\n */\nelasticlunr.Index.load = function (serialisedData) {\n  if (serialisedData.version !== elasticlunr.version) {\n    elasticlunr.utils.warn('version mismatch: current '\n                    + elasticlunr.version + ' importing ' + serialisedData.version);\n  }\n\n  var idx = new this;\n\n  idx._fields = serialisedData.fields;\n  idx._ref = serialisedData.ref;\n  idx.documentStore = elasticlunr.DocumentStore.load(serialisedData.documentStore);\n  idx.pipeline = elasticlunr.Pipeline.load(serialisedData.pipeline);\n  idx.index = {};\n  for (var field in serialisedData.index) {\n    idx.index[field] = elasticlunr.InvertedIndex.load(serialisedData.index[field]);\n  }\n\n  return idx;\n};\n\n/**\n * Adds a field to the list of fields that will be searchable within documents in the index.\n *\n * Remember that inner index is build based on field, which means each field has one inverted index.\n *\n * Fields should be added before any documents are added to the index, fields\n * that are added after documents are added to the index will only apply to new\n * documents added to the index.\n *\n * @param {String} fieldName The name of the field within the document that should be indexed\n * @return {elasticlunr.Index}\n * @memberOf Index\n */\nelasticlunr.Index.prototype.addField = function (fieldName) {\n  this._fields.push(fieldName);\n  this.index[fieldName] = new elasticlunr.InvertedIndex;\n  return this;\n};\n\n/**\n * Sets the property used to uniquely identify documents added to the index,\n * by default this property is 'id'.\n *\n * This should only be changed before adding documents to the index, changing\n * the ref property without resetting the index can lead to unexpected results.\n *\n * @param {String} refName The property to use to uniquely identify the\n * documents in the index.\n * @param {Boolean} emitEvent Whether to emit add events, defaults to true\n * @return {elasticlunr.Index}\n * @memberOf Index\n */\nelasticlunr.Index.prototype.setRef = function (refName) {\n  this._ref = refName;\n  return this;\n};\n\n/**\n *\n * Set if the JSON format original documents are save into elasticlunr.DocumentStore\n *\n * Defaultly save all the original JSON documents.\n *\n * @param {Boolean} save Whether to save the original JSON documents.\n * @return {elasticlunr.Index}\n * @memberOf Index\n */\nelasticlunr.Index.prototype.saveDocument = function (save) {\n  this.documentStore = new elasticlunr.DocumentStore(save);\n  return this;\n};\n\n/**\n * Add a JSON format document to the index.\n *\n * This is the way new documents enter the index, this function will run the\n * fields from the document through the index's pipeline and then add it to\n * the index, it will then show up in search results.\n *\n * An 'add' event is emitted with the document that has been added and the index\n * the document has been added to. This event can be silenced by passing false\n * as the second argument to add.\n *\n * @param {Object} doc The JSON format document to add to the index.\n * @param {Boolean} emitEvent Whether or not to emit events, default true.\n * @memberOf Index\n */\nelasticlunr.Index.prototype.addDoc = function (doc, emitEvent) {\n  if (!doc) return;\n  var emitEvent = emitEvent === undefined ? true : emitEvent;\n\n  var docRef = doc[this._ref];\n\n  this.documentStore.addDoc(docRef, doc);\n  this._fields.forEach(function (field) {\n    var fieldTokens = this.pipeline.run(elasticlunr.tokenizer(doc[field]));\n    this.documentStore.addFieldLength(docRef, field, fieldTokens.length);\n\n    var tokenCount = {};\n    fieldTokens.forEach(function (token) {\n      if (token in tokenCount) tokenCount[token] += 1;\n      else tokenCount[token] = 1;\n    }, this);\n\n    for (var token in tokenCount) {\n      var termFrequency = tokenCount[token];\n      termFrequency = Math.sqrt(termFrequency);\n      this.index[field].addToken(token, { ref: docRef, tf: termFrequency });\n    }\n  }, this);\n\n  if (emitEvent) this.eventEmitter.emit('add', doc, this);\n};\n\n/**\n * Removes a document from the index by doc ref.\n *\n * To make sure documents no longer show up in search results they can be\n * removed from the index using this method.\n *\n * A 'remove' event is emitted with the document that has been removed and the index\n * the document has been removed from. This event can be silenced by passing false\n * as the second argument to remove.\n *\n * If user setting DocumentStore not storing the documents, then remove doc by docRef is not allowed.\n *\n * @param {String|Integer} docRef The document ref to remove from the index.\n * @param {Boolean} emitEvent Whether to emit remove events, defaults to true\n * @memberOf Index\n */\nelasticlunr.Index.prototype.removeDocByRef = function (docRef, emitEvent) {\n  if (!docRef) return;\n  if (this.documentStore.isDocStored() === false) {\n    return;\n  }\n\n  if (!this.documentStore.hasDoc(docRef)) return;\n  var doc = this.documentStore.getDoc(docRef);\n  this.removeDoc(doc, false);\n};\n\n/**\n * Removes a document from the index.\n * This remove operation could work even the original doc is not store in the DocumentStore.\n *\n * To make sure documents no longer show up in search results they can be\n * removed from the index using this method.\n *\n * A 'remove' event is emitted with the document that has been removed and the index\n * the document has been removed from. This event can be silenced by passing false\n * as the second argument to remove.\n *\n *\n * @param {Object} doc The document ref to remove from the index.\n * @param {Boolean} emitEvent Whether to emit remove events, defaults to true\n * @memberOf Index\n */\nelasticlunr.Index.prototype.removeDoc = function (doc, emitEvent) {\n  if (!doc) return;\n\n  var emitEvent = emitEvent === undefined ? true : emitEvent;\n\n  var docRef = doc[this._ref];\n  if (!this.documentStore.hasDoc(docRef)) return;\n\n  this.documentStore.removeDoc(docRef);\n\n  this._fields.forEach(function (field) {\n    var fieldTokens = this.pipeline.run(elasticlunr.tokenizer(doc[field]));\n    fieldTokens.forEach(function (token) {\n      this.index[field].removeToken(token, docRef);\n    }, this);\n  }, this);\n\n  if (emitEvent) this.eventEmitter.emit('remove', doc, this);\n};\n\n/**\n * Updates a document in the index.\n *\n * When a document contained within the index gets updated, fields changed,\n * added or removed, to make sure it correctly matched against search queries,\n * it should be updated in the index.\n *\n * This method is just a wrapper around `remove` and `add`\n *\n * An 'update' event is emitted with the document that has been updated and the index.\n * This event can be silenced by passing false as the second argument to update. Only\n * an update event will be fired, the 'add' and 'remove' events of the underlying calls\n * are silenced.\n *\n * @param {Object} doc The document to update in the index.\n * @param {Boolean} emitEvent Whether to emit update events, defaults to true\n * @see Index.prototype.remove\n * @see Index.prototype.add\n * @memberOf Index\n */\nelasticlunr.Index.prototype.updateDoc = function (doc, emitEvent) {\n  var emitEvent = emitEvent === undefined ? true : emitEvent;\n\n  this.removeDocByRef(doc[this._ref], false);\n  this.addDoc(doc, false);\n\n  if (emitEvent) this.eventEmitter.emit('update', doc, this);\n};\n\n/**\n * Calculates the inverse document frequency for a token within the index of a field.\n *\n * @param {String} token The token to calculate the idf of.\n * @param {String} field The field to compute idf.\n * @see Index.prototype.idf\n * @private\n * @memberOf Index\n */\nelasticlunr.Index.prototype.idf = function (term, field) {\n  var cacheKey = \"@\" + field + '/' + term;\n  if (Object.prototype.hasOwnProperty.call(this._idfCache, cacheKey)) return this._idfCache[cacheKey];\n\n  var df = this.index[field].getDocFreq(term);\n  var idf = 1 + Math.log(this.documentStore.length / (df + 1));\n  this._idfCache[cacheKey] = idf;\n\n  return idf;\n};\n\n/**\n * get fields of current index instance\n *\n * @return {Array}\n */\nelasticlunr.Index.prototype.getFields = function () {\n  return this._fields.slice();\n};\n\n/**\n * Searches the index using the passed query.\n * Queries should be a string, multiple words are allowed.\n *\n * If config is null, will search all fields defaultly, and lead to OR based query.\n * If config is specified, will search specified with query time boosting.\n *\n * All query tokens are passed through the same pipeline that document tokens\n * are passed through, so any language processing involved will be run on every\n * query term.\n *\n * Each query term is expanded, so that the term 'he' might be expanded to\n * 'hello' and 'help' if those terms were already included in the index.\n *\n * Matching documents are returned as an array of objects, each object contains\n * the matching document ref, as set for this index, and the similarity score\n * for this document against the query.\n *\n * @param {String} query The query to search the index with.\n * @param {JSON} userConfig The user query config, JSON format.\n * @return {Object}\n * @see Index.prototype.idf\n * @see Index.prototype.documentVector\n * @memberOf Index\n */\nelasticlunr.Index.prototype.search = function (query, userConfig) {\n  if (!query) return [];\n\n  var configStr = null;\n  if (userConfig != null) {\n    configStr = JSON.stringify(userConfig);\n  }\n\n  var config = new elasticlunr.Configuration(configStr, this.getFields()).get();\n\n  var queryTokens = this.pipeline.run(elasticlunr.tokenizer(query));\n\n  var queryResults = {};\n\n  for (var field in config) {\n    var fieldSearchResults = this.fieldSearch(queryTokens, field, config);\n    var fieldBoost = config[field].boost;\n\n    for (var docRef in fieldSearchResults) {\n      fieldSearchResults[docRef] = fieldSearchResults[docRef] * fieldBoost;\n    }\n\n    for (var docRef in fieldSearchResults) {\n      if (docRef in queryResults) {\n        queryResults[docRef] += fieldSearchResults[docRef];\n      } else {\n        queryResults[docRef] = fieldSearchResults[docRef];\n      }\n    }\n  }\n\n  var results = [];\n  for (var docRef in queryResults) {\n    results.push({ref: docRef, score: queryResults[docRef]});\n  }\n\n  results.sort(function (a, b) { return b.score - a.score; });\n  return results;\n};\n\n/**\n * search queryTokens in specified field.\n *\n * @param {Array} queryTokens The query tokens to query in this field.\n * @param {String} field Field to query in.\n * @param {elasticlunr.Configuration} config The user query config, JSON format.\n * @return {Object}\n */\nelasticlunr.Index.prototype.fieldSearch = function (queryTokens, fieldName, config) {\n  var booleanType = config[fieldName].bool;\n  var expand = config[fieldName].expand;\n  var boost = config[fieldName].boost;\n  var scores = null;\n  var docTokens = {};\n\n  // Do nothing if the boost is 0\n  if (boost === 0) {\n    return;\n  }\n\n  queryTokens.forEach(function (token) {\n    var tokens = [token];\n    if (expand == true) {\n      tokens = this.index[fieldName].expandToken(token);\n    }\n    // Consider every query token in turn. If expanded, each query token\n    // corresponds to a set of tokens, which is all tokens in the \n    // index matching the pattern queryToken* .\n    // For the set of tokens corresponding to a query token, find and score\n    // all matching documents. Store those scores in queryTokenScores, \n    // keyed by docRef.\n    // Then, depending on the value of booleanType, combine the scores\n    // for this query token with previous scores.  If booleanType is OR,\n    // then merge the scores by summing into the accumulated total, adding\n    // new document scores are required (effectively a union operator). \n    // If booleanType is AND, accumulate scores only if the document \n    // has previously been scored by another query token (an intersection\n    // operation0. \n    // Furthermore, since when booleanType is AND, additional \n    // query tokens can't add new documents to the result set, use the\n    // current document set to limit the processing of each new query \n    // token for efficiency (i.e., incremental intersection).\n    \n    var queryTokenScores = {};\n    tokens.forEach(function (key) {\n      var docs = this.index[fieldName].getDocs(key);\n      var idf = this.idf(key, fieldName);\n      \n      if (scores && booleanType == 'AND') {\n          // special case, we can rule out documents that have been\n          // already been filtered out because they weren't scored\n          // by previous query token passes.\n          var filteredDocs = {};\n          for (var docRef in scores) {\n              if (docRef in docs) {\n                  filteredDocs[docRef] = docs[docRef];\n              }\n          }\n          docs = filteredDocs;\n      }\n      // only record appeared token for retrieved documents for the\n      // original token, not for expaned token.\n      // beause for doing coordNorm for a retrieved document, coordNorm only care how many\n      // query token appear in that document.\n      // so expanded token should not be added into docTokens, if added, this will pollute the\n      // coordNorm\n      if (key == token) {\n        this.fieldSearchStats(docTokens, key, docs);\n      }\n\n      for (var docRef in docs) {\n        var tf = this.index[fieldName].getTermFrequency(key, docRef);\n        var fieldLength = this.documentStore.getFieldLength(docRef, fieldName);\n        var fieldLengthNorm = 1;\n        if (fieldLength != 0) {\n          fieldLengthNorm = 1 / Math.sqrt(fieldLength);\n        }\n\n        var penality = 1;\n        if (key != token) {\n          // currently I'm not sure if this penality is enough,\n          // need to do verification\n          penality = (1 - (key.length - token.length) / key.length) * 0.15;\n        }\n\n        var score = tf * idf * fieldLengthNorm * penality;\n\n        if (docRef in queryTokenScores) {\n          queryTokenScores[docRef] += score;\n        } else {\n          queryTokenScores[docRef] = score;\n        }\n      }\n    }, this);\n    \n    scores = this.mergeScores(scores, queryTokenScores, booleanType);\n  }, this);\n\n  scores = this.coordNorm(scores, docTokens, queryTokens.length);\n  return scores;\n};\n\n/**\n * Merge the scores from one set of tokens into an accumulated score table.\n * Exact operation depends on the op parameter. If op is 'AND', then only the\n * intersection of the two score lists is retained. Otherwise, the union of\n * the two score lists is returned. For internal use only.\n *\n * @param {Object} bool accumulated scores. Should be null on first call.\n * @param {String} scores new scores to merge into accumScores.\n * @param {Object} op merge operation (should be 'AND' or 'OR').\n *\n */\n\nelasticlunr.Index.prototype.mergeScores = function (accumScores, scores, op) {\n    if (!accumScores) {\n        return scores; \n    }\n    if (op == 'AND') {\n        var intersection = {};\n        for (var docRef in scores) {\n            if (docRef in accumScores) {\n                intersection[docRef] = accumScores[docRef] + scores[docRef];\n            }\n        }\n        return intersection;\n    } else {\n        for (var docRef in scores) {\n            if (docRef in accumScores) {\n                accumScores[docRef] += scores[docRef];\n            } else {\n                accumScores[docRef] = scores[docRef];\n            }\n        }\n        return accumScores;\n    }\n};\n\n\n/**\n * Record the occuring query token of retrieved doc specified by doc field.\n * Only for inner user.\n *\n * @param {Object} docTokens a data structure stores which token appears in the retrieved doc.\n * @param {String} token query token\n * @param {Object} docs the retrieved documents of the query token\n *\n */\nelasticlunr.Index.prototype.fieldSearchStats = function (docTokens, token, docs) {\n  for (var doc in docs) {\n    if (doc in docTokens) {\n      docTokens[doc].push(token);\n    } else {\n      docTokens[doc] = [token];\n    }\n  }\n};\n\n/**\n * coord norm the score of a doc.\n * if a doc contain more query tokens, then the score will larger than the doc\n * contains less query tokens.\n *\n * only for inner use.\n *\n * @param {Object} results first results\n * @param {Object} docs field search results of a token\n * @param {Integer} n query token number\n * @return {Object}\n */\nelasticlunr.Index.prototype.coordNorm = function (scores, docTokens, n) {\n  for (var doc in scores) {\n    if (!(doc in docTokens)) continue;\n    var tokens = docTokens[doc].length;\n    scores[doc] = scores[doc] * tokens / n;\n  }\n\n  return scores;\n};\n\n/**\n * Returns a representation of the index ready for serialisation.\n *\n * @return {Object}\n * @memberOf Index\n */\nelasticlunr.Index.prototype.toJSON = function () {\n  var indexJson = {};\n  this._fields.forEach(function (field) {\n    indexJson[field] = this.index[field].toJSON();\n  }, this);\n\n  return {\n    version: elasticlunr.version,\n    fields: this._fields,\n    ref: this._ref,\n    documentStore: this.documentStore.toJSON(),\n    index: indexJson,\n    pipeline: this.pipeline.toJSON()\n  };\n};\n\n/**\n * Applies a plugin to the current index.\n *\n * A plugin is a function that is called with the index as its context.\n * Plugins can be used to customise or extend the behaviour the index\n * in some way. A plugin is just a function, that encapsulated the custom\n * behaviour that should be applied to the index.\n *\n * The plugin function will be called with the index as its argument, additional\n * arguments can also be passed when calling use. The function will be called\n * with the index as its context.\n *\n * Example:\n *\n *     var myPlugin = function (idx, arg1, arg2) {\n *       // `this` is the index to be extended\n *       // apply any extensions etc here.\n *     }\n *\n *     var idx = elasticlunr(function () {\n *       this.use(myPlugin, 'arg1', 'arg2')\n *     })\n *\n * @param {Function} plugin The plugin to apply.\n * @memberOf Index\n */\nelasticlunr.Index.prototype.use = function (plugin) {\n  var args = Array.prototype.slice.call(arguments, 1);\n  args.unshift(this);\n  plugin.apply(this, args);\n};\n/*!\n * elasticlunr.DocumentStore\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * elasticlunr.DocumentStore is a simple key-value document store used for storing sets of tokens for\n * documents stored in index.\n *\n * elasticlunr.DocumentStore store original JSON format documents that you could build search snippet by this original JSON document.\n *\n * user could choose whether original JSON format document should be store, if no configuration then document will be stored defaultly.\n * If user care more about the index size, user could select not store JSON documents, then this will has some defects, such as user\n * could not use JSON document to generate snippets of search results.\n *\n * @param {Boolean} save If the original JSON document should be stored.\n * @constructor\n * @module\n */\nelasticlunr.DocumentStore = function (save) {\n  if (save === null || save === undefined) {\n    this._save = true;\n  } else {\n    this._save = save;\n  }\n\n  this.docs = {};\n  this.docInfo = {};\n  this.length = 0;\n};\n\n/**\n * Loads a previously serialised document store\n *\n * @param {Object} serialisedData The serialised document store to load.\n * @return {elasticlunr.DocumentStore}\n */\nelasticlunr.DocumentStore.load = function (serialisedData) {\n  var store = new this;\n\n  store.length = serialisedData.length;\n  store.docs = serialisedData.docs;\n  store.docInfo = serialisedData.docInfo;\n  store._save = serialisedData.save;\n\n  return store;\n};\n\n/**\n * check if current instance store the original doc\n *\n * @return {Boolean}\n */\nelasticlunr.DocumentStore.prototype.isDocStored = function () {\n  return this._save;\n};\n\n/**\n * Stores the given doc in the document store against the given id.\n * If docRef already exist, then update doc.\n *\n * Document is store by original JSON format, then you could use original document to generate search snippets.\n *\n * @param {Integer|String} docRef The key used to store the JSON format doc.\n * @param {Object} doc The JSON format doc.\n */\nelasticlunr.DocumentStore.prototype.addDoc = function (docRef, doc) {\n  if (!this.hasDoc(docRef)) this.length++;\n\n  if (this._save === true) {\n    this.docs[docRef] = clone(doc);\n  } else {\n    this.docs[docRef] = null;\n  }\n};\n\n/**\n * Retrieves the JSON doc from the document store for a given key.\n *\n * If docRef not found, return null.\n * If user set not storing the documents, return null.\n *\n * @param {Integer|String} docRef The key to lookup and retrieve from the document store.\n * @return {Object}\n * @memberOf DocumentStore\n */\nelasticlunr.DocumentStore.prototype.getDoc = function (docRef) {\n  if (this.hasDoc(docRef) === false) return null;\n  return this.docs[docRef];\n};\n\n/**\n * Checks whether the document store contains a key (docRef).\n *\n * @param {Integer|String} docRef The id to look up in the document store.\n * @return {Boolean}\n * @memberOf DocumentStore\n */\nelasticlunr.DocumentStore.prototype.hasDoc = function (docRef) {\n  return docRef in this.docs;\n};\n\n/**\n * Removes the value for a key in the document store.\n *\n * @param {Integer|String} docRef The id to remove from the document store.\n * @memberOf DocumentStore\n */\nelasticlunr.DocumentStore.prototype.removeDoc = function (docRef) {\n  if (!this.hasDoc(docRef)) return;\n\n  delete this.docs[docRef];\n  delete this.docInfo[docRef];\n  this.length--;\n};\n\n/**\n * Add field length of a document's field tokens from pipeline results.\n * The field length of a document is used to do field length normalization even without the original JSON document stored.\n *\n * @param {Integer|String} docRef document's id or reference\n * @param {String} fieldName field name\n * @param {Integer} length field length\n */\nelasticlunr.DocumentStore.prototype.addFieldLength = function (docRef, fieldName, length) {\n  if (docRef === null || docRef === undefined) return;\n  if (this.hasDoc(docRef) == false) return;\n\n  if (!this.docInfo[docRef]) this.docInfo[docRef] = {};\n  this.docInfo[docRef][fieldName] = length;\n};\n\n/**\n * Update field length of a document's field tokens from pipeline results.\n * The field length of a document is used to do field length normalization even without the original JSON document stored.\n *\n * @param {Integer|String} docRef document's id or reference\n * @param {String} fieldName field name\n * @param {Integer} length field length\n */\nelasticlunr.DocumentStore.prototype.updateFieldLength = function (docRef, fieldName, length) {\n  if (docRef === null || docRef === undefined) return;\n  if (this.hasDoc(docRef) == false) return;\n\n  this.addFieldLength(docRef, fieldName, length);\n};\n\n/**\n * get field length of a document by docRef\n *\n * @param {Integer|String} docRef document id or reference\n * @param {String} fieldName field name\n * @return {Integer} field length\n */\nelasticlunr.DocumentStore.prototype.getFieldLength = function (docRef, fieldName) {\n  if (docRef === null || docRef === undefined) return 0;\n\n  if (!(docRef in this.docs)) return 0;\n  if (!(fieldName in this.docInfo[docRef])) return 0;\n  return this.docInfo[docRef][fieldName];\n};\n\n/**\n * Returns a JSON representation of the document store used for serialisation.\n *\n * @return {Object} JSON format\n * @memberOf DocumentStore\n */\nelasticlunr.DocumentStore.prototype.toJSON = function () {\n  return {\n    docs: this.docs,\n    docInfo: this.docInfo,\n    length: this.length,\n    save: this._save\n  };\n};\n\n/**\n * Cloning object\n *\n * @param {Object} object in JSON format\n * @return {Object} copied object\n */\nfunction clone(obj) {\n  if (null === obj || \"object\" !== typeof obj) return obj;\n\n  var copy = obj.constructor();\n\n  for (var attr in obj) {\n    if (obj.hasOwnProperty(attr)) copy[attr] = obj[attr];\n  }\n\n  return copy;\n}\n/*!\n * elasticlunr.stemmer\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n * Includes code from - http://tartarus.org/~martin/PorterStemmer/js.txt\n */\n\n/**\n * elasticlunr.stemmer is an english language stemmer, this is a JavaScript\n * implementation of the PorterStemmer taken from http://tartarus.org/~martin\n *\n * @module\n * @param {String} str The string to stem\n * @return {String}\n * @see elasticlunr.Pipeline\n */\nelasticlunr.stemmer = (function(){\n  var step2list = {\n      \"ational\" : \"ate\",\n      \"tional\" : \"tion\",\n      \"enci\" : \"ence\",\n      \"anci\" : \"ance\",\n      \"izer\" : \"ize\",\n      \"bli\" : \"ble\",\n      \"alli\" : \"al\",\n      \"entli\" : \"ent\",\n      \"eli\" : \"e\",\n      \"ousli\" : \"ous\",\n      \"ization\" : \"ize\",\n      \"ation\" : \"ate\",\n      \"ator\" : \"ate\",\n      \"alism\" : \"al\",\n      \"iveness\" : \"ive\",\n      \"fulness\" : \"ful\",\n      \"ousness\" : \"ous\",\n      \"aliti\" : \"al\",\n      \"iviti\" : \"ive\",\n      \"biliti\" : \"ble\",\n      \"logi\" : \"log\"\n    },\n\n    step3list = {\n      \"icate\" : \"ic\",\n      \"ative\" : \"\",\n      \"alize\" : \"al\",\n      \"iciti\" : \"ic\",\n      \"ical\" : \"ic\",\n      \"ful\" : \"\",\n      \"ness\" : \"\"\n    },\n\n    c = \"[^aeiou]\",          // consonant\n    v = \"[aeiouy]\",          // vowel\n    C = c + \"[^aeiouy]*\",    // consonant sequence\n    V = v + \"[aeiou]*\",      // vowel sequence\n\n    mgr0 = \"^(\" + C + \")?\" + V + C,               // [C]VC... is m>0\n    meq1 = \"^(\" + C + \")?\" + V + C + \"(\" + V + \")?$\",  // [C]VC[V] is m=1\n    mgr1 = \"^(\" + C + \")?\" + V + C + V + C,       // [C]VCVC... is m>1\n    s_v = \"^(\" + C + \")?\" + v;                   // vowel in stem\n\n  var re_mgr0 = new RegExp(mgr0);\n  var re_mgr1 = new RegExp(mgr1);\n  var re_meq1 = new RegExp(meq1);\n  var re_s_v = new RegExp(s_v);\n\n  var re_1a = /^(.+?)(ss|i)es$/;\n  var re2_1a = /^(.+?)([^s])s$/;\n  var re_1b = /^(.+?)eed$/;\n  var re2_1b = /^(.+?)(ed|ing)$/;\n  var re_1b_2 = /.$/;\n  var re2_1b_2 = /(at|bl|iz)$/;\n  var re3_1b_2 = new RegExp(\"([^aeiouylsz])\\\\1$\");\n  var re4_1b_2 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n\n  var re_1c = /^(.+?[^aeiou])y$/;\n  var re_2 = /^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/;\n\n  var re_3 = /^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/;\n\n  var re_4 = /^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/;\n  var re2_4 = /^(.+?)(s|t)(ion)$/;\n\n  var re_5 = /^(.+?)e$/;\n  var re_5_1 = /ll$/;\n  var re3_5 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n\n  var porterStemmer = function porterStemmer(w) {\n    var   stem,\n      suffix,\n      firstch,\n      re,\n      re2,\n      re3,\n      re4;\n\n    if (w.length < 3) { return w; }\n\n    firstch = w.substr(0,1);\n    if (firstch == \"y\") {\n      w = firstch.toUpperCase() + w.substr(1);\n    }\n\n    // Step 1a\n    re = re_1a\n    re2 = re2_1a;\n\n    if (re.test(w)) { w = w.replace(re,\"$1$2\"); }\n    else if (re2.test(w)) { w = w.replace(re2,\"$1$2\"); }\n\n    // Step 1b\n    re = re_1b;\n    re2 = re2_1b;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      re = re_mgr0;\n      if (re.test(fp[1])) {\n        re = re_1b_2;\n        w = w.replace(re,\"\");\n      }\n    } else if (re2.test(w)) {\n      var fp = re2.exec(w);\n      stem = fp[1];\n      re2 = re_s_v;\n      if (re2.test(stem)) {\n        w = stem;\n        re2 = re2_1b_2;\n        re3 = re3_1b_2;\n        re4 = re4_1b_2;\n        if (re2.test(w)) {  w = w + \"e\"; }\n        else if (re3.test(w)) { re = re_1b_2; w = w.replace(re,\"\"); }\n        else if (re4.test(w)) { w = w + \"e\"; }\n      }\n    }\n\n    // Step 1c - replace suffix y or Y by i if preceded by a non-vowel which is not the first letter of the word (so cry -> cri, by -> by, say -> say)\n    re = re_1c;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      stem = fp[1];\n      w = stem + \"i\";\n    }\n\n    // Step 2\n    re = re_2;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      stem = fp[1];\n      suffix = fp[2];\n      re = re_mgr0;\n      if (re.test(stem)) {\n        w = stem + step2list[suffix];\n      }\n    }\n\n    // Step 3\n    re = re_3;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      stem = fp[1];\n      suffix = fp[2];\n      re = re_mgr0;\n      if (re.test(stem)) {\n        w = stem + step3list[suffix];\n      }\n    }\n\n    // Step 4\n    re = re_4;\n    re2 = re2_4;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      stem = fp[1];\n      re = re_mgr1;\n      if (re.test(stem)) {\n        w = stem;\n      }\n    } else if (re2.test(w)) {\n      var fp = re2.exec(w);\n      stem = fp[1] + fp[2];\n      re2 = re_mgr1;\n      if (re2.test(stem)) {\n        w = stem;\n      }\n    }\n\n    // Step 5\n    re = re_5;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      stem = fp[1];\n      re = re_mgr1;\n      re2 = re_meq1;\n      re3 = re3_5;\n      if (re.test(stem) || (re2.test(stem) && !(re3.test(stem)))) {\n        w = stem;\n      }\n    }\n\n    re = re_5_1;\n    re2 = re_mgr1;\n    if (re.test(w) && re2.test(w)) {\n      re = re_1b_2;\n      w = w.replace(re,\"\");\n    }\n\n    // and turn initial Y back to y\n\n    if (firstch == \"y\") {\n      w = firstch.toLowerCase() + w.substr(1);\n    }\n\n    return w;\n  };\n\n  return porterStemmer;\n})();\n\nelasticlunr.Pipeline.registerFunction(elasticlunr.stemmer, 'stemmer');\n/*!\n * elasticlunr.stopWordFilter\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * elasticlunr.stopWordFilter is an English language stop words filter, any words\n * contained in the stop word list will not be passed through the filter.\n *\n * This is intended to be used in the Pipeline. If the token does not pass the\n * filter then undefined will be returned.\n * Currently this StopwordFilter using dictionary to do O(1) time complexity stop word filtering.\n *\n * @module\n * @param {String} token The token to pass through the filter\n * @return {String}\n * @see elasticlunr.Pipeline\n */\nelasticlunr.stopWordFilter = function (token) {\n  if (token && elasticlunr.stopWordFilter.stopWords[token] !== true) {\n    return token;\n  }\n};\n\n/**\n * Remove predefined stop words\n * if user want to use customized stop words, user could use this function to delete\n * all predefined stopwords.\n *\n * @return {null}\n */\nelasticlunr.clearStopWords = function () {\n  elasticlunr.stopWordFilter.stopWords = {};\n};\n\n/**\n * Add customized stop words\n * user could use this function to add customized stop words\n * \n * @params {Array} words customized stop words\n * @return {null}\n */\nelasticlunr.addStopWords = function (words) {\n  if (words == null || Array.isArray(words) === false) return;\n\n  words.forEach(function (word) {\n    elasticlunr.stopWordFilter.stopWords[word] = true;\n  }, this);\n};\n\n/**\n * Reset to default stop words\n * user could use this function to restore default stop words\n *\n * @return {null}\n */\nelasticlunr.resetStopWords = function () {\n  elasticlunr.stopWordFilter.stopWords = elasticlunr.defaultStopWords;\n};\n\nelasticlunr.defaultStopWords = {\n  \"\": true,\n  \"a\": true,\n  \"able\": true,\n  \"about\": true,\n  \"across\": true,\n  \"after\": true,\n  \"all\": true,\n  \"almost\": true,\n  \"also\": true,\n  \"am\": true,\n  \"among\": true,\n  \"an\": true,\n  \"and\": true,\n  \"any\": true,\n  \"are\": true,\n  \"as\": true,\n  \"at\": true,\n  \"be\": true,\n  \"because\": true,\n  \"been\": true,\n  \"but\": true,\n  \"by\": true,\n  \"can\": true,\n  \"cannot\": true,\n  \"could\": true,\n  \"dear\": true,\n  \"did\": true,\n  \"do\": true,\n  \"does\": true,\n  \"either\": true,\n  \"else\": true,\n  \"ever\": true,\n  \"every\": true,\n  \"for\": true,\n  \"from\": true,\n  \"get\": true,\n  \"got\": true,\n  \"had\": true,\n  \"has\": true,\n  \"have\": true,\n  \"he\": true,\n  \"her\": true,\n  \"hers\": true,\n  \"him\": true,\n  \"his\": true,\n  \"how\": true,\n  \"however\": true,\n  \"i\": true,\n  \"if\": true,\n  \"in\": true,\n  \"into\": true,\n  \"is\": true,\n  \"it\": true,\n  \"its\": true,\n  \"just\": true,\n  \"least\": true,\n  \"let\": true,\n  \"like\": true,\n  \"likely\": true,\n  \"may\": true,\n  \"me\": true,\n  \"might\": true,\n  \"most\": true,\n  \"must\": true,\n  \"my\": true,\n  \"neither\": true,\n  \"no\": true,\n  \"nor\": true,\n  \"not\": true,\n  \"of\": true,\n  \"off\": true,\n  \"often\": true,\n  \"on\": true,\n  \"only\": true,\n  \"or\": true,\n  \"other\": true,\n  \"our\": true,\n  \"own\": true,\n  \"rather\": true,\n  \"said\": true,\n  \"say\": true,\n  \"says\": true,\n  \"she\": true,\n  \"should\": true,\n  \"since\": true,\n  \"so\": true,\n  \"some\": true,\n  \"than\": true,\n  \"that\": true,\n  \"the\": true,\n  \"their\": true,\n  \"them\": true,\n  \"then\": true,\n  \"there\": true,\n  \"these\": true,\n  \"they\": true,\n  \"this\": true,\n  \"tis\": true,\n  \"to\": true,\n  \"too\": true,\n  \"twas\": true,\n  \"us\": true,\n  \"wants\": true,\n  \"was\": true,\n  \"we\": true,\n  \"were\": true,\n  \"what\": true,\n  \"when\": true,\n  \"where\": true,\n  \"which\": true,\n  \"while\": true,\n  \"who\": true,\n  \"whom\": true,\n  \"why\": true,\n  \"will\": true,\n  \"with\": true,\n  \"would\": true,\n  \"yet\": true,\n  \"you\": true,\n  \"your\": true\n};\n\nelasticlunr.stopWordFilter.stopWords = elasticlunr.defaultStopWords;\n\nelasticlunr.Pipeline.registerFunction(elasticlunr.stopWordFilter, 'stopWordFilter');\n/*!\n * elasticlunr.trimmer\n * Copyright (C) 2016 Oliver Nightingale\n * Copyright (C) 2016 Wei Song\n */\n\n/**\n * elasticlunr.trimmer is a pipeline function for trimming non word\n * characters from the begining and end of tokens before they\n * enter the index.\n *\n * This implementation may not work correctly for non latin\n * characters and should either be removed or adapted for use\n * with languages with non-latin characters.\n *\n * @module\n * @param {String} token The token to pass through the filter\n * @return {String}\n * @see elasticlunr.Pipeline\n */\nelasticlunr.trimmer = function (token) {\n  if (token === null || token === undefined) {\n    throw new Error('token should not be undefined');\n  }\n\n  return token\n    .replace(/^\\W+/, '')\n    .replace(/\\W+$/, '');\n};\n\nelasticlunr.Pipeline.registerFunction(elasticlunr.trimmer, 'trimmer');\n/*!\n * elasticlunr.InvertedIndex\n * Copyright (C) 2016 Wei Song\n * Includes code from - http://tartarus.org/~martin/PorterStemmer/js.txt\n */\n\n/**\n * elasticlunr.InvertedIndex is used for efficiently storing and\n * lookup of documents that contain a given token.\n *\n * @constructor\n */\nelasticlunr.InvertedIndex = function () {\n  this.root = { docs: {}, df: 0 };\n};\n\n/**\n * Loads a previously serialised inverted index.\n *\n * @param {Object} serialisedData The serialised inverted index to load.\n * @return {elasticlunr.InvertedIndex}\n */\nelasticlunr.InvertedIndex.load = function (serialisedData) {\n  var idx = new this;\n  idx.root = serialisedData.root;\n\n  return idx;\n};\n\n/**\n * Adds a {token: tokenInfo} pair to the inverted index.\n * If the token already exist, then update the tokenInfo.\n *\n * tokenInfo format: { ref: 1, tf: 2}\n * tokenInfor should contains the document's ref and the tf(token frequency) of that token in\n * the document.\n *\n * By default this function starts at the root of the current inverted index, however\n * it can start at any node of the inverted index if required.\n *\n * @param {String} token \n * @param {Object} tokenInfo format: { ref: 1, tf: 2}\n * @param {Object} root An optional node at which to start looking for the\n * correct place to enter the doc, by default the root of this elasticlunr.InvertedIndex\n * is used.\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.addToken = function (token, tokenInfo, root) {\n  var root = root || this.root,\n      idx = 0;\n\n  while (idx <= token.length - 1) {\n    var key = token[idx];\n\n    if (!(key in root)) root[key] = {docs: {}, df: 0};\n    idx += 1;\n    root = root[key];\n  }\n\n  var docRef = tokenInfo.ref;\n  if (!root.docs[docRef]) {\n    // if this doc not exist, then add this doc\n    root.docs[docRef] = {tf: tokenInfo.tf};\n    root.df += 1;\n  } else {\n    // if this doc already exist, then update tokenInfo\n    root.docs[docRef] = {tf: tokenInfo.tf};\n  }\n};\n\n/**\n * Checks whether a token is in this elasticlunr.InvertedIndex.\n * \n *\n * @param {String} token The token to be checked\n * @return {Boolean}\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.hasToken = function (token) {\n  if (!token) return false;\n\n  var node = this.root;\n\n  for (var i = 0; i < token.length; i++) {\n    if (!node[token[i]]) return false;\n    node = node[token[i]];\n  }\n\n  return true;\n};\n\n/**\n * Retrieve a node from the inverted index for a given token.\n * If token not found in this InvertedIndex, return null.\n * \n *\n * @param {String} token The token to get the node for.\n * @return {Object}\n * @see InvertedIndex.prototype.get\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.getNode = function (token) {\n  if (!token) return null;\n\n  var node = this.root;\n\n  for (var i = 0; i < token.length; i++) {\n    if (!node[token[i]]) return null;\n    node = node[token[i]];\n  }\n\n  return node;\n};\n\n/**\n * Retrieve the documents of a given token.\n * If token not found, return {}.\n *\n *\n * @param {String} token The token to get the documents for.\n * @return {Object}\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.getDocs = function (token) {\n  var node = this.getNode(token);\n  if (node == null) {\n    return {};\n  }\n\n  return node.docs;\n};\n\n/**\n * Retrieve term frequency of given token in given docRef.\n * If token or docRef not found, return 0.\n *\n *\n * @param {String} token The token to get the documents for.\n * @param {String|Integer} docRef\n * @return {Integer}\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.getTermFrequency = function (token, docRef) {\n  var node = this.getNode(token);\n\n  if (node == null) {\n    return 0;\n  }\n\n  if (!(docRef in node.docs)) {\n    return 0;\n  }\n\n  return node.docs[docRef].tf;\n};\n\n/**\n * Retrieve the document frequency of given token.\n * If token not found, return 0.\n *\n *\n * @param {String} token The token to get the documents for.\n * @return {Object}\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.getDocFreq = function (token) {\n  var node = this.getNode(token);\n\n  if (node == null) {\n    return 0;\n  }\n\n  return node.df;\n};\n\n/**\n * Remove the document identified by document's ref from the token in the inverted index.\n *\n *\n * @param {String} token Remove the document from which token.\n * @param {String} ref The ref of the document to remove from given token.\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.removeToken = function (token, ref) {\n  if (!token) return;\n  var node = this.getNode(token);\n\n  if (node == null) return;\n\n  if (ref in node.docs) {\n    delete node.docs[ref];\n    node.df -= 1;\n  }\n};\n\n/**\n * Find all the possible suffixes of given token using tokens currently in the inverted index.\n * If token not found, return empty Array.\n *\n * @param {String} token The token to expand.\n * @return {Array}\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.expandToken = function (token, memo, root) {\n  if (token == null || token == '') return [];\n  var memo = memo || [];\n\n  if (root == void 0) {\n    root = this.getNode(token);\n    if (root == null) return memo;\n  }\n\n  if (root.df > 0) memo.push(token);\n\n  for (var key in root) {\n    if (key === 'docs') continue;\n    if (key === 'df') continue;\n    this.expandToken(token + key, memo, root[key]);\n  }\n\n  return memo;\n};\n\n/**\n * Returns a representation of the inverted index ready for serialisation.\n *\n * @return {Object}\n * @memberOf InvertedIndex\n */\nelasticlunr.InvertedIndex.prototype.toJSON = function () {\n  return {\n    root: this.root\n  };\n};\n\n/*!\n * elasticlunr.Configuration\n * Copyright (C) 2016 Wei Song\n */\n \n /** \n  * elasticlunr.Configuration is used to analyze the user search configuration.\n  * \n  * By elasticlunr.Configuration user could set query-time boosting, boolean model in each field.\n  * \n  * Currently configuration supports:\n  * 1. query-time boosting, user could set how to boost each field.\n  * 2. boolean model chosing, user could choose which boolean model to use for each field.\n  * 3. token expandation, user could set token expand to True to improve Recall. Default is False.\n  * \n  * Query time boosting must be configured by field category, \"boolean\" model could be configured \n  * by both field category or globally as the following example. Field configuration for \"boolean\"\n  * will overwrite global configuration.\n  * Token expand could be configured both by field category or golbally. Local field configuration will\n  * overwrite global configuration.\n  * \n  * configuration example:\n  * {\n  *   fields:{ \n  *     title: {boost: 2},\n  *     body: {boost: 1}\n  *   },\n  *   bool: \"OR\"\n  * }\n  * \n  * \"bool\" field configuation overwrite global configuation example:\n  * {\n  *   fields:{ \n  *     title: {boost: 2, bool: \"AND\"},\n  *     body: {boost: 1}\n  *   },\n  *   bool: \"OR\"\n  * }\n  * \n  * \"expand\" example:\n  * {\n  *   fields:{ \n  *     title: {boost: 2, bool: \"AND\"},\n  *     body: {boost: 1}\n  *   },\n  *   bool: \"OR\",\n  *   expand: true\n  * }\n  * \n  * \"expand\" example for field category:\n  * {\n  *   fields:{ \n  *     title: {boost: 2, bool: \"AND\", expand: true},\n  *     body: {boost: 1}\n  *   },\n  *   bool: \"OR\"\n  * }\n  * \n  * setting the boost to 0 ignores the field (this will only search the title):\n  * {\n  *   fields:{\n  *     title: {boost: 1},\n  *     body: {boost: 0}\n  *   }\n  * }\n  *\n  * then, user could search with configuration to do query-time boosting.\n  * idx.search('oracle database', {fields: {title: {boost: 2}, body: {boost: 1}}});\n  * \n  * \n  * @constructor\n  * \n  * @param {String} config user configuration\n  * @param {Array} fields fields of index instance\n  * @module\n  */\nelasticlunr.Configuration = function (config, fields) {\n  var config = config || '';\n\n  if (fields == undefined || fields == null) {\n    throw new Error('fields should not be null');\n  }\n\n  this.config = {};\n\n  var userConfig;\n  try {\n    userConfig = JSON.parse(config);\n    this.buildUserConfig(userConfig, fields);\n  } catch (error) {\n    elasticlunr.utils.warn('user configuration parse failed, will use default configuration');\n    this.buildDefaultConfig(fields);\n  }\n};\n\n/**\n * Build default search configuration.\n * \n * @param {Array} fields fields of index instance\n */\nelasticlunr.Configuration.prototype.buildDefaultConfig = function (fields) {\n  this.reset();\n  fields.forEach(function (field) {\n    this.config[field] = {\n      boost: 1,\n      bool: \"OR\",\n      expand: false\n    };\n  }, this);\n};\n\n/**\n * Build user configuration.\n * \n * @param {JSON} config User JSON configuratoin\n * @param {Array} fields fields of index instance\n */\nelasticlunr.Configuration.prototype.buildUserConfig = function (config, fields) {\n  var global_bool = \"OR\";\n  var global_expand = false;\n\n  this.reset();\n  if ('bool' in config) {\n    global_bool = config['bool'] || global_bool;\n  }\n\n  if ('expand' in config) {\n    global_expand = config['expand'] || global_expand;\n  }\n\n  if ('fields' in config) {\n    for (var field in config['fields']) {\n      if (fields.indexOf(field) > -1) {\n        var field_config = config['fields'][field];\n        var field_expand = global_expand;\n        if (field_config.expand != undefined) {\n          field_expand = field_config.expand;\n        }\n\n        this.config[field] = {\n          boost: (field_config.boost || field_config.boost === 0) ? field_config.boost : 1,\n          bool: field_config.bool || global_bool,\n          expand: field_expand\n        };\n      } else {\n        elasticlunr.utils.warn('field name in user configuration not found in index instance fields');\n      }\n    }\n  } else {\n    this.addAllFields2UserConfig(global_bool, global_expand, fields);\n  }\n};\n\n/**\n * Add all fields to user search configuration.\n * \n * @param {String} bool Boolean model\n * @param {String} expand Expand model\n * @param {Array} fields fields of index instance\n */\nelasticlunr.Configuration.prototype.addAllFields2UserConfig = function (bool, expand, fields) {\n  fields.forEach(function (field) {\n    this.config[field] = {\n      boost: 1,\n      bool: bool,\n      expand: expand\n    };\n  }, this);\n};\n\n/**\n * get current user configuration\n */\nelasticlunr.Configuration.prototype.get = function () {\n  return this.config;\n};\n\n/**\n * reset user search configuration.\n */\nelasticlunr.Configuration.prototype.reset = function () {\n  this.config = {};\n};\n/**\n * sorted_set.js is added only to make elasticlunr.js compatible with lunr-languages.\n * if elasticlunr.js support different languages by default, this will make elasticlunr.js\n * much bigger that not good for browser usage.\n *\n */\n\n\n/*!\n * lunr.SortedSet\n * Copyright (C) 2016 Oliver Nightingale\n */\n\n/**\n * lunr.SortedSets are used to maintain an array of uniq values in a sorted\n * order.\n *\n * @constructor\n */\nlunr.SortedSet = function () {\n  this.length = 0\n  this.elements = []\n}\n\n/**\n * Loads a previously serialised sorted set.\n *\n * @param {Array} serialisedData The serialised set to load.\n * @returns {lunr.SortedSet}\n * @memberOf SortedSet\n */\nlunr.SortedSet.load = function (serialisedData) {\n  var set = new this\n\n  set.elements = serialisedData\n  set.length = serialisedData.length\n\n  return set\n}\n\n/**\n * Inserts new items into the set in the correct position to maintain the\n * order.\n *\n * @param {Object} The objects to add to this set.\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.add = function () {\n  var i, element\n\n  for (i = 0; i < arguments.length; i++) {\n    element = arguments[i]\n    if (~this.indexOf(element)) continue\n    this.elements.splice(this.locationFor(element), 0, element)\n  }\n\n  this.length = this.elements.length\n}\n\n/**\n * Converts this sorted set into an array.\n *\n * @returns {Array}\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.toArray = function () {\n  return this.elements.slice()\n}\n\n/**\n * Creates a new array with the results of calling a provided function on every\n * element in this sorted set.\n *\n * Delegates to Array.prototype.map and has the same signature.\n *\n * @param {Function} fn The function that is called on each element of the\n * set.\n * @param {Object} ctx An optional object that can be used as the context\n * for the function fn.\n * @returns {Array}\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.map = function (fn, ctx) {\n  return this.elements.map(fn, ctx)\n}\n\n/**\n * Executes a provided function once per sorted set element.\n *\n * Delegates to Array.prototype.forEach and has the same signature.\n *\n * @param {Function} fn The function that is called on each element of the\n * set.\n * @param {Object} ctx An optional object that can be used as the context\n * @memberOf SortedSet\n * for the function fn.\n */\nlunr.SortedSet.prototype.forEach = function (fn, ctx) {\n  return this.elements.forEach(fn, ctx)\n}\n\n/**\n * Returns the index at which a given element can be found in the\n * sorted set, or -1 if it is not present.\n *\n * @param {Object} elem The object to locate in the sorted set.\n * @returns {Number}\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.indexOf = function (elem) {\n  var start = 0,\n      end = this.elements.length,\n      sectionLength = end - start,\n      pivot = start + Math.floor(sectionLength / 2),\n      pivotElem = this.elements[pivot]\n\n  while (sectionLength > 1) {\n    if (pivotElem === elem) return pivot\n\n    if (pivotElem < elem) start = pivot\n    if (pivotElem > elem) end = pivot\n\n    sectionLength = end - start\n    pivot = start + Math.floor(sectionLength / 2)\n    pivotElem = this.elements[pivot]\n  }\n\n  if (pivotElem === elem) return pivot\n\n  return -1\n}\n\n/**\n * Returns the position within the sorted set that an element should be\n * inserted at to maintain the current order of the set.\n *\n * This function assumes that the element to search for does not already exist\n * in the sorted set.\n *\n * @param {Object} elem The elem to find the position for in the set\n * @returns {Number}\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.locationFor = function (elem) {\n  var start = 0,\n      end = this.elements.length,\n      sectionLength = end - start,\n      pivot = start + Math.floor(sectionLength / 2),\n      pivotElem = this.elements[pivot]\n\n  while (sectionLength > 1) {\n    if (pivotElem < elem) start = pivot\n    if (pivotElem > elem) end = pivot\n\n    sectionLength = end - start\n    pivot = start + Math.floor(sectionLength / 2)\n    pivotElem = this.elements[pivot]\n  }\n\n  if (pivotElem > elem) return pivot\n  if (pivotElem < elem) return pivot + 1\n}\n\n/**\n * Creates a new lunr.SortedSet that contains the elements in the intersection\n * of this set and the passed set.\n *\n * @param {lunr.SortedSet} otherSet The set to intersect with this set.\n * @returns {lunr.SortedSet}\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.intersect = function (otherSet) {\n  var intersectSet = new lunr.SortedSet,\n      i = 0, j = 0,\n      a_len = this.length, b_len = otherSet.length,\n      a = this.elements, b = otherSet.elements\n\n  while (true) {\n    if (i > a_len - 1 || j > b_len - 1) break\n\n    if (a[i] === b[j]) {\n      intersectSet.add(a[i])\n      i++, j++\n      continue\n    }\n\n    if (a[i] < b[j]) {\n      i++\n      continue\n    }\n\n    if (a[i] > b[j]) {\n      j++\n      continue\n    }\n  };\n\n  return intersectSet\n}\n\n/**\n * Makes a copy of this set\n *\n * @returns {lunr.SortedSet}\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.clone = function () {\n  var clone = new lunr.SortedSet\n\n  clone.elements = this.toArray()\n  clone.length = clone.elements.length\n\n  return clone\n}\n\n/**\n * Creates a new lunr.SortedSet that contains the elements in the union\n * of this set and the passed set.\n *\n * @param {lunr.SortedSet} otherSet The set to union with this set.\n * @returns {lunr.SortedSet}\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.union = function (otherSet) {\n  var longSet, shortSet, unionSet\n\n  if (this.length >= otherSet.length) {\n    longSet = this, shortSet = otherSet\n  } else {\n    longSet = otherSet, shortSet = this\n  }\n\n  unionSet = longSet.clone()\n\n  for(var i = 0, shortSetElements = shortSet.toArray(); i < shortSetElements.length; i++){\n    unionSet.add(shortSetElements[i])\n  }\n\n  return unionSet\n}\n\n/**\n * Returns a representation of the sorted set ready for serialisation.\n *\n * @returns {Array}\n * @memberOf SortedSet\n */\nlunr.SortedSet.prototype.toJSON = function () {\n  return this.toArray()\n}\n  /**\n   * export the module via AMD, CommonJS or as a browser global\n   * Export code from https://github.com/umdjs/umd/blob/master/returnExports.js\n   */\n  ;(function (root, factory) {\n    if (typeof define === 'function' && define.amd) {\n      // AMD. Register as an anonymous module.\n      define(factory)\n    } else if (typeof exports === 'object') {\n      /**\n       * Node. Does not work with strict CommonJS, but\n       * only CommonJS-like enviroments that support module.exports,\n       * like Node.\n       */\n      module.exports = factory()\n    } else {\n      // Browser globals (root is window)\n      root.elasticlunr = factory()\n    }\n  }(this, function () {\n    /**\n     * Just return a value to define the module export.\n     * This example returns an object, but the module\n     * can return a function as the exported value.\n     */\n    return elasticlunr\n  }))\n})();\n"],"sourceRoot":""}